<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Out of Order Core]]></title><description><![CDATA[A blog discussing computer architecture and microarchitectural implementation by dissecting vulnerabilities of modern processing devices.]]></description><link>https://outofordercore.github.io</link><generator>GatsbyJS</generator><lastBuildDate>Fri, 02 Jul 2021 17:40:34 GMT</lastBuildDate><item><title><![CDATA[RowClone: Fast and energy-efficient in-DRAM bulk data copy and initialization]]></title><description><![CDATA[In this post, we’ll take a brief look at the paper: This post only takes a brief look at the concept described in the paper and I highly…]]></description><link>https://outofordercore.github.io/row-clone/</link><guid isPermaLink="false">https://outofordercore.github.io/row-clone/</guid><pubDate>Fri, 02 Jul 2021 20:00:00 GMT</pubDate><content:encoded>&lt;p&gt;In this post, we’ll take a brief look at the paper:&lt;/p&gt;
&lt;center&gt;
&lt;a href=&quot;https://users.ece.cmu.edu/~omutlu/pub/rowclone_micro13.pdf&quot; target=&quot;_blank&quot;&gt;
V. Seshadri et al.,
&lt;br/&gt;
&quot;RowClone: Fast and energy-efficient in-DRAM bulk data copy and initialization,&quot;
&lt;br/&gt;
46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), 2013
&lt;br/&gt;
&lt;/a&gt;
(Link opens a new tab with PDF ~ 2.4MB)
&lt;br/&gt;
IEEE Page (link opens a new tab): &lt;a href=&quot;https://ieeexplore.ieee.org/document/7847625&quot; target=&quot;_blank&quot;&gt;https://ieeexplore.ieee.org/document/7847625&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;This post only takes a brief look at the concept described in the paper and I highly encourage you all to go through the paper to know more about the concept and the underlying mechanism that enables RowClone.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 36.075949367088604%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABbklEQVQoz0WQvW7VQBCF76OlRDSEloIH4C0iQAgB4iFo6RB/BSQlkAQ6JDqQLr72/u96d30dr/0hb+Ay0tGMNGfOmZlNCIEQPL0ReKvona4IVhGdYp4LKWXGcWRZFrz39H1fc0qp5mEYam+NzTRNXI0jTnXIboeWbYUSO/q/gqtYKaUOaa2vYQzGWJTS1WCe59rfrKrV2VmMVigpaq2VJKVYif9ira3RB6y8NacY/2+4FivRWY3RskIpgVaCPri6WYyRYb9nLlfI5ieq3aK6LUb8pmt+EUzHkHN9wWHDfg8+g0/gIoQM+wlKmYgp1T/NpWD9iA0Trp8IacGGQk4j+yGTc2bjfSD2HvntOfLyEfLrM8TlE8TFY+T3F5TlcDFDtLSfThDnD2gvntKdP6T9fB/94yXTcm2+sc7hnaY7vUvz5gbNu2OatzfZvjqiObtXiSylCuYg2L2/hfl4G3l6B/3hmN3rI8SXk3qZFC1/AOt7CvI7XBZCAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A diagram that illustrates RowClone that uses to back to back activates to clone data from one DRAM row to another using the Row Buffer&quot;
        title=&quot;A diagram that illustrates RowClone that uses to back to back activates to clone data from one DRAM row to another using the Row Buffer&quot;
        src=&quot;/static/f4ff1fb0a2860cfb5f8d0560aa0251fd/f058b/banner.png&quot;
        srcset=&quot;/static/f4ff1fb0a2860cfb5f8d0560aa0251fd/c26ae/banner.png 158w,
/static/f4ff1fb0a2860cfb5f8d0560aa0251fd/6bdcf/banner.png 315w,
/static/f4ff1fb0a2860cfb5f8d0560aa0251fd/f058b/banner.png 630w,
/static/f4ff1fb0a2860cfb5f8d0560aa0251fd/40601/banner.png 945w,
/static/f4ff1fb0a2860cfb5f8d0560aa0251fd/48ca3/banner.png 1084w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A diagram that illustrates RowClone that uses to back to back activates to clone data from one DRAM row to another using the Row Buffer
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Structure of DRAM&lt;/h2&gt;
&lt;p&gt;If you have read my previous posts on Processing using Memory or Row Hammer, you can skip this section. For those who are new to the blog or are interested in a quick refresh, let us briefly look at structure of DRAM.&lt;/p&gt;
&lt;p&gt;A DRAM mainly consists of a Transistor and Capacitor connected as depicted in diagram below. When a high voltage is applied to the word line (also known as address line), the transistor is active and the charge in the capacitor can be read from the bit line. The capacitor leaks charge over time and hence it is recharged periodically.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 101.8987341772152%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAACRUlEQVQ4y42UaY+iQBCG5///EhO/qMwmOpuYRUTAAwTvA40mBjS68RY8eCfVM03A0V0raem01U931VvVbwAQBAGitt2skctmkUgkUJAkWJaFTDqFtPCO48nDI+OMNz4ZDocwDINt1vUaFEWBpmnIZrPI5/Moaxokqch8TNNkg3xrtRocxwmhb3xyvV7Dcbvd2CDr9XpwXTfcQOtRX+4fAu/DjV6fQIVCAdVqFZPJJNz4z5Dp53K5YL/fxxw8z0OlUoGu62xQCna73VNQLGRypHzRwvF4BLnMZjO0Wq3Qud/vYzQahYf5vh8LlRsDHg4HpFIpBjAtC2a9zoRYLpcIbjd4no/lcoVKpcqEaDQaUFUVzWaTQaKpYEAKt9vtRgNhmzKCgF/vGaQzAj5yOTjuIvSgSHgED4EEICPVuJq+57HwzuczC5H/R7bZbNDpdJ4D768fPFGToGTz+Ry2bb8OpNuVigVIJRVqSUZJUWNdQvmlUooqHKr8CHi5nGEPB9ANA2VNYXl03DmGts2KnUpKkiQ2H4/HL9zQ92DV6xCEDCtsURSZytWajnJZgyzLrDajaj8FPuoebtQEZIPBANPplPmSaD+A9yXAc8IH729+GMFImIc5pE6hgo2qeA/kIH4gdQ11U7RTQuDpdIol9lnI0fXFYoHtdhs2QuxxkIsich+/kUwmoajl7xoMfjT+Vzkd0W630e32WN6NugnP9+M33KzXWK3+wnUd9o2GfA88+x7arS+QKP6BVJThf4vy3/fw1fXoe/gJt4jzCAFNktMAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The diagram shows the structure of a DRAM cell with a storage capacitor and a transistor. When the transistor is activated using address line, the charge from capacitor flows into the bit line and can be stored or read.&quot;
        title=&quot;The diagram shows the structure of a DRAM cell with a storage capacitor and a transistor. When the transistor is activated using address line, the charge from capacitor flows into the bit line and can be stored or read.&quot;
        src=&quot;/static/a2aa7f589e9bbedcd5ae95860a63d35d/f058b/dram.png&quot;
        srcset=&quot;/static/a2aa7f589e9bbedcd5ae95860a63d35d/c26ae/dram.png 158w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/6bdcf/dram.png 315w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/f058b/dram.png 630w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/40601/dram.png 945w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/eb2af/dram.png 954w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The diagram shows the structure of a DRAM cell with a storage capacitor and a transistor. When the transistor is activated using address line, the charge from capacitor flows into the bit line and can be stored or read.
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://electronics.stackexchange.com/questions/306002/why-does-a-dram-cell-necessarily-contain-a-capacitor&quot; target=&quot;_blank&quot;&gt;https://electronics.stackexchange.com/questions/306002/why-does-a-dram-cell-necessarily-contain-a-capacitor&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;These cells are arranged into a 2D grid. The bottom row of the grid is know as the Row Buffer. The Row Buffer stores the data from the the activated row that is later consumed. If data to be accessed is present in the Row Buffer, it is termed as a Row Buffer hit and the row activate can be avoided. Each DRAM module contains multiple banks that can work independently and each bank contains its own Row Buffer.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 69.62025316455697%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsTAAALEwEAmpwYAAADOElEQVQozyXP708adwAG8PuD9q5NXJd0Oi2K1Qpii4qIUFabVDFd1rG9qYitcct+JVuWZXvTur3a8EXtMW0xYlfwx5ZpaSobEO7H9w4ODnZ3HBzHfe+8+y6658Unz7snD3Z5vNsRGO2Z7B32Xxucvmqb7nf4nb3evhG/w+Yf6PH1Ov3OvukrQ75h+/Sgzdc/4nf0evscfme/bwAbmhpajayM+a9/+NG90N3QzJ2ZB5Hl68Eby/eXfaGZkVnnamR14tZEOByeW5gLzAei96NjgbHlSPTmfBAb9F57GPnUfcvzQTh8OzTnmw9GFqOuoHtp8aF3ITB827US+cw967n38Sd37i74Q+8vLT4YvemOLq0EQrPYO4NvuSZ7+lwXHJ7LNudF+/jbE8GRgYmusan3rk5d6p+66PZesU92OTzvDo1fso93jXq6bTcuuDzddncXFvv5i8Pff0pu/ri79cN+8nHi6ff7qSfPN757tvHN8yff/hb7euOXz/Ffv8TXv9pPPj5Iru0lHx3uru3tPDpIrmE0YBFCunHaUlSEUEtRq9V6S9HaqtFW9bZqtBTYUqDc7Jxalmki00Sn55oWwuq1mg41URQqFe7Fi910OkXTVLutGDqs8VWuXNI6qtJq5vM5CDXD0A1DPz1XhxATBEGSpHw+v7m5GYvFEokEAEDXdUlu0AygAE1SpCiKpVIJIdRsNkmS5HkeQogQwur1Osuy8Xh8fX09Ho+nUime59V2W6AAe/IP/Tp7/HJPFASSJE3TtCwrn88DAFT17CNG03Q6nU4mk1tbW4lEolQqNRoNvspX3xTZo79zqb/+fPZSbsiVCocQ4nleURTDMBiGsSwLy2QyOzs729vbOI4TBGFZ1r+CACFsSgLHMhwDsq8zoigSBIEQAgAoimKapiAIZ8uZTAbHn+I4ns1mRVGUJIlhGE3TCJI6evXq4PCPo+PjWq1WLpcsC1mWhdCZ/xeMIIhCoVAul3VdVxSlXq+TJNlqtViWzeVyJycnFEXJslwoFBRF0c8DIdQ0TVVVrFgs0jTNcRzP8xRFMQwjCAIAoFwuS5JUrVY5jmMYRpZlCCHDMMViEQBQqVQ6nc5/j11mEW0II1oAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The image above shows how a DRAM module contains multiple banks capable of operating independently. Each bank consists a grid of DRAM cell with the Row Buffer as the last row. The DRAM cell itself consists of a Transistor and Capacitor. On applying a high voltage across the word line / address line, the data from the particular row is transferred to the Row Buffer and the data can be accessed from the Row Buffer.&quot;
        title=&quot;The image above shows how a DRAM module contains multiple banks capable of operating independently. Each bank consists a grid of DRAM cell with the Row Buffer as the last row. The DRAM cell itself consists of a Transistor and Capacitor. On applying a high voltage across the word line / address line, the data from the particular row is transferred to the Row Buffer and the data can be accessed from the Row Buffer.&quot;
        src=&quot;/static/d1ee6c0da3e4ae61732fc85ffd8cc910/f058b/topology.png&quot;
        srcset=&quot;/static/d1ee6c0da3e4ae61732fc85ffd8cc910/c26ae/topology.png 158w,
/static/d1ee6c0da3e4ae61732fc85ffd8cc910/6bdcf/topology.png 315w,
/static/d1ee6c0da3e4ae61732fc85ffd8cc910/f058b/topology.png 630w,
/static/d1ee6c0da3e4ae61732fc85ffd8cc910/ae694/topology.png 850w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The image above shows how a DRAM module contains multiple banks capable of operating independently. Each bank consists a grid of DRAM cell with the Row Buffer as the last row. The DRAM cell itself consists of a Transistor and Capacitor. On applying a high voltage across the word line / address line, the data from the particular row is transferred to the Row Buffer and the data can be accessed from the Row Buffer.
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://www.researchgate.net/figure/Simplified-topology-of-DRAM-organization_fig1_326276966&quot; target=&quot;_blank&quot;&gt;https://www.researchgate.net/figure/Simplified-topology-of-DRAM-organization_fig1_326276966&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;Now that we know, each row activate brings data into the Row Buffer, we can dive deeper into the mechanism of the RowClone.&lt;/p&gt;
&lt;h2&gt;Storing Data in DRAM Row&lt;/h2&gt;
&lt;p&gt;Just as one can open a row to transfer charges onto the DRAM Row Buffer, one can also open an empty row to transfer charge from the DRAM Row Buffer to the DRAM cells of the activated row. Once charges stabilize, the cells with charged capacitor can be charged completely to denote a binary 1 and the cells that are uncharged stay the same to denote a binary 0.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 438px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 208.86075949367088%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAqCAYAAACz+XvQAAAACXBIWXMAAAsTAAALEwEAmpwYAAAGMklEQVRIx5VWS4gc1xVtsLFiEyK8EcFgMAEREnC0NQRMCI6dpTZBEQmYbJyNDV6EyAYtZCNvTLa2FwHbYGIFfSzJoyGKRiOPrIwGydaMR9ane7q6vt1dXd1d/1931XSfcN7MGw0zpdi5cKlX77173/29c18NmzSdTsV3fX0drusiCAJEUYR2uw3f9xGGIQaDgWDOc244HArm2LZt5HmO2k6F4/FYCEvSdV3MkeI4FoLcO5lM0O/3hTISD8myrFphkiRbCg3DEMKkoijQ7Xa31mgdDyHRukoLpcue5wkB0zThOM6WuwwB18m0lgdwL7+VCqUVUqjRaAglVErlXOO41+sJ6zudzv9WyDhwg6S1tTWUZbkVJ8ZNEhVzjsQwkXcp5Cky0CRVVTEajcSYyaKbkjiWh3ON8dylkAmgklarJVzSNA2WZQnmPL+ck8wqoNv1er3aQlkOaZoKy6iEp9NtWs5DOM9q4D4yE8lvpUIKyrjIspF1yPjyXxKzzkqQNVrpMoW5kbGkJc1mE0Hgi3kKM0kcc53uMruUpYxQyB/JkqIoRBB4iOMQYRAgDH2EgScU+56LmOu+B88dim+axBgO+6LktiyUxFNcP4YfFfDCMcIohR+Nxb8f5QiiFG44hhuM4Pncm8ILC7EnDCPUmAQCgSwNZxBBvXYcw/mDsC7+Dvevfwhr7mV0Z1+AOvcalJsfozd/GN25Q7C++QT61TfgfflHaJdfhd66ixozs7KyImIjamuQYnDl9whP7kE+82OY/zmG6MJ+pGceQzj/IjpLx5B+9gTSM3vgLL0B58IvEZ3aA/ezp2E0b6HGwmQNse6ACexhBveLQ0hPP4Jidh+sxWNIZ3+C8tyjCOd/g96Nt1Ccfxyjs4/BWfwL3IvPIz3zAwTnn4GpLO+Ooe24aN74CL2lo+hcP4bWylmol1+HcelPUBffhb7yT5jzf0Z74TXoyyegLxxB9/Jh3J99BZpyb3eW8zyDG+TwE8BPpgjjHEFcwo8niNIScTIS4yCZIk4LJFmJMJ2IpKRp9kDh9lrcrMxNfkBlMcZ4M3k71yTtKuztFu+0njdFAiqro2pfDd+DpEKWFyFr+8EPtfC7rCSxIuRdrg7T/+nyzsO/0+UqQUmMH6FMYuDDqLbzRIm+ZGIiMVDcb9cVQMr+wn7CNc5zn+zThL5KgCVMETnItIgCHFOYiE1ApTBbAJlrhK/KvsyNzKYk4h0VkAggtFISkyT7D/HxoYjNTQRRKqBFdE0iORVyTQIxoV+u0YPKRk8ljBX7MBFbUZStZiUbGP+5zjG/BJjKFkCrtrusqi3hDomJ2J5hxprJkonkeuXLgcj7oEmZWJ9s9hvxqrC3KXTh+xuHp1m2obCqONumDrttom93oKzV0eu2MXBsdNsG1GYDTreNfq8LQ1Ogqwo8d4BWsy56TcVdnsJW78Ax1+AYa9Abq7D1BgaWgo56T/xzTNYbt6HWV+G0VTHvd1uoMZAbGQrgBwHWixyR20M2KkBPdcPEuCjBiJTrE9g9B5PNEAyGrnCbIWEyg76FGqueWSTXGw2MswR+v404yVAUJZRWC0maCWVZPkLX7mF98704dD14vo8049twhHDQqXB5WqJv1uE6Flxbh968i6GtidP7HRWGcg+JZyPxe+gaTVhqHZHbFeEIetpGUnjdNgCTqFwgSXIk6TqSpECWpsiyAmlWIs9GyJIYPnuxnyCOYsRRgjjOUIxKlMVot4V+EEG7/Tmsr9+H+dV7UO9egbHyKYyv/w519Rxa95bQXvkQ+s0PoN25BO3OHMzVk2jc/Ae0Vn3DQl6njYfkFAM/hzN/GPHpPUjPPQlt4U2Es8+KvuzP/RprC8eRnf2haJ3W/CvozPwK+fm96J7YB+3+ImosxuXlZcGTcgx7OMLw6ssITj2BjI3+yyNILv4Co7OPI7nyAtRr7yA//yTGn/8Ig8XX4V1+CcGpvRiefgpGYwk1XnJmmjydlOh7OfSFvyL81wH4F5/D2sLb6P/7t/Bmfob2pT+gee1v8GZ+Dn/mpzCvHYU+exDxhf3QTh6AqdzaHUPWJEGg0zbR61pwHBtty4ChK7BMDW1LEw2d7xjLUKAr30JXVtGs30a/7+C/Z4NA+cKvnRYAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot; An illustration that depicts how the binary data 0110 in the DRAM row buffer is transferred to the the destination row by activating the destination row and waiting for charges to stabilize.&quot;
        title=&quot; An illustration that depicts how the binary data 0110 in the DRAM row buffer is transferred to the the destination row by activating the destination row and waiting for charges to stabilize.&quot;
        src=&quot;/static/85545e24823149479ee7cd2829d8c510/50e4b/store.png&quot;
        srcset=&quot;/static/85545e24823149479ee7cd2829d8c510/c26ae/store.png 158w,
/static/85545e24823149479ee7cd2829d8c510/6bdcf/store.png 315w,
/static/85545e24823149479ee7cd2829d8c510/50e4b/store.png 438w&quot;
        sizes=&quot;(max-width: 438px) 100vw, 438px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: An illustration that depicts how the binary data 0110 in the DRAM row buffer is transferred to the the destination row by activating the destination row and waiting for charges to stabilize.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;Now that we know how to put data back into the DRAM row, let us look into RowClone.&lt;/p&gt;
&lt;h2&gt;RowClone&lt;/h2&gt;
&lt;p&gt;In RowClone, the source and destination rows are activated one after the other. The Row Buffer acts as an intermediary for the data transfer. The data gets placed in the Row Buffer and then read back from it into the destination.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 561px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 172.1518987341772%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAiCAYAAABfqvm9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAE5ElEQVRIx31WS4scVRRucCGuXYjoRpCAiNkJLgPZKC5dCYKirlxldKELA0r8BYK4FMxGDUSHjDNiNEMyMo5xGIfI5Dnd9bhVdev9fnVVdX1ybk/11HT3eOFyzq2+99zzncd3e9C2LfqzP8IoBtN0qEzDSJLhej7mx/zZwfyGIg1RZrGYeRKgTCMUSTj9Ln6jdYA8DtA29YLxQZqmcBwHtuMgjgL4XEIa+XA4g22oSEMXnElIAkfopiYj8mzYuoQq9dFMWtRVhaZpph6SQcuyxIxCH1nsoWmBMIyQZjkICEGlg51eVjXSJEFTxPD8ALIswff9JZDbBqbyAK7JwEb3wYb3YLMh1MMDWOohTPUR5If/CqkND1DncXfwGHI/qFVVCfgkGWOwbRt5nkPXNRCSOI7F9zzPhEf1EcyFpHQLMkSHaHDOUZblTO+GbhhCJkki9s9n+oRBCix5QPFUVRWmaQpjiqIInb53Ou3rEtEfJwzWdS0gk6RDrusKyHQ4yzIxDcMQ32hfURRi0pomXbBgMEmmkD3PQxAEQmdMnQa+bcFU9QhyLMJDSOhCkmR80A8oySCMkKQ54jgRJRHGVKce0jRHFCewbQdJSkkJFjproWwokwYbwlDvg+sKuHYIQzmAaZA+AtclWKYOy5Bhm7oIwUJSyE2CRHDDKIH2+7uIrz0PdetTuNdfR7B2Fur2Fwh+PYd48zUoW5/Bu3YW2i9vwHXtI4OTY4MU+P39fYRhgDjJYG+cx/iHAayb7yNdP4Pixydg/rGCfPVJjNefBd98D8l3AzirL8L3nJnBGWTKDHknEuEHGO18BXv7Q8h7l8G2PoG2+QGUvcvgWyuw/rqI0c7XMK6/ieGNj0Xi+kldiCE1eVa2yCqgrICins68bIQs6+PvpDe9TpkZXM6FbU+2otXaST1bA5MT/XtqYc+T7WQyjQ11yHg8XrpnKeRlBvuDuuK0S0+N4bwRik8YhoIEaFLX0Pq0J2BGX/MeEsN0rCNJEjRNE21FpDClrnzWv30nltIXlQ+VAnUASeI8OtjFkAwR+0RRJIiDUFCc+9leQg6J2ESSvCSdiJb2dBcSCrqUkNAlhIS8p70LfEjekGdEUwSTPCHYRGdkuONJ+r0j4P/lQwGlrgW07gmg24k4SDcMXdSl49izDjtBDv0sVQQ5TYUehKEwQoMMd4Poi0aWF6jrZvkT0I3JpIEmPYCpDqFJD8XLZyiHkB8dgKtDcDbC8OFdcE2F9Oguxnm6CJniQJ5QcMsig2+qSJMYFtfFTKIAXGfIkkjoTB4h8GyEjoHUN1HVDcqyEPGkEAymQWdQGRMPfexykRzPc+G6jvCaINPmuq6O4lqgyFNkkQtuWpBlWWSabM099BOElobI9+HbHJ5lIPZduJwh8j1EngtLVxC5JlxDQTV76HGSbY6fgAyGchd8dBtcvSfo35DvgGuSkProH/EMcPYAunJf1OpCUqgYqUSoSOkJMH57C/FPT8He/gjGz+cRrr0AaesS/I1XEG68DPnGCvy1l6CunoNr80XGpoTs7u5O/ywlOfjGqyivDODeehve6hkUVx+HunkB+bWnMV5/BubmO0ivPAZ+5Tn4nrX8CaAMT5oGcZJC3fsWzu2LYHe+h777JfQ/P4e0f1VIY+cSRn9/A+PWBQxvXkIY+gv09R+3Qwwe/m5oFAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The above diagram illustrates RowClone. The first activate of source row brings the data 0110 stored in the source row into the Row Buffer. The second activate of the destination row transfers the data from the Row Buffer to the destination row completing the cloning of row.&quot;
        title=&quot;The above diagram illustrates RowClone. The first activate of source row brings the data 0110 stored in the source row into the Row Buffer. The second activate of the destination row transfers the data from the Row Buffer to the destination row completing the cloning of row.&quot;
        src=&quot;/static/5b0be0b9dc6b8642aaafc55b42964ebf/410f3/rowclone.png&quot;
        srcset=&quot;/static/5b0be0b9dc6b8642aaafc55b42964ebf/c26ae/rowclone.png 158w,
/static/5b0be0b9dc6b8642aaafc55b42964ebf/6bdcf/rowclone.png 315w,
/static/5b0be0b9dc6b8642aaafc55b42964ebf/410f3/rowclone.png 561w&quot;
        sizes=&quot;(max-width: 561px) 100vw, 561px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The above diagram illustrates RowClone. The first activate of source row brings the data 0110 stored in the source row into the Row Buffer. The second activate of the destination row transfers the data from the Row Buffer to the destination row completing the cloning of row.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Advantages of Row Clone&lt;/h2&gt;
&lt;p&gt;There are numerous advantages of RowClone:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RowClone takes a small fraction of energy required to clone data compared to traditional CPU centered approaches.&lt;/li&gt;
&lt;li&gt;RowClone is very fast compared to CPU centered approaches as data doesn’t leave the DRAM module.&lt;/li&gt;
&lt;li&gt;RowClone prevents cache pollution by not bringing in data to CPU thus keeping  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The authors later went on to publish more papers that solved efficiency issues related to data transfer between different banks that would have otherwise used the data bus and consumed more power.&lt;/p&gt;
&lt;p&gt;RowClone gives an different perspective at processing similar to Processing using Memory - instead of centering processing around CPU, we can move processing near data to save time and energy and as our focus shifts to making more energy efficient and data centric architectures to counter slowing down of Moore’s Law.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please leave a comment and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Row Hammer: Flipping Bits in Memory Without Accessing Them]]></title><description><![CDATA[This post we’ll take a look at Row Hammer, a read disturbance phenomenon observed in commodity DRAM, first unearthed in the paper: In this…]]></description><link>https://outofordercore.github.io/row-hammer/</link><guid isPermaLink="false">https://outofordercore.github.io/row-hammer/</guid><pubDate>Fri, 02 Jul 2021 19:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This post we’ll take a look at Row Hammer, a read disturbance phenomenon observed in commodity DRAM, first unearthed in the paper:&lt;/p&gt;
&lt;center&gt;
&lt;a href=&quot;https://users.ece.cmu.edu/~yoonguk/papers/kim-isca14.pdf&quot; target=&quot;_blank&quot;&gt;
Y. Kim et al.,
&lt;br/&gt;
&quot;Flipping bits in memory without accessing them: An experimental study of DRAM disturbance errors,&quot;
&lt;br/&gt;
2014 ACM/IEEE 41st International Symposium on Computer Architecture (ISCA &apos;14)
&lt;br/&gt;
&lt;/a&gt;
(Link opens a new tab with PDF ~ 828KB)
&lt;br/&gt;
IEEE Page (link opens a new tab): &lt;a href=&quot;https://ieeexplore.ieee.org/document/6853210&quot; target=&quot;_blank&quot;&gt;https://ieeexplore.ieee.org/document/6853210&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;In this post I’ll only betaking a brief look at the issue and I highly encourage you all to read the paper to find more insights and nitty gritty details of this vulnerability.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 62.0253164556962%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABoklEQVQoz3WSC47iQAxEuf/5OAHsbkKSDmn6/32j7hCGGbSWIrmtil121QmglMIRIQV+RyqJVPKPWq0Vn/wH9rSuK+fzmYd8EHLk7zaw6JV/ckS6By55Niu5qxW9LjzuMyZYdDAM8vbCPrzCp7A3HIaBRSx9wmq3Dt6c7A1b+OhxRpGVIqyCEiOF2ge15sLcUV7vDH9Tbs2OmLUg5tS/xr5FNoa0bVTARvfCTmohl8yp3eL4eIJK3W/apjZQu+Fx2+I9xdqeN3bHPdvK/21Ya3m9+4/OdIY5NWEqKSWMMTvDyje21s+VTfTUt7dShpuYSRSmaSbnQi6VYbwhrf5W/VB5WRYulwvTNEFJKL1QgiEFRfYavQm8kwQnu8I5aMiemhzz/Idg5F6LltpU9t6jlMI61xtKNaG0YFivyMdMbQo72WujuCLkSI6W0uykZsQ2Mt6vfSg5fq5so6c8b7JaSW4GzhH1VN+lwGLu+zmC7as2CW9akEv5FKUpd6jcfNbMGnN8qdzyRYsPizWDx3eGP1Xe82aDlu9ejC/cUXdPH77XvgAMRqrHvQJF1AAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;An illustration of Row Hammer showing how an activate of one row can influence the data stored in the adjacent row.&quot;
        title=&quot;An illustration of Row Hammer showing how an activate of one row can influence the data stored in the adjacent row.&quot;
        src=&quot;/static/209d8c513f56f33a2d6954d0e2d2a472/f058b/banner.png&quot;
        srcset=&quot;/static/209d8c513f56f33a2d6954d0e2d2a472/c26ae/banner.png 158w,
/static/209d8c513f56f33a2d6954d0e2d2a472/6bdcf/banner.png 315w,
/static/209d8c513f56f33a2d6954d0e2d2a472/f058b/banner.png 630w,
/static/209d8c513f56f33a2d6954d0e2d2a472/dba9a/banner.png 652w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: An illustration of Row Hammer showing how an activate of one row can influence the data stored in the adjacent row.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Structure of DRAM&lt;/h2&gt;
&lt;p&gt;To fully understand the vulnerability, we must first take a look at the how modern DRAM are structured.&lt;/p&gt;
&lt;p&gt;All digital data can be represented using binary bits - 0 or 1. Storing these bits in their meaningful order to retrieve back again forms the crux of storage systems. In DRAM, these bits are stored as charges in cells consisting of a transistor and a capacitor. as shown below:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 101.8987341772152%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAACRUlEQVQ4y42UaY+iQBCG5///EhO/qMwmOpuYRUTAAwTvA40mBjS68RY8eCfVM03A0V0raem01U931VvVbwAQBAGitt2skctmkUgkUJAkWJaFTDqFtPCO48nDI+OMNz4ZDocwDINt1vUaFEWBpmnIZrPI5/Moaxokqch8TNNkg3xrtRocxwmhb3xyvV7Dcbvd2CDr9XpwXTfcQOtRX+4fAu/DjV6fQIVCAdVqFZPJJNz4z5Dp53K5YL/fxxw8z0OlUoGu62xQCna73VNQLGRypHzRwvF4BLnMZjO0Wq3Qud/vYzQahYf5vh8LlRsDHg4HpFIpBjAtC2a9zoRYLpcIbjd4no/lcoVKpcqEaDQaUFUVzWaTQaKpYEAKt9vtRgNhmzKCgF/vGaQzAj5yOTjuIvSgSHgED4EEICPVuJq+57HwzuczC5H/R7bZbNDpdJ4D768fPFGToGTz+Ry2bb8OpNuVigVIJRVqSUZJUWNdQvmlUooqHKr8CHi5nGEPB9ANA2VNYXl03DmGts2KnUpKkiQ2H4/HL9zQ92DV6xCEDCtsURSZytWajnJZgyzLrDajaj8FPuoebtQEZIPBANPplPmSaD+A9yXAc8IH729+GMFImIc5pE6hgo2qeA/kIH4gdQ11U7RTQuDpdIol9lnI0fXFYoHtdhs2QuxxkIsich+/kUwmoajl7xoMfjT+Vzkd0W630e32WN6NugnP9+M33KzXWK3+wnUd9o2GfA88+x7arS+QKP6BVJThf4vy3/fw1fXoe/gJt4jzCAFNktMAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The diagram shows the structure of a DRAM cell with a storage capacitor and a transistor. When the transistor is activated using address line, the charge from capacitor flows into the bit line and can be stored or read.&quot;
        title=&quot;The diagram shows the structure of a DRAM cell with a storage capacitor and a transistor. When the transistor is activated using address line, the charge from capacitor flows into the bit line and can be stored or read.&quot;
        src=&quot;/static/a2aa7f589e9bbedcd5ae95860a63d35d/f058b/dram.png&quot;
        srcset=&quot;/static/a2aa7f589e9bbedcd5ae95860a63d35d/c26ae/dram.png 158w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/6bdcf/dram.png 315w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/f058b/dram.png 630w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/40601/dram.png 945w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/eb2af/dram.png 954w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The diagram shows the structure of a DRAM cell with a storage capacitor and a transistor. When the transistor is activated using address line, the charge from capacitor flows into the bit line and can be stored or read.
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://electronics.stackexchange.com/questions/306002/why-does-a-dram-cell-necessarily-contain-a-capacitor&quot; target=&quot;_blank&quot;&gt;https://electronics.stackexchange.com/questions/306002/why-does-a-dram-cell-necessarily-contain-a-capacitor&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;The cells leak charge over time and hence they are recharged periodically to retain the data they hold.&lt;/p&gt;
&lt;p&gt;A single bit is rarely ever accessed at once and hence these cells are arranged into a 2D grid with each row connected to the same word line. When data needs to be accessed from a particular row, the word line is used to enable the row and the data of the row can be sampled from the bit lines aka the digit lines. These rows typically consist of 4096 cells to match the page size of most operating system and maximize performance. A row buffer is at the end of the word line to store data before it is put on the bus. In case of data access to same row, data can be read directly from the row buffer and this is called a row buffer hit, analogous to cache hit.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 600px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAQADAAAAAAAAAAAAAAAAAAIBAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHtygpA34AD/8QAGhAAAgMBAQAAAAAAAAAAAAAAAAECERIQMf/aAAgBAQABBQJt3pmmS9442ZMH/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAFBABAAAAAAAAAAAAAAAAAAAAMP/aAAgBAQAGPwIf/8QAGxAAAgMAAwAAAAAAAAAAAAAAAAERUbEx0eH/2gAIAQEAAT8hWgjChy+GZ0PkQ0kbY0tn/9oADAMBAAIAAwAAABADDwD/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAeEAACAgICAwAAAAAAAAAAAAABEQAhQVEx0WGhsf/aAAgBAQABPxAzJSfEKze0DIDAXqCKNYYg6eowiQUqUr8Cx1CS/h1P/9k=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The diagram shows the structure of a DRAM grid with multiple rows consisting of cells connected to the same word line. The bit line is used to sample the data that runs across the image. (In the image, the columns are actually DRAM rows connected by the same word line WL and the rows are in fact the DRAM columns across which bit lines are connected)&quot;
        title=&quot;The diagram shows the structure of a DRAM grid with multiple rows consisting of cells connected to the same word line. The bit line is used to sample the data that runs across the image. (In the image, the columns are actually DRAM rows connected by the same word line WL and the rows are in fact the DRAM columns across which bit lines are connected)&quot;
        src=&quot;/static/03817da758fb4595be8423dfca9fc5a2/b4294/dramarray.jpg&quot;
        srcset=&quot;/static/03817da758fb4595be8423dfca9fc5a2/ff44c/dramarray.jpg 158w,
/static/03817da758fb4595be8423dfca9fc5a2/a6688/dramarray.jpg 315w,
/static/03817da758fb4595be8423dfca9fc5a2/b4294/dramarray.jpg 600w&quot;
        sizes=&quot;(max-width: 600px) 100vw, 600px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The diagram shows the structure of a DRAM grid with multiple rows consisting of cells connected to the same word line. The bit line is used to sample the data that runs across the image. (In the image, the columns are actually DRAM rows connected by the same word lines (WL) and the rows are in fact the DRAM columns across which digit lines (DL) are connected)
Source (link opens a new tab): &lt;a href=&quot;https://www.cse.scu.edu/~tschwarz/coen180/LN/DRAM.html&quot; target=&quot;_blank&quot;&gt;https://www.cse.scu.edu/~tschwarz/coen180/LN/DRAM.html&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;At this point you can understand where the “Row” in “Row Hammer” comes from.&lt;/p&gt;
&lt;h2&gt;Read Disturbance&lt;/h2&gt;
&lt;p&gt;Whenever we read from the row, we apply a high voltage to the word line. The data from the activated row is then transferred to row buffer. When we illustrate these cells, they look large but in reality they are so small, their size is measured in nano meters. When components are placed far away, it is rare that one components influences the other but as we try to move to smaller processes to manufacture these and develop strategies to pack them densely, these component can end up influencing one another.&lt;/p&gt;
&lt;p&gt;When a high voltage is applied to a row, the electrical disturbance caused to the cell by this sudden activation can influence the cells nearby. These are not new phenomenon and can also be found in Flash Memory but they implement error correction, adding redundancy, to mitigate these problems. In commercial DRAM, this was never a problem before and hence there were no mechanism placed to mitigate these problems.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 385px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 104.43037974683544%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsTAAALEwEAmpwYAAACMElEQVQ4y51V23KbMBT0/39XHuokT0k6U9dObI9TY3MRoLuExHaOEhNsJm5SMQIER3t2zwVmfd9jPGhNB40QA3zwuDYu98/o5JzDYrGAMebMSFqFilcIXZdsvPdv0zk469B13QeJ9z0zrTWyLMP9/T12ux2klJBOQTiJl2yD5+MGpaiRC4bs+IpDlSGXDK/lHsfqOAXcbrd4fHzEcrnE3d0dVqvVQL8WDdqmBLRGEAJ68Qtm/YLeGATvzxSd5uxaXGreoG0r9MaikxJ91yGS5DyHNwbG2kkcZ2P08aTR8BbcyolDX5YwjJ0BWmsRY7zOkAuOWjXnsiiJ+z10lsE4l96R9JubGyilrgNSghrdTmR1dQ1TFAMg2d3e3uJwOFwHJI8EGPuY1lVVgdU1GcApNUgmqYwxcM7/DchUMwCu1+tUWimOXQcquW8lRXCBXf4KIWWKE9UrMaH7tm2Twy+VzdhrISuE+MaQQPRFN11eE8MQQorDaY5ZMlUjxvCWTa1T213KPJNcFAXm8zkeHh4wn//A09NPeNUiigOizMGKZwRxBGQB3fyB5xmgSkRZIOoa/Xt8B4bEjhqemp+Kk+7JqCdWfUTOcxinEYLHMl9hXW7gvEEIDn3sppI/jeH7dd8e0BqO1gpob6G8SXGl9QD0lSyfPJaKTZwZb5GLcpLh6wxPgJKlLI83HUWB38Xz5NP1JcBafxT20JJOpVD8F+C49U7Pxr+GbwPazn5ac5cZJsC/hoVs62ryMPgAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;An illustration of how an activate of one cell can cause disturbance to flip bit in the cell of an adjacent row.&quot;
        title=&quot;An illustration of how an activate of one cell can cause disturbance to flip bit in the cell of an adjacent row.&quot;
        src=&quot;/static/b0f79427fc83a77922fe25d9f11728b6/409e6/flip.png&quot;
        srcset=&quot;/static/b0f79427fc83a77922fe25d9f11728b6/c26ae/flip.png 158w,
/static/b0f79427fc83a77922fe25d9f11728b6/6bdcf/flip.png 315w,
/static/b0f79427fc83a77922fe25d9f11728b6/409e6/flip.png 385w&quot;
        sizes=&quot;(max-width: 385px) 100vw, 385px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: An illustration of how an activate of one cell can cause disturbance to flip bit in the cell of an adjacent row.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;br/&gt;
 
&lt;p&gt;A thing to note is this disturbance is not caused as a result of single read but as a result of continuous activation.&lt;/p&gt;
&lt;h2&gt;Piecing Together Row Hammer&lt;/h2&gt;
&lt;p&gt;Now we know the fundamentals behind row hammer, let us see how the authors of the paper executed it.&lt;/p&gt;
&lt;p&gt;The authors rapidly activated two rows, with a single row gap in middle, alternatively to see how the data in adjacent cells change. Alternate activates were used as opposed to hammering a single row as the existence of the row data in the row buffer will lead to row buffer hit and the row will not get activated. Accessing the row alternatively makes sure that the data is not present in the row buffer.&lt;/p&gt;
&lt;p&gt;The authors observed when repeating this tens of thousands of time will eventually cause data corruption in the adjacent cells.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 37.9746835443038%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB50lEQVQozz2Rz0tUURiG79/msmVGLYJaBBEVgU0aaEoGUQvBMoLUJI2KijYpYuMYBi2iaBpn0hojENRz77nn3J/jzNyZuTpPnJv6wse7Od/he97X8qIWftRChwlhLaWZdEjTlCiKCMOQIAjwfT/zZrNJly5Gf6ItJkszdKafM//lJQ835pjfymOJ0lPsygu2izPI8gxJvJMtuK7EcRyklNi2nU29XudIRbXOhcJ1Po7dZHhhkLMrfYz/mMIS+ZM4hdOI5TM4iz003O/ZglYSrVw8TyGlg+s6JEmC53lEXsSmqpJbGuDi19v0r45wNd/PWHkSy3ZDXK/GrhMgdQ2l/WxJqhDbjbDdmB2h2BY+tb06vtbsaEVUXMMfGKLv8x1+3x+lMDHM3fVpLKXc7BLp2Hha0Wg0sgvVp3M4SydQK72IfC9ioYe6rh4jV+1f3Hp/gyurQwwuj3BtMce90mMsk5PJRwiRZWawsgw3FxGVV8iNt+xW3iDWnrEXysNK4Jtb5lThMucLOWaf5Biau8Ro6RGWwTMtaq0zVBN8u93GjxKCuEMQt/HCBD/u0ExacPhl1f/Lg9IU4z9nkVOTFN5N8Hr3A1a328WMkcE1rZox+Af7KQcHaeb7aef43ZEbteMEEYbU6v/J/gFlRjOKm/ERNgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;An illustration of how hammering alternate rows for tens of thousands of time will lead to data corruption in the DRAM array.&quot;
        title=&quot;An illustration of how hammering alternate rows for tens of thousands of time will lead to data corruption in the DRAM array.&quot;
        src=&quot;/static/3d7a57b6d21e98c0bbdb2f688aec9deb/f058b/hammer.png&quot;
        srcset=&quot;/static/3d7a57b6d21e98c0bbdb2f688aec9deb/c26ae/hammer.png 158w,
/static/3d7a57b6d21e98c0bbdb2f688aec9deb/6bdcf/hammer.png 315w,
/static/3d7a57b6d21e98c0bbdb2f688aec9deb/f058b/hammer.png 630w,
/static/3d7a57b6d21e98c0bbdb2f688aec9deb/40601/hammer.png 945w,
/static/3d7a57b6d21e98c0bbdb2f688aec9deb/fbf08/hammer.png 962w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: An illustration of how hammering alternate rows for tens of thousands of time will lead to data corruption in the DRAM array.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;This data corruption patter is random and doesn’t link to any particular cell to be averted just by profiling the DRAM module.&lt;/p&gt;
&lt;h2&gt;Severity of the Vulnerability&lt;/h2&gt;
&lt;p&gt;Integrity of the data is the sole reason behind deterministic functioning of our computer. Row Hammer proves that just accessing memory in a certain way can lead to data corruption and this can be exploited in various ways. The smart folks working at Google Project Zero devised a way to exploit the Row Hammer bug to get write access to the Page Table of a system essentially giving complete access of the system to the attacker. You can read more about it here (link opens a new tab): &lt;a href=&quot;https://googleprojectzero.blogspot.com/2015/03/exploiting-dram-rowhammer-bug-to-gain.html&quot; target=&quot;_blank&quot;&gt;https://googleprojectzero.blogspot.com/2015/03/exploiting-dram-rowhammer-bug-to-gain.html&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Mitigation&lt;/h2&gt;
&lt;p&gt;Some of the mitigation proposed include, but not limited to, decrease time between DRAM refresh at cost of power consumption, profile memory access to prevent DRAM Row Hammer, build a larger reliable cache in DRAM to prevent rapid row activation. DRAM manufacturers implemented Targeted Row Refresh using an proprietary mechanism but the paper &lt;strong&gt;“TRRespass: Exploiting the Many Sides of Target Row Refresh”&lt;/strong&gt; [&lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9152631/&quot; target=&quot;_blank&quot;&gt;IEEE post&lt;/a&gt;, &lt;a href=&quot;https://download.vusec.net/papers/trrespass_sp20.pdf&quot; target=&quot;_blank&quot;&gt;PDF&lt;/a&gt; ~ 817KB] (link opens a new tab) reverse engineered the mechanism and showed ways of exploiting Targeted Row Refresh to induce Row Hammer vulnerability in DRAM module. There are publications such as &lt;strong&gt;“BlockHammer: Preventing RowHammer at Low Cost by Blacklisting Rapidly-Accessed DRAM Rows”&lt;/strong&gt; [&lt;a href=&quot;https://ieeexplore.ieee.org/document/9407238/&quot; target=&quot;_blank&quot;&gt;IEEE post&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/pdf/2102.05981.pdf&quot; target=&quot;_blank&quot;&gt;PDF&lt;/a&gt; ~ 2.2MB] (link opens a new tab) that looks at preventing Row Hammer using open research and hopefully one day we get to a fundamental solution to this problem.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please leave a comment and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Processing using Memory (PuM)]]></title><description><![CDATA[Today we will discuss the concept put forward by an amazing paper titled: This post takes a brief look at the concept however the paper goes…]]></description><link>https://outofordercore.github.io/processing-using-memory/</link><guid isPermaLink="false">https://outofordercore.github.io/processing-using-memory/</guid><pubDate>Fri, 02 Jul 2021 18:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Today we will discuss the concept put forward by an amazing paper titled:&lt;/p&gt;
&lt;center&gt;
&lt;a href=&quot;https://www.microsoft.com/en-us/research/wp-content/uploads/2017/09/MICRO-50_347.pdf&quot; target=&quot;_blank&quot;&gt;
V. Seshadri et al.,
&lt;br/&gt;
&quot;Ambit: In-Memory Accelerator for Bulk Bitwise Operations Using Commodity DRAM Technology,&quot;
&lt;br/&gt;50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), 2017
&lt;br/&gt;
&lt;/a&gt;
(link opens a new tab with pdf ~ 2.6MB)
&lt;br/&gt;
IEEE Page (link opens a new tab): &lt;a href=&quot;https://ieeexplore.ieee.org/document/8686556&quot; target=&quot;_blank&quot;&gt;https://ieeexplore.ieee.org/document/8686556&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;This post takes a brief look at the concept however the paper goes in depth reasoning the approach and ways to realize it in commodity hardware. I highly recommend reading the paper if you would like to learn more about the mechanism that enables this compute in DRAM. If you like a higher bandwidth medium like video, you can find the more recent talk by Nastaran Hajinazar about &lt;a href=&quot;https://youtu.be/lu3Br4-kySw&quot; target=&quot;_blank&quot;&gt;SIMDRAM on Youtube&lt;/a&gt; (link opens a new tab) that talks about the entire system right from programming interface and Instruction Set Architecture to realizing the mechanism in hardware in their talk and their paper.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 487px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 138.60759493670886%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAcCAYAAABh2p9gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFgElEQVRIx5WV/1dTdRjH/Zf6tX7IUEolsk4mAfHF5imDU2galEKGIWKaElIZlfbdjtk3LRVk39jdLhsDGTS+XMYYuxsb+8I2GBvIxqtz7wy06NvnnOfcz32e+3nveT/P8/5sE39a7vA0bX2f0D54kcsjVwkFQsTiMeYT80jeCT4dvkTHyNd8O/ITXp9MNBolHA4zOzurnt+0vLzM5OQkc7E51SHKdh7W7maLuZSq3iNEgxFW7/6YzdXPDl0FW4QSykw1TPu9qn91dZVIJLIOKMsy8URcdVj9A+T3lLLNUkG1tZ6AL7CWvXUyB7i9t5IK8wE8M9NrsTXAP1MeCY5TKzTxRu8J2gcuEPQFSMQTLMTmGXQNUy+cpMH2DqesH+DxT6sxhXYwGMwBKumurKyQyWZUhzMwxsu6I1TrD3O2r4MPxYvs09exV/8aVx03SQTjJKJxorNR/D4/4UiufvfV0Ol04vF6VIfZayNfeI5HLWXU9Tdz1HJa3W+3VHLptx9hJccklU6tgSgrkUisZ3jnzh2W7yyrjl65n3x9KVuNJdRaj9Noepd8Yyn5Pc9xse8Sq6kck+RCkmAgR5MsxOZi99dQAVbWmH+CE0IbJ8xtfOv4ie/t12g2tnJSbKfTocM15WLcIyG5J1QbmRrFIQ3jlqfWM7x3DfiHKBcPUGbdT9PtNt4WzlIq1qCx1ao11QiHeFrcx0HrMVptHTxjeYmdPXv50PF5DlAZGUmScI44iYdi9PkH2aIt5lFzGa/Zm6g1NLHVVEqhRUOD6R2KeqrYJlawz/w6LWI7j4vP85ipjHNDF3KASofT6TQLi0mUCe73OyjQVlIoaKizNVOna6Kgp5Jd5n0cNZ7iWV0VBcIeqoQjtAjn2CnsZbu+nPOOLzaew8WlFJMRD1J4ksmwh+mwzHjIxUTYjTfiU+d0ODiKW4lFZJyzYwwHR/DHAus1vNf+aaWSi/8YV87/pcvKM7ua3dCUS+LvYtm75/8F8P7sFb1mMpm17zZi978oSxOSKoL/RPnepkxHZdUC8SBLi2kWEguqMhRbWloinUqzlF4ilUqRXEwyvzCv7tUMs9ksip5XMjmRGqYsFBqe5wmjhtctzbhcLtwBD4FIEMkl4Z/xE19I4PXL6j2aXcmSWcmsSy+ZTDI4OEgoHFIdN8d1bNWWsFVfwkFDI/U9J9nRXcFu40s0dZ+h/PorPN39AgcMR3GOOYmnEoQTEeQZn1pftYbK5o8MzVM2iszV7BarabK/R51wnDxDMYVmDfW6Fgq79pBnKqZKOMzxzjM82alhx7UyzgjnNx5sacZFq9hBa+/HfGP/noGJQYyjZnqlPvpHb2MasiCMitjHB+h12rgx1M11xy1uTw7lAJWuKXqOzkVVh84tsN1QQYGhkgPmRoTfRG5JBozTIoZhE10jeoweEd2YiVlfcC2RdCKV67KiZa/Xu1bDG+Na8nTF5OmLedXcSPWNN3iw8ynyDaXsv95A/vViNuuKeKbrRa6IP3PTreea1KVmvSHlnikRjeEQGuMh9Q5s6GrhqRsayrU1NGtbKblaxa7OF6jpbuDIr8fZ+fMetn1Xwkfi5xsDjgUnaOlv54S9nS8clwnJs8TDMZJzC/imffimZEIzIfxeH7JPJhwNMxMMEAjevRxisRiKKYFsOoPJ3cvm7iI2a3dzUDjGl+JlWuzvc85xgQ7DZ7ylO80x61lOmd7HP+W7KxFIROKqXDcp//put5ux8TEWY0kssp0txhLyjMUc7jtJTc+bPKAtYLOpiEO6Rh65VcRDll2UC/s5Z/iYo/3vqgL44fYvG1MenZFotrZxzHqGL4ev8FX/FfX99OB5vrFdUetY393CB+aLnBc+o9b4Ngd1b/GLs0sF/B32dH2lsXCeuQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A diagram showing OR operation with Processing in memory where two data rows are opened together with a fully charged compute row to effectively perform an OR operation.&quot;
        title=&quot;A diagram showing OR operation with Processing in memory where two data rows are opened together with a fully charged compute row to effectively perform an OR operation.&quot;
        src=&quot;/static/94a16c76833c5f4cd9f2f7b95bfd1349/7b439/banner.png&quot;
        srcset=&quot;/static/94a16c76833c5f4cd9f2f7b95bfd1349/c26ae/banner.png 158w,
/static/94a16c76833c5f4cd9f2f7b95bfd1349/6bdcf/banner.png 315w,
/static/94a16c76833c5f4cd9f2f7b95bfd1349/7b439/banner.png 487w&quot;
        sizes=&quot;(max-width: 487px) 100vw, 487px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A diagram showing OR operation with Processing in memory where two data rows are opened together with a fully charged compute row to effectively perform an OR operation.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;DRAM Cell Design&lt;/h2&gt;
&lt;p&gt;A DRAM cell consists of two parts - a storage capacitor and a transistor. The capacitor stores the charge and transistor guards the access to charge. These cells are arranged in form of an array and the data is accessed using a address line and a bit line - the address line activates a particular row and the bit line carries the charge fro the particular cell it is connected to.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 101.8987341772152%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAACRUlEQVQ4y42UaY+iQBCG5///EhO/qMwmOpuYRUTAAwTvA40mBjS68RY8eCfVM03A0V0raem01U931VvVbwAQBAGitt2skctmkUgkUJAkWJaFTDqFtPCO48nDI+OMNz4ZDocwDINt1vUaFEWBpmnIZrPI5/Moaxokqch8TNNkg3xrtRocxwmhb3xyvV7Dcbvd2CDr9XpwXTfcQOtRX+4fAu/DjV6fQIVCAdVqFZPJJNz4z5Dp53K5YL/fxxw8z0OlUoGu62xQCna73VNQLGRypHzRwvF4BLnMZjO0Wq3Qud/vYzQahYf5vh8LlRsDHg4HpFIpBjAtC2a9zoRYLpcIbjd4no/lcoVKpcqEaDQaUFUVzWaTQaKpYEAKt9vtRgNhmzKCgF/vGaQzAj5yOTjuIvSgSHgED4EEICPVuJq+57HwzuczC5H/R7bZbNDpdJ4D768fPFGToGTz+Ry2bb8OpNuVigVIJRVqSUZJUWNdQvmlUooqHKr8CHi5nGEPB9ANA2VNYXl03DmGts2KnUpKkiQ2H4/HL9zQ92DV6xCEDCtsURSZytWajnJZgyzLrDajaj8FPuoebtQEZIPBANPplPmSaD+A9yXAc8IH729+GMFImIc5pE6hgo2qeA/kIH4gdQ11U7RTQuDpdIol9lnI0fXFYoHtdhs2QuxxkIsich+/kUwmoajl7xoMfjT+Vzkd0W630e32WN6NugnP9+M33KzXWK3+wnUd9o2GfA88+x7arS+QKP6BVJThf4vy3/fw1fXoe/gJt4jzCAFNktMAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The diagram shows the structure of a DRAM cell with a storage capacitor and a transistor. When the transistor is activated using wordline, the charge from capcitor flows into the bit line and can be stored or read.&quot;
        title=&quot;The diagram shows the structure of a DRAM cell with a storage capacitor and a transistor. When the transistor is activated using wordline, the charge from capcitor flows into the bit line and can be stored or read.&quot;
        src=&quot;/static/a2aa7f589e9bbedcd5ae95860a63d35d/f058b/dram.png&quot;
        srcset=&quot;/static/a2aa7f589e9bbedcd5ae95860a63d35d/c26ae/dram.png 158w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/6bdcf/dram.png 315w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/f058b/dram.png 630w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/40601/dram.png 945w,
/static/a2aa7f589e9bbedcd5ae95860a63d35d/eb2af/dram.png 954w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The diagram shows the structure of a DRAM cell with a storage capacitor and a transistor. When the transistor is activated using address line, the charge from capacitor flows into the bit line and can be stored or read.
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://electronics.stackexchange.com/questions/306002/why-does-a-dram-cell-necessarily-contain-a-capacitor&quot; target=&quot;_blank&quot;&gt;https://electronics.stackexchange.com/questions/306002/why-does-a-dram-cell-necessarily-contain-a-capacitor&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;The gate connected to the address line restricts the flow of charge from capacitor into bit line. When the transistor is activated via the address line, the charge flows into the bit line and we can see if capacitor is charged signifying 1 or uncharged signifying 0.&lt;/p&gt;
&lt;p&gt;The charge dissipates from the capacitor eventually and hence the capacitor is recharged periodically to preserve the correct state. If the level is over half, the capacitor is charged to show 1 and if it is below half, the capacitor is discharged to signify 0.&lt;/p&gt;
&lt;h2&gt;Charges and Equilibrium&lt;/h2&gt;
&lt;p&gt;When two bodies are connected by a physical medium such as wire and they have a potential difference, the charges from one body to another until a equilibrium is reached.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 551px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 45.56962025316456%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAAByUlEQVQoz22RS2sTURiG86Nc6sKVGIubCu2mWiqIVAXduFBRd0LAndSlO90I0kWxYKNO0qY0JWBpqUnMmOkFydySuWRudmYeOROmSbHv4WM48535zvs+U0jTlEkdmse8b33iY2eFD+1lyt0qaZKSrXRcQo7joGkag8EA13XRdZ2CaERRhBf42aGyXOXil2mufr/Jpa83eFR7CTHnSgxMkuR0b1nWaKCqqrTareylpGwytbHAzNZ9pmoLPG2UcC0X27ZxXJfhcJgNEo76/T5xPL5NOC3k9pN0dNM3eZ3i2i1mKotcl27zrF4i/htnfeEmL/GdcOR5HkEQZCmzyDmTfKDjO7S0DrKhIPcV/ti9EbdzGAZhgKqp6IaePQ3TGEWeVBSEEKUQASfg2d6ZWJMKg5AkGPds06IgeBiGgWmaDN0hPb1Huycja11+Gwr7SvP0L+bsRIV+SPuow+bBNjvaPrtGk/qvBgUBttvtcnB0iG1Y1JRtitI80+t3KVbneVh5ge/6GSPBKgxD/NCHFJabq1z4fI0r0hyXpVlmVxf/j/zjeI+5lQfcW3vCnfJjXm+8JTlJzpwRPIX2ej95XilRqi/xqvGGpfo7/gG4y49z/z97wAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A depiction of how unbalanced charges reach equilibrium once connected by a wire.&quot;
        title=&quot;A depiction of how unbalanced charges reach equilibrium once connected by a wire.&quot;
        src=&quot;/static/2a795d58855f9fd27716291a597c7ba3/db783/equilibrium.png&quot;
        srcset=&quot;/static/2a795d58855f9fd27716291a597c7ba3/c26ae/equilibrium.png 158w,
/static/2a795d58855f9fd27716291a597c7ba3/6bdcf/equilibrium.png 315w,
/static/2a795d58855f9fd27716291a597c7ba3/db783/equilibrium.png 551w&quot;
        sizes=&quot;(max-width: 551px) 100vw, 551px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A depiction of how unbalanced charges reach equilibrium once connected by a wire.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;Once reached equilibrium, the charge level remains same between both bodies. If n bodies with charge q and y uncharged bodies are connected to each other, the final equilibrium state will be reached with all bodies with a charge of&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;r&quot;&gt;&lt;pre class=&quot;language-r&quot;&gt;&lt;code class=&quot;language-r&quot;&gt;q &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;final&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;n &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; q&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;n &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; y&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So if one charged body with charge q is connected to 2 uncharged body, the final equilibrium is reached with each body having a &lt;code class=&quot;language-text&quot;&gt;charge = q * (1 / 3)&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Computation in DRAM&lt;/h2&gt;
&lt;p&gt;Let us look at the working of Compute DRAM. In Compute DRAM, data to be operated on are brought into data rows. A compute / operation row is pre-charged based on the operation. All rows are opened at once for charges to balance and finally the compute row is recharged to reveal the output of computation.&lt;/p&gt;
&lt;h3&gt;Bitwise OR&lt;/h3&gt;
&lt;p&gt;Consider the following example for bitwise OR:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 505px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 172.1518987341772%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,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&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The diagram above shows Compute DRAM operation for bitwise OR. The data is loaded into data rows and he compute row is pre-charged. Once opened, the charges balance as follows: for data cells with 1 and 1, the charge equalizes to 1, for data cells with 0 and 1 or 1 and 0, the charges equalizes to 2/3 and for data cells with 0 and 0 the charges equalizes to 1/3. On recharging the compute row, the 1 stays 1, the 2/3 is brought up to 1 and 1/3 is brought down to 0 effectively giving bitwise OR.&quot;
        title=&quot;The diagram above shows Compute DRAM operation for bitwise OR. The data is loaded into data rows and he compute row is pre-charged. Once opened, the charges balance as follows: for data cells with 1 and 1, the charge equalizes to 1, for data cells with 0 and 1 or 1 and 0, the charges equalizes to 2/3 and for data cells with 0 and 0 the charges equalizes to 1/3. On recharging the compute row, the 1 stays 1, the 2/3 is brought up to 1 and 1/3 is brought down to 0 effectively giving bitwise OR.&quot;
        src=&quot;/static/c2b84c10d862f03a35a577b86f6aaddd/c0cb9/or.png&quot;
        srcset=&quot;/static/c2b84c10d862f03a35a577b86f6aaddd/c26ae/or.png 158w,
/static/c2b84c10d862f03a35a577b86f6aaddd/6bdcf/or.png 315w,
/static/c2b84c10d862f03a35a577b86f6aaddd/c0cb9/or.png 505w&quot;
        sizes=&quot;(max-width: 505px) 100vw, 505px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The diagram above shows Compute DRAM operation for bitwise OR. The data is loaded into data rows and he compute row is pre-charged. Once opened, the charges balance as follows: for data cells with 1 and 1, the charge equalizes to 1, for data cells with 0 and 1 or 1 and 0, the charges equalizes to 2/3 and for data cells with 0 and 0 the charges equalizes to 1/3. On recharging the compute row, the 1 stays 1, the 2/3 is brought up to 1 and 1/3 is brought down to 0 effectively giving bitwise OR.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h3&gt;Bitwise AND&lt;/h3&gt;
&lt;p&gt;The following example is for bitwise AND:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 554px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 156.96202531645568%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAfCAYAAADnTu3OAAAACXBIWXMAAAsTAAALEwEAmpwYAAAE3UlEQVRIx42V+2+TZRTH+//4I7+YiDHRoD9IDFEXo8IPRiQaL0QSCV5CABmKhjEuEmFhGEe4OI2MSZCNy7qNlm1dt26MtrB27dqu7dq39673fsx5Xt7aboNwtmc5e97nOed8z/me85gAyuWyWiILmp9d1gN8PPY1l+f6KGYKlMolQqEQB6eO88nEN/wydY6UlqJYKpJKpVhZWVF36/U6JlEikQgut0ttuuPzbB75gBfvttFhP00lrzsKRkJstexk4902vho7SClfVPvFYpFsNvu/QfnTLJ64jx1Du3nf/DndkxcpaQXqhSp+v5/Phr/jrds7OGDpQFvWyOayxGIx8vl8a4S1Wo1qtapHklyi3XqMb62HueS4wunJHvaPddBj7yUajRKIBgmGg0rXNE0ZLJVKrQblg9vthjq44vO8MfIhm6zbaB8/xtaRnWwcbWOP5VADRS6ba8CU3K/JoURoeHkY8/Dm7R28Zt7Gz2On+Mi8m1eG3mPPULvKZ6lSJh6Pk0gk1L1MJrPWYLNoqQTDbgvD81amPTOMzFm483CUe64JIuEI4XCYxcVFAoEAS0tLBIPBVsjiRUovHsWbwEFPJ0ktSTFXUHpKS1Io6noymVR3jCq3RCjFMLwuLy+TSqfIr+hVU4lPaHqxQkHlUETOCWwRqfCaKjeLeJSLckiKJUt0qaZEJbqgMfZlr1KptPKweT1JJE/GxfXEuGtavbHagbEveZLon3amAflpxoxvAjGXyz27wWa4tXoN+WmhU5PBJ0Fe08t16uQzOcrZIoX0Cpl0hmhsmWQ6xXJMZ0AunyP+uOVWF6WRQ6GHf9Gv+Nc/e4N940f43tKJY2GWalY/HAmEKed1AmtRTZFaJJ1OK1aIUeG0yUh4Mp1UvXzC3s2Gm5t5+cY79Dmu86P1JPttRzlh7uK47Sy7re10jfWQiieVQYNiDYOrqeIN+5jw2rF7HSws+bg8fYXz039y1X6df+/f4vJMH7fnhlkKhlQaBN0ayNJKArlaqmJ1jfPHTB+X7H/j8j8EvdvIRzOgs4Zysqggy6QRksvkEZ5K15mM9onFY0hhO+1dPDe4iecHtnDNOUjvbD+/P/qL8+O9XJy7wln3JXqnr5KIay2QBe66rTfmm+SM/Tw9jl7uBx5w7O4ZDt87Sbf1Aqcs59hr/onuexeIRWNoiYR6a1paT/4xHql6rY43sIDDM8vUvEMNhHq6CmXQAjEqiZLSM5GU+iaUEegt40umhsfjwel2Us2VOTX9GxsGXuelG20MOO8wG3qAI/6A0TkrtsVpbLEZxh7ZiMfiDchCHTEqy9TcHSL9zgG+HNnHgYlOrD4b+0eOKKp0jP7KIXMn26/t4vhwF8l4QvW2RGk8wS3TxugU+aWZSY//r5Vr+uCVVdOnT6FQaIGraLNeo1frVSq1it7Tjw8KteTBb7683qQy8Yzi9XpVRE+bhcqg4JdKCylr1RqFUoFkPkWqkFa6fBdYwjVDN1hh6C3Txufz4XQ6mZmdIbwQot81wJZb23n3zqcMzg1RXimrN0ZeN4EtI0zeH+kOWTJ1WiKUAw6Hg8mpSSqZMr3z//DC8Nu8OrSVm25zA5YQ2CiA6IYRMSpd0pJD8SKNLjLoNfPFxF72TPyAbWGKSkGPUIyIc5lMoksKRBfaNEf4H2Uv/OV6jbWhAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The diagram above shows Compute DRAM operation for bitwise AND. The data is loaded into data rows and he compute row is uncharged. Once opened, the charges balance as follows: for data cells with 1 and 1, the charge equalizes to 2/3, for data cells with 0 and 1 or 1 and 0, the charges equalizes to 1/3 and for data cells with 0 and 0 the charges equalizes to 0. On recharging the compute row, the 2/3 is brought up to 1, 1/3 is brought down to 0, and 0 stays at 0, effectively giving bitwise AND.&quot;
        title=&quot;The diagram above shows Compute DRAM operation for bitwise AND. The data is loaded into data rows and he compute row is uncharged. Once opened, the charges balance as follows: for data cells with 1 and 1, the charge equalizes to 2/3, for data cells with 0 and 1 or 1 and 0, the charges equalizes to 1/3 and for data cells with 0 and 0 the charges equalizes to 0. On recharging the compute row, the 2/3 is brought up to 1, 1/3 is brought down to 0, and 0 stays at 0, effectively giving bitwise AND.&quot;
        src=&quot;/static/1753b2360fad388030a7f445ea2f1975/04abd/and.png&quot;
        srcset=&quot;/static/1753b2360fad388030a7f445ea2f1975/c26ae/and.png 158w,
/static/1753b2360fad388030a7f445ea2f1975/6bdcf/and.png 315w,
/static/1753b2360fad388030a7f445ea2f1975/04abd/and.png 554w&quot;
        sizes=&quot;(max-width: 554px) 100vw, 554px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The diagram above shows Compute DRAM operation for bitwise AND. The data is loaded into data rows and he compute row is uncharged. Once opened, the charges balance as follows: for data cells with 1 and 1, the charge equalizes to 2/3, for data cells with 0 and 1 or 1 and 0, the charges equalizes to 1/3 and for data cells with 0 and 0 the charges equalizes to 0. On recharging the compute row, the 2/3 is brought up to 1, 1/3 is brought down to 0, and 0 stays at 0, effectively giving bitwise AND.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;This is how Compute DRAM realize bitwise OR and BITWISE and but the paper goes into details or realizing more complex logic. I highly recommend reading the paper or even watching the video on Computer System for Processing Using Memory by Nastaran Hajinazar linked at the top of this post.&lt;/p&gt;
&lt;h2&gt;Why “Processing using Memory”?&lt;/h2&gt;
&lt;p&gt;As memory becomes a bottleneck and moving data becomes expensive in terms of energy, paradigms like Processing in Memory and Processing using Memory are gaining popularity among researchers to see whether novel ideas like In DRAM Processing can pave the way forward for a new avenue in computer architecture to extract more performance and influence the design of future general purpose hardware.&lt;/p&gt;
&lt;p&gt;Future seems bright for the architects as things are taking hard turn for the better.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please leave a comment and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; Fixed some typographical errors pointed out by reader Samyak (&lt;a href=&quot;https://github.com/Samyak2&quot; target=&quot;_blank&quot;&gt;Github&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/Samyak210&quot; target=&quot;_blank&quot;&gt;Twitter&lt;/a&gt;) (link opens Samyak’s profile on respective platform in a new tab)&lt;/p&gt;</content:encoded></item><item><title><![CDATA[RIDL: Rogue In-flight Data Load ]]></title><description><![CDATA[This post is based on the attack covered in the paper: This post covers the attack is brief however I recommend reading the paper to get the…]]></description><link>https://outofordercore.github.io/ridl/</link><guid isPermaLink="false">https://outofordercore.github.io/ridl/</guid><pubDate>Fri, 02 Jul 2021 17:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This post is based on the attack covered in the paper:&lt;/p&gt;
&lt;center&gt;
&lt;a href=&quot;https://mdsattacks.com/files/ridl.pdf&quot; target=&quot;_blank&quot;&gt;
Stephan van Schaik, Alyssa Milburn, Sebastian Österlund, Pietro Frigo, Giorgi Maisuradze, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida. 2019.
&lt;br/&gt;&quot;RIDL:Rogue In-flight Data Load&quot;. In S&amp;P.
&lt;br/&gt;
&lt;/a&gt;
(Link opens a new tab with PDF ~ 2.2MB)
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://mdsattacks.com/&quot; target=&quot;_blank&quot;&gt;https://mdsattacks.com/&lt;/a&gt;
&lt;/center&gt;
&lt;br /&gt;
&lt;p&gt;This post covers the attack is brief however I recommend reading the paper to get the full insight about the attack and various little details that made the exploit possible.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 621px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 58.86075949367089%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABqElEQVQoz31Tv0vDUBDOf+bgJo4iVB1EqG66uilWkI7ioLiIqIOLg5ubIiq2VBCpQ1NoC9U2TdLUpGl+vZdP7ulLf9j6wce9l7v7uLt3UeI4BpEQRRE45+h2uzBNU5z/A+V5jgPXNOFomrCKdBDq9bpgEATwPA+u66LVaiU0DENQ0zRwxkSOeXAAd3UVvXQaZjYLRYqRLZVKqFQqcBxHCFCV1WoV5XIZtVpNkPyqqqJtGPjUdWjb2+CLi4J2JjMsSK1SZVQFCf7XchSG8BgTgl4qBT+VQntnZ7hlCdma9I1yEF/v77ByOdiFArqqOlyhPMsKJwlOEicogw5pdV1PBEdF+3F0B2Iai2Qc9wUHE0iMXnJcJaPxnHHwiIFHXFAZN/DBGUrQy9ODjeK6dIONpy1s5vewm9+H0mg0REW2baPT6QhLq0G0LCv5RqtCayXj2h0Lge3j8PUU0/cLmH1cwdL9OpRerwff98WK0J/CGBMJsiL5PVmX35gwCmmMOCqeYepuHjMPy5i7XRvfMgk2m02EYfhndskdP+fnjxccv53jpHiJi+IVvgEQeYlkoMhU6gAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;An illustrative diagram of RIDL where data is wrongly forwarded based on speculation&quot;
        title=&quot;An illustrative diagram of RIDL where data is wrongly forwarded based on speculation&quot;
        src=&quot;/static/6f282a08f31baffe508219dab1d139c2/3075e/banner.png&quot;
        srcset=&quot;/static/6f282a08f31baffe508219dab1d139c2/c26ae/banner.png 158w,
/static/6f282a08f31baffe508219dab1d139c2/6bdcf/banner.png 315w,
/static/6f282a08f31baffe508219dab1d139c2/3075e/banner.png 621w&quot;
        sizes=&quot;(max-width: 621px) 100vw, 621px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: An illustrative diagram of RIDL where data is wrongly forwarded based on speculation
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Value Prediction&lt;/h2&gt;
&lt;p&gt;As an aggressive method to increase Instruction Level Parallelism, modern processors have started speculating on value for a particular long latency cache miss using the program counter and the data address. There are competitions around value prediction - most notable one being the &lt;a href=&quot;https://www.microarch.org/cvp1/cvp1online/contestants.html&quot; target=&quot;_blank&quot;&gt;Championship Value Prediction (CVP)&lt;/a&gt; (link opens a new tab) where competitors try to predict value for loads for varying storage budget. André Seznec, the branch prediction ninja as also the winner of the first CVP competition for all the storage budget - 8KB, 32KB and Unlimited Storage (the last was a join effort by André Seznec and his colleague Kleovoulos Kalaitzidis, both working in IRISA/INRIA at the time of the championship).&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 22.78481012658228%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAwElEQVQY032QyaqFQAxE+/8/zoXgRty4UHGe56EeJ+Djchc30HQlnVSq2rVtq2EY1HWd3ed56jgOw2VZal1X7ftuZ5omjeNoPeB5nu2uqkp936tpGrksywxQrOvayLZtswUQEmCI7/u2RZBTg4Q8z3MhrCgKOQae59F3oGJZFiPyfV9hGBrmfM5c1/VfR4xL01RxHCuKIlPIA7ZQniSJDdH4KkcVVnGEA3qDIJDnecbj9CNofv+NRdgi/w7e3q/4A1btgT/+s7NVAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A schematic of a value predictor that takes the value of Program Counter and Load Address to predict a value and also output a confidence for the predicted value being right.&quot;
        title=&quot;A schematic of a value predictor that takes the value of Program Counter and Load Address to predict a value and also output a confidence for the predicted value being right.&quot;
        src=&quot;/static/b3a5ad134e1f0ba3a2242319e9a11aad/f058b/value_predictor.png&quot;
        srcset=&quot;/static/b3a5ad134e1f0ba3a2242319e9a11aad/c26ae/value_predictor.png 158w,
/static/b3a5ad134e1f0ba3a2242319e9a11aad/6bdcf/value_predictor.png 315w,
/static/b3a5ad134e1f0ba3a2242319e9a11aad/f058b/value_predictor.png 630w,
/static/b3a5ad134e1f0ba3a2242319e9a11aad/b2982/value_predictor.png 729w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A schematic of a value predictor that takes the value of Program Counter and Load Address to predict a value and also output a confidence for the predicted value being right.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;Although modern processors don’t have buffers dedicated to hold the history of loads and complex prediction units, what they do try to do is predicatively forward data in store buffer and line fill buffer to outstanding loads.&lt;/p&gt;
&lt;h2&gt;Line Fill Buffers&lt;/h2&gt;
&lt;p&gt;Line fill buffers are structure on top of caches that is used to optimize loads and stores - in case of multiple loads to same address, it squashes the loads into a single request and broadcasts the data back on arrival. In case of outstanding stores to same address, line fill buffer overwrites the old value and sends a single store request. Line fill buffer also requests and stores data that bypasses entire cache hierarchy - data that won’t be used soon or is sensitive in nature, and need not be cached.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 605px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 62.0253164556962%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABdUlEQVQoz2WT6arCQAyF5/2fTEH9IbjiWvet4m7V9sgXSJnrDQzpZJKTk6WhKAoh6PF4rH6/r8FgoDzPzbZcLjWfz7VYLMzvcrmo1+tpNpvpfD7r8/mo2+1a3Ha7VXBAHkajkRqNhj1if71earfbqlQqarVa5nc6ndRsNlWv15WmqfnwVq1WtVqtFJwd8ng8LHOWZXK5Xq+WiECX3W5nYC4wBQwxhn4QAKFOaYChSRQLd0DRz+dT9/u99Am/jvQPDUs0xwNut5sxnU6n5kf5MCWpVxC8TBjS/MlkYvQZxnq9tkHBGADuSZLYUND4HQ4HbTabcrAB506no/f7bSCIl8ygvDceBADv6P1+bzY2wFsW6AXZCHZGHNjCfDgc2jeDwY+7+2DjjbiSoffPM5DZv3/F7QzreDz+sZWA8ZRpMr2CCS1wp3gLqATmHIYU+5Rr40IZLCzLDYuYQcyOxa7VamXP/wH6BVYMyJsdv8XfDIHfDba/gF9NYZYNMFxtBQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A diagram showing how line fill buffer squashes loads to same address and writes only the most recent value to the address with multiple outstanding store.&quot;
        title=&quot;A diagram showing how line fill buffer squashes loads to same address and writes only the most recent value to the address with multiple outstanding store.&quot;
        src=&quot;/static/ef26398e9675bc296eae6a32d9b72391/90cbd/lfb.png&quot;
        srcset=&quot;/static/ef26398e9675bc296eae6a32d9b72391/c26ae/lfb.png 158w,
/static/ef26398e9675bc296eae6a32d9b72391/6bdcf/lfb.png 315w,
/static/ef26398e9675bc296eae6a32d9b72391/90cbd/lfb.png 605w&quot;
        sizes=&quot;(max-width: 605px) 100vw, 605px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A diagram showing how line fill buffer squashes loads to same address and writes only the most recent value to the address with multiple outstanding store.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Speculative Forwarding&lt;/h2&gt;
&lt;p&gt;In speculative forwarding, the store buffer and line fill buffer try to match the lower bits of address with the outstanding stores and if and when a match is found, speculatively forward the data to the process. This being speculative state, has no impact on the correctness of program in case of mis-prediction where the pipeline is flushed and restarted from the point of speculation. What this doesn’t take into account is the micro-architectural traces it leaves behind in cache that can be surfaced using timing analysis.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 347px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 51.89873417721519%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABRUlEQVQoz4WSW6+CMBCE+///GC/eIl5BQCFeA/GBoEaEMd8mNSc+eJpstrvdTqez6w6Hg4bDoRaLhWazmXksDEPz8/lcy+XSjP14PFae54qiyOLtdqvNZmN57ruqqhTHsXa7ndI0tQIuEHubTqeWy7LMHjmfzzqdToLM9Xq1mLrL5SInSX3f6/V6qW1bPZ9P8xi5pmkUBIHu97vlWEVR2OOAwhQgMFjOb36t4/Gorus+cVmW9r3JZKLBYKAkSeSJGeAvY8HkO4c06Ixcfhngf+wooiGPx+OTQztkGI1GxpTv+x84dCL4xZKLAHqt9/u9dZZGwRAJvO4Ofegi4sKEgvV6rdVqZXs8Med0GN18x8nBDnAwkMCBzgWEpYBDD8oe7wF5kJllRKhhDrkHOF8ndtC83W42Ft/m894zQnVdm8fI/90zcm+eYuyfj++m2gAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A schematic that shows how processors speculate two addresses might me same based on just the lower bits&quot;
        title=&quot;A schematic that shows how processors speculate two addresses might me same based on just the lower bits&quot;
        src=&quot;/static/da2779c4b9d00a408bb6f0732529f357/39e45/speculative_forwarding.png&quot;
        srcset=&quot;/static/da2779c4b9d00a408bb6f0732529f357/c26ae/speculative_forwarding.png 158w,
/static/da2779c4b9d00a408bb6f0732529f357/6bdcf/speculative_forwarding.png 315w,
/static/da2779c4b9d00a408bb6f0732529f357/39e45/speculative_forwarding.png 347w&quot;
        sizes=&quot;(max-width: 347px) 100vw, 347px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A schematic that shows how processors speculate two addresses might me same based on just the lower bits
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: In reality, the speculation uses lot more lower bits than shown above but the concept remains the same.&lt;/p&gt;
&lt;h2&gt;Rogue In-Flight Data Load (RIDL)&lt;/h2&gt;
&lt;p&gt;In RIDL, the attacker can extract secrets from line fill buffer in a way similar to that of the meltdown attack. Consider the following code:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;char&lt;/span&gt; device&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;4096&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;ptr&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
device&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;ptr &lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;4096&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let ptr be any valid pointer in attacker’s user space. Assume value at address pointed by ptr is 2. If we run the following code ensuring device is not cached and perform a timing analysis, we might find an anomaly as such:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 53.16455696202532%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACEElEQVQoz52TTUsbURSG8wdbtUUyqZFOIHGjopsuTI1tUxddFIJgWkRsoVAKLly5aqHQhesQurAxiWLUJDMxH87cyWQyc+cpM0mqbTelB87m5dyH93zciO/7SCmZhGVZSM8j0H0p/z19P3wfCQDNZnNE832swYD/jQAacV03dDWJzvk54vQUp9fDqlSwymX61Sp2uYytaViNBuLkBDuoOTujX6lgVqthV6FD0zRpt9uhu8B0fWuL1vQ02uEhuqoiFAUzHsecmqKzu0srl8OcmRlpc3OIaBR9YYGhECNgqVTi+PgYeyx03rylH43S+fIZsbiITCRwUymGikLn3R7dfB43FhtpySSeqmKsrOCOu4wUi0UCaLFQCIXuzg5mLEb/2xHm8jLDRAIntYCtRDHef8Da3WMQU3BSKZxkkqGq0ltdvQUG7Yap66Fws72Nef8eXz9t0U08xo89YjgfhwezFF6v8/3VGjycxZ2P48bjSEVBLC3h2fYI+NuWghnu73OZXiP/cZ2L7AZW9iXX2Rf0nz7nIL/GQe4JIv2MxkaGRiZDM53mdHMT0evhSUkkvLfxDXnBxl2XlmVRLZ9xpWkMIcyeM+DyqsmPUpkbx8GWMqy9sW1qmsZ5rcZ1q3XrcAL967Y8D2EY2MGMxjXSdX+dyZ8RuQubuL37exzH4aJWo16vI4TAMAx0Xac1nvnkl0zyJycsDYoXk3L8AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A diagram that shows timing analysis for array access. It is observed that not only data at address 2 * 4096 (which is expected given data pointed by ptr is 2) is cached but also data at 8 * 4096&quot;
        title=&quot;A diagram that shows timing analysis for array access. It is observed that not only data at address 2 * 4096 (which is expected given data pointed by ptr is 2) is cached but also data at 8 * 4096&quot;
        src=&quot;/static/5e9cf8a73416fcf828aef7d4834abc97/f058b/timing.png&quot;
        srcset=&quot;/static/5e9cf8a73416fcf828aef7d4834abc97/c26ae/timing.png 158w,
/static/5e9cf8a73416fcf828aef7d4834abc97/6bdcf/timing.png 315w,
/static/5e9cf8a73416fcf828aef7d4834abc97/f058b/timing.png 630w,
/static/5e9cf8a73416fcf828aef7d4834abc97/bca35/timing.png 683w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A diagram that shows timing analysis for array access. It is observed that not only data at address 2 * 4096 (which is expected given data pointed by ptr is 2) is cached but also data at 8 * 4096
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The index is scaled by a factor of 4096 as to prevent anomalies due to hardware prefetcher bringing neighboring pages into the cache.&lt;/p&gt;
&lt;p&gt;We observe two addresses being cached however we expected only one of them to be cached. The second value is a result of processor speculatively forwarding the value from line fill buffer whose address have the same corresponding lower bits that of address in ptr.&lt;/p&gt;
&lt;h2&gt;Exploits&lt;/h2&gt;
&lt;p&gt;RIDL is hard to exploit as data in line fill buffer only stays there for a small time and attacker has a very small window to read the data. In the exploit outlined in paper, the attacker can only manage to read some bytes per day from a victim that is continuously loading same data in a loop. However we see, such an attack is possible and speculation can have an adverse side effects often leaking states via microarchitectural side channels which otherwise shouldn’t be accessible to the user.&lt;/p&gt;
&lt;p&gt;Again I urge the readers to go through the paper to understand the intricacies of the exploit. The RIDL paper also does a great job explaining the microarchitectural implementations in Intel processors which is wonderful.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please leave a comment and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[M1RACLES: M1ssing Register Access Controls Leak EL0 State]]></title><description><![CDATA[This bug in Apple M1 was discovered by Hector Martin (link opens a new tab) during his research for adding GNU/Linux support for Apple M…]]></description><link>https://outofordercore.github.io/m1racles/</link><guid isPermaLink="false">https://outofordercore.github.io/m1racles/</guid><pubDate>Fri, 02 Jul 2021 16:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This bug in Apple M1 was discovered by &lt;a href=&quot;https://twitter.com/marcan42&quot; target=&quot;_blank&quot;&gt;Hector Martin&lt;/a&gt; (link opens a new tab) during his research for adding GNU/Linux support for Apple M1 through his &lt;a href=&quot;https://asahilinux.org/&quot; target=&quot;_blank&quot;&gt;Asahi Linux Project&lt;/a&gt; (link opens a new tab). His website discussing this bug in detailed is titled &lt;a href=&quot;https://m1racles.com/&quot; target=&quot;_blank&quot;&gt;M1RACLES: M1ssing Register Access Controls Leak EL0 State&lt;/a&gt; (link opens a new tab). If you are familiar with privilege levels and register accesses, you an directly head over to Hector’s blog and read the much more detailed and in-depth review of the bug he found. Please do go check out his awesome awesome work after reading this article.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 550px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 55.69620253164557%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB6klEQVQoz31SzW7TQBj0kyEOCLUCSiWEeig0xOJHiEpQUA65gAQn3gC4Uw69wKE5IdJSVCkltLWIBUkAg0hqm+zasR3bazv2oN3IoUlLRxpptZ6dnfnWEqEELfoDn80vaJhfsW+o0OgvBH6AwWBwhP7AR9/rQzFV7BkN7BsN1HUFXUdHz+xBIjbFsvIIF7dvYKF2BzMflvBCe4WTQGMbV3bu4fy2jEu12zi9sYC1gwpih0GifYqbu2Wcq17DXKWI2a0Cnn97KQ4O0yGyLBszzVKx3wspivUSLrwtYr4i4+zWVax11hH1GSTT+gO5XsLs+wLmN6/jzOYinn2fNMyRG5LIwmLtLmY2ljBXlXGqehmrv98g5oYHRMeK8hiFnQe49akshKs/X09UzBPmIIGFsvIUy3sPcV95AvljCevGO4S2D4kQgiiL4ScBgiREMGTwggFs2walFGmajo0YY7AsC67rgiUR4jRBnMaIhvHoIkJGhseBJ+p2u4LcxHEcaJomLjkqxj/DXMDnc/gBcnAz0zQFwzCcGMH0YwlDXi0XHU6XV2y321BVFc1mE61W679tJhJ6njf6aX1frPmMOHk6wzDQ6XREdV3XRXVO13XGOo/T88R36bgK07WnEScJ/CAEiyKEjJMhCEKx/xfK/CQ0LO5PWgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A Schematic diagram of M1RACLES showing two processes transmitting data to each other over a covert channel&quot;
        title=&quot;A Schematic diagram of M1RACLES showing two processes transmitting data to each other over a covert channel&quot;
        src=&quot;/static/2951894ce619875d9a86dd9be12c1e87/dd45a/banner.png&quot;
        srcset=&quot;/static/2951894ce619875d9a86dd9be12c1e87/c26ae/banner.png 158w,
/static/2951894ce619875d9a86dd9be12c1e87/6bdcf/banner.png 315w,
/static/2951894ce619875d9a86dd9be12c1e87/dd45a/banner.png 550w&quot;
        sizes=&quot;(max-width: 550px) 100vw, 550px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A Schematic diagram of M1RACLES showing two processes transmitting data to each other over a covert channel
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Privilege Levels in ARM-v8&lt;/h2&gt;
&lt;p&gt;Hector’s blog goes into details of the bug but I’m writing this from the perspective of myself, a complete beginner, and summarizing the concept on the way up. First I would like to discuss EL0 - the E in M1RACLES. ARM-v8, like any other architecture, comes with a set of privilege level that dictate the capabilities of the program running at that level. The different levels are as shown below:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 383px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 70.88607594936708%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABQAB/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAL/2gAMAwEAAhADEAAAAWiViEs2yv/EABkQAAIDAQAAAAAAAAAAAAAAAAABAhEiEv/aAAgBAQABBQJvPUiySzSKP//EABgRAAIDAAAAAAAAAAAAAAAAAAEDAhAy/9oACAEDAQE/ASqbM1//xAAXEQEAAwAAAAAAAAAAAAAAAAACEBMx/9oACAECAQE/AbCNj//EABgQAAIDAAAAAAAAAAAAAAAAAAEQAAIx/9oACAEBAAY/AjNui//EABoQAAIDAQEAAAAAAAAAAAAAAAABESExQbH/2gAIAQEAAT8hc33jwVPsN5eEHemKijZ//9oADAMBAAIAAwAAABD4D//EABcRAAMBAAAAAAAAAAAAAAAAABAhQWH/2gAIAQMBAT8QeRo//8QAFxEAAwEAAAAAAAAAAAAAAAAAARAhQf/aAAgBAgEBPxASbX//xAAdEAEAAwABBQAAAAAAAAAAAAABABFBITFxgZHR/9oACAEBAAE/ECpRBO0Z4A19girg7K00FXOoz0XWJUq8tz//2Q==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A diagram showing the different privilege levels of ARM architecture with EL0 on top with least privilege where user application run, followed by EL1, the operating system level, followed by EL2, the hypervisor level, and finally EL3 the firmware level.&quot;
        title=&quot;A diagram showing the different privilege levels of ARM architecture with EL0 on top with least privilege where user application run, followed by EL1, the operating system level, followed by EL2, the hypervisor level, and finally EL3 the firmware level.&quot;
        src=&quot;/static/1a206691875a56234522d0c864146941/411a4/levels.jpg&quot;
        srcset=&quot;/static/1a206691875a56234522d0c864146941/ff44c/levels.jpg 158w,
/static/1a206691875a56234522d0c864146941/a6688/levels.jpg 315w,
/static/1a206691875a56234522d0c864146941/411a4/levels.jpg 383w&quot;
        sizes=&quot;(max-width: 383px) 100vw, 383px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A diagram showing the different privilege levels of ARM architecture with EL0 on top with least privilege where user application run, followed by EL1, the operating system level, followed by EL2, the hypervisor level, and finally EL3 the firmware level.
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;&quot; target=&quot;_blank&quot;&gt;https://developer.arm.com/documentation/102412/0100/Privilege-and-Exception-levels&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;As we go down the stack, the privilege increases as we gradually go closer to the hardware. These privilege levels guard memory and register access and trap invalid accesses.&lt;/p&gt;
&lt;p&gt;What EL0 means is that any user land program can use this functionality and hence M1RACLES is possible from a userspace program.&lt;/p&gt;
&lt;h2&gt;Missing Registers&lt;/h2&gt;
&lt;p&gt;Apple M1 contains a two bit ARM System Register encoded as s3&lt;em&gt;5&lt;/em&gt;c15&lt;em&gt;c10&lt;/em&gt;1 that is accessible across all the processing core of the processor. In addition to this, it is EL0 accessible for both reads and writes and hence can be used to transmit data across processes.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 188px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 175.31645569620252%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAjCAYAAACU9ioYAAAACXBIWXMAAAsTAAALEwEAmpwYAAADbElEQVRIx62W6UorQRCF8/6PISKi+EMQVBQXxH3fd000ezKZzJLJYmJdvpLKneSqmcAtaDrd033mVJ2qmqRERD4/P8Xsp99J91K2cF1Xzs7OZHt7W9crKytSr9d1/+rqSvb29mRra0ufPT8/y+npqe69vr5Kt9uVi4uLQcB8Pi9LS0uyv7+vIEdHR1IoFOTm5kYuLy/l5eVFTk5O9BlnAAXk7u5OwjBUYAUcptzr9fRSq9WSWq0mvu/r84+PD2k2m1IsFqXRaEi73dYzeMEZw+kzZAYMy2Qy8vj4KKVSSXK5nLJjj/n9/V3ZEYb7+3v1gDMjAR8eHuTp6anvCnswZh9g7O3tTbLZbH/N/VRcLQMEZHd3V6ampnRmHyDYTUxMqGC4u7m5qWCA/gp4e3uroNVqVcXCfeIKQ2JIKHCVM+bNACDu2sAINIdhxNtRm0GsWKfTaQXCZeLJi/oxHJW0Sc3uDjDEHMdRNnEjLYiZhQS3LZ1In7ilhhWmUmZnZ2VxcVE2NjZkbm5OZmZmdMzPz6uLy8vLMj09rYUwOTkpCwsLsra29j1Dz/M088kzAk91WAqRdzxHKPbOz8+1Wqik6+vrv4C/xRDmBB2VcdNmqsa8+tbleILHQ3BwcKAsUB11URqGzIeHh/2zjH9UHmbKIdw2I8mJV6VS0TWNwV48oPJvgLQ0lOx0OnJ8fCzr6+tSLpf1OR1pLEDMBLGGgTBWbogyHLLUqERFEFLFYggwL8BdlI2iKBlDcwVGuMhF2JIiiEKiA0pdjwSMH4CZgdPyV1dXtZowxDGBRgIaCIlNE0AYLtOBSG4YwjbeGBIxpG7JNwaKA4IYVBIu84Eai6EpCzCxtOZBYvPlS8zQAFHYOgqi0DAs2e0lY6kMQxoueyiK26QNxkxMxwIk73CNnGPAzmaGsU8sCuxwmzjyrbEZUJoGio8VQ/KQMqOWmWFlcQU8/k1OxBBFLU4oSrpQghgx/bZShnvhcC0DEgSBlhyMEQq2Ozs7A9/k/p+lnwaGazCCKWliMyOdzmjnjpNJyX82BcwVy1Kt1aXiuFIsV6Xb7YkXhFKqOLrXbnckmy+J43rier44LmdrkiuUpeq44vmh+EH49c8BmmEjkroX6CYAUbMlQdjQfeZ2p6O/eQln6n7wtfZDiaKmeP7XXRj+AS/ma7RKlwYwAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The diagram shows the schematic of the two bit register s3_5_c15_c10_1 with possible states as 00, 01, 10 and 11&quot;
        title=&quot;The diagram shows the schematic of the two bit register s3_5_c15_c10_1 with possible states as 00, 01, 10 and 11&quot;
        src=&quot;/static/6299d687369846f5378832673df0bdb2/4dcb9/reg.png&quot;
        srcset=&quot;/static/6299d687369846f5378832673df0bdb2/c26ae/reg.png 158w,
/static/6299d687369846f5378832673df0bdb2/4dcb9/reg.png 188w&quot;
        sizes=&quot;(max-width: 188px) 100vw, 188px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The diagram shows the schematic of the two bit register s3_5_c15_c10_1 with possible states as 00, 01, 10 and 11
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Transmitting Data&lt;/h2&gt;
&lt;p&gt;How do you use this two bit register to transmit data? Well you make a 2 bit data transfer protocol. The diagram below shows one such possible protocol:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 325px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 73.41772151898735%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB2UlEQVQ4y52UB6siQRCE9///IkEQQREj5pxzdt1dI4Y6vn4sCHePu3sN7cx2z9TUdPXo7Pd7bTYbnc9nMXddV57nabvd2hgEgd7vtzDGv7mzXC5VrVaVTqeVTCaVSqU0GAwUj8cVi8Xs+3K5/BMg5tzvd63Xax2PR51OJxsfj4d+ag5g0+lUlUpF9Xpdq9VKh8PBkrvdTpFIROVyWdFoVO12224D60QioVqtZrFisWgxcg41A7Db7ZqPx2P5vm+Ar9fLrnu73Yz98/m0OXWlvtfr1WrPepy5ww+As9lMo9HIAGGGAdLpdEwsRKLeACHicDi02G9XZjGLAGs0GnYKGzDmhULBvFQqKZvNqtfr2Tpi7MFgzm1MZcBYAMv5fK5Wq2UH/FgUNiPEYrGw0xEJ1qFR8Hw+bwJMJhMTjuLTDcQRrNlsWqkg5JAAhABKA04stLBexKkpdWOOINQdZ2+Yd0hQeByVYRAyDJv1v65M28AIEABpE6iHxgGZTMYcJrwieo49CJXL5UwsygF7B5oA0BL9ft8SXCM0eo7DaCVuw4F8oyxkeATsZR0x5/ONhi3w+WfwnX2Xcz4Tf5ozup6v7d6V55/kByd5fiA/OOtw9OQefR3cr/FyueoXFb5wMJwO368AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Each state of register corresponds to a transmission state - 00 means sender is ready to send, 01 is used by receiver to acknowledge receiving sender&amp;#39;s states. 10 means sender is sending binary bit 0 and 11 means sender is sending binary 1&quot;
        title=&quot;Each state of register corresponds to a transmission state - 00 means sender is ready to send, 01 is used by receiver to acknowledge receiving sender&amp;#39;s states. 10 means sender is sending binary bit 0 and 11 means sender is sending binary 1&quot;
        src=&quot;/static/09a3452acc6c9b5e6a5a88071a717e3a/ff46a/states.png&quot;
        srcset=&quot;/static/09a3452acc6c9b5e6a5a88071a717e3a/c26ae/states.png 158w,
/static/09a3452acc6c9b5e6a5a88071a717e3a/6bdcf/states.png 315w,
/static/09a3452acc6c9b5e6a5a88071a717e3a/ff46a/states.png 325w&quot;
        sizes=&quot;(max-width: 325px) 100vw, 325px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: Each state of register corresponds to a transmission state - 00 means sender is ready to send, 01 is used by receiver to acknowledge receiving sender&apos;s states. 10 means sender is sending binary bit 0 and 11 means sender is sending binary 1
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;p&gt;Let us now see how to send binary data “101” using this protocol between to processes:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 140.50632911392407%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAcCAYAAABh2p9gAAAACXBIWXMAAAsTAAALEwEAmpwYAAACiElEQVRIx4WW6Y7CMAyEef8n4y9CQggQiPu+r5YWvPosTTatWoiUTUljezxjp9v4fD7GYNVzlmX2fD7t8XjY7Xbzlb0kSXzViJ9l2+BPnuc2mUxsPp/b+/3236yn08mazaaNx+PgQE6u16v1ej3bbDZ+Vk7dIRu73c4nz7zQIQxAyXi9XgWHvNvv92HPHXLocrn44TRNPT3m8XgM6d7vdw+AIeirRkgZJ7PZzNbrtUcEJfxtt1ufq9XK90gfNKzYEAwQBOJ3IeXyEIcMDmOofRDjFL7htt/vO5dCXusQR6gqVIfDwVeoYF/B2u22dTodD+QOBRl+WM/ns7+EV6WJE9JnP+aQFFVOgUM2gA6PGE2nU3cCR6pHRFE1iIo6YSpTBiliUJsIgmCgpFRALrXlvFCH6pB4xkgwjDljgpqMqAqCDYfD76LENUfqIFONwjG/2ccxFEEZNLlDIWIVGhmS7mKxcDQYIRLvJEAlh+pjGQIfnjAkEDWoOoypKNMTVBYypjZJZblcujBCRxCVFAGqWrBWZSFTi1E2qlP4U2vSLQSgW9gLCOMpZYUgvrKksNoP5zgdjUZOGUBq6xAjDAaDgRuRPiWim6lc4ALkonCYFJAegcQVRqwEKPNclVnoZaIySQfOeKZkcMwzF4NQx9d+fA/+vL5wjCN1gwpcJSUQDNqyUDblWXczx+9wghDMVqvl61eEpEi56CbXRF2oUbGDVjeSq0xEVKSA2dRngPRoQ5CoDUmx7psSREHdbrfrty4K81uCEIAJf2oziYJjnvUlVIvWdgoOaT/1uD4BSlmC8Z7C5iw2tZ0ChzjGWJxBwc+Uq2pKakrReP7/u5LbM0ktJRAtmST2yjL7AyN3gqwtpwmmAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The sender first sets register state to 00 indicating he is ready to send. Receiver ACKs this by writing 01 to the register. Sender sends 11 implying bit 1. The receiver ACKs this with 01. The sender sends 10 next indicating bit 0. The receiver ACKs with 01. The sender sends 11 next indicating bit 1. The receiver ACKs this with 01. The sender finally writes 00 indicating transmission has finished and is ready for next transmission. The receiver interprets the message received as 101.&quot;
        title=&quot;The sender first sets register state to 00 indicating he is ready to send. Receiver ACKs this by writing 01 to the register. Sender sends 11 implying bit 1. The receiver ACKs this with 01. The sender sends 10 next indicating bit 0. The receiver ACKs with 01. The sender sends 11 next indicating bit 1. The receiver ACKs this with 01. The sender finally writes 00 indicating transmission has finished and is ready for next transmission. The receiver interprets the message received as 101.&quot;
        src=&quot;/static/9c0dc8a2abef1a12cbb917dbedc27bb9/f058b/transmission.png&quot;
        srcset=&quot;/static/9c0dc8a2abef1a12cbb917dbedc27bb9/c26ae/transmission.png 158w,
/static/9c0dc8a2abef1a12cbb917dbedc27bb9/6bdcf/transmission.png 315w,
/static/9c0dc8a2abef1a12cbb917dbedc27bb9/f058b/transmission.png 630w,
/static/9c0dc8a2abef1a12cbb917dbedc27bb9/748f4/transmission.png 656w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The sender first sets register state to 00 indicating he is ready to send. Receiver ACKs this by writing 01 to the register. Sender sends 11 implying bit 1. The receiver ACKs this with 01. The sender sends 10 next indicating bit 0. The receiver ACKs with 01. The sender sends 11 next indicating bit 1. The receiver ACKs this with 01.  The sender finally writes 00 indicating transmission has finished and is ready for next transmission. The receiver interprets the message received as 101.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;How serious is this vulnerability?&lt;/h2&gt;
&lt;p&gt;This vulnerability has very low impact as it can only send data between two cooperating processes. What is interesting is the existence of this vulnerability in Apple A14 processor - &lt;a href=&quot;https://twitter.com/_saagarjha&quot; target=&quot;_blank&quot;&gt;Saagar Jha&lt;/a&gt; (link opens a new tab) has a nice tweet that demos this vulnerability you can find here- &lt;a href=&quot;https://twitter.com/_saagarjha/status/1397515649530830852&quot; target=&quot;_blank&quot;&gt;https://twitter.com/&lt;em&gt;saagarjha/status/1397515649530830852&lt;/a&gt;. Could this mean this covert channel can be used by apps to send user tracking information amongst each other? Probably not as outlined by Hector himself in &amp;#x3C;a href=”&lt;a href=&quot;https://m1racles.com/#ios&quot;&gt;https://m1racles.com/#ios&lt;/a&gt;” target=”&lt;/em&gt;blank”&gt;iOS section of M1RACLES site&lt;/a&gt; (link opens a new tab). The only reason this is a vulnerability is because it goes against the principles of operating system by adding a cover channel for Inter Process Communication. Between cooperating processes, the data can be transmitted at 1MB/s as seen in Hector’s &lt;a href=&quot;https://youtu.be/hLQKrEh6w7M&quot; target=&quot;_blank&quot;&gt;M1RACLES demo on YouTube&lt;/a&gt; (link opens a new tab) where the sender is streaming video data to a receiver and receiver then playing it.&lt;/p&gt;
&lt;h2&gt;Any mitigation in sight?&lt;/h2&gt;
&lt;p&gt;As this access to registers is possible across cores, there aren’t any straightforward mitigation to implement. If it was across a single core, Hector mentioned the idea of clearing the register on context switches making them an ineffective side channel. If you are running in a virtualized environment, the hypervisor traps access to the register and hence this cover channel disappears. Only on bare metal is this possible.&lt;/p&gt;
&lt;p&gt;Again in words of Hector himself, this side channel is almost inconsequential compared to the cache based side channel that can transmit data across cooperative processes much more effectively.&lt;/p&gt;
&lt;p&gt;This is the link to Hector’s thread where he first disclosed this vulnerability - &lt;a href=&quot;https://twitter.com/marcan42/status/1397387066044911618&quot; target=&quot;_blank&quot;&gt;https://twitter.com/marcan42/status/1397387066044911618&lt;/a&gt; (link opens a new tab). It is a worthwhile read I promise with people chipping in their opinion and possible enhancement to data transmission protocol for better throughput.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please leave a comment and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Power Analysis]]></title><description><![CDATA[In our last few posts we looked at Timing Analysis and techniques such as Flush and Reload, and Prime and Probe that exploit timing…]]></description><link>https://outofordercore.github.io/power-analysis/</link><guid isPermaLink="false">https://outofordercore.github.io/power-analysis/</guid><pubDate>Fri, 02 Jul 2021 15:00:00 GMT</pubDate><content:encoded>&lt;p&gt;In our last few posts we looked at &lt;strong&gt;Timing Analysis&lt;/strong&gt; and techniques such as &lt;strong&gt;Flush and Reload&lt;/strong&gt;, and &lt;strong&gt;Prime and Probe&lt;/strong&gt; that exploit timing difference to deduce operations of victim.&lt;/p&gt;
&lt;p&gt;Looking at Timing Analysis, we observe how we exploit the lack of uniformity within the system to observe the victim. In timing analysis, we exploit the timing difference between loading data from cache and loading data from main memory as a device to observe bits of program victim is executing. If this execution pattern depends on some secret held by the victim, we can infer details about the secret from the patter on execution of victim thread.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 512px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAA7EAAAOxAGVKw4bAAACyklEQVQ4y52Ua0hTYRjH/+ecHbfp5izzPjdjSa2L1jRzkVpmroTUjDQS8tIHU8gumoWXtNvSIEIKpITAwqiIoA8JYQ2CCKKLfQrDL2U2L6yIaKHT7YkzNznIpqvny/ucl+f839/7XF4gMJMBeMKySGAY9zeDf7C5YJmU45QKCULk3OGIcOkPAEpRDPO/wmzxbs1wSb52UPC9e74A/AnkAYgWHI51b1U/7M6g/QVaC1E/RgcKOU/cagCZC4l6T80HcFxwiCpwoSHJ8vVtEaWnRD/q6tiKxqMGiSfuPICUxSjdFqrkVSt1oVgaJj049qHQMTJQRmv1sd0bDTr8GW7kt2yKFw4PDkhMRKrYszPuG42X07tnhyiIl5h7u4pARCDqRSBiHMcxSFCHeHPU8PRuFpHz1NTQ61rKMmqGzU3Ztzovmm5HRypeAIgXAXC+Fdm5A5eUFmmtNFFOM6ONTppocTmsTeQca6bxj3WUZoh7M5tj8ku3DEAVz7MamdR949b+e9uIftY7JkdaXc7xMzRtbXbStHnqevsuQWW76N81AMpFOZ0lAlCSpA8T1vC6qlU2clQS2U846VcDzViPEdlaZmyD9ZS6PsZC9AD2L6e9uU4EUAhA7o+2raYskXo6ja6rbRuo704GuUYOuGjyrPPaJTedSQiScCzHsszCRYkMlyKIZ7UAjAAMADbnZEQNka2Svn+qo5TkWAtRH4heiceO8VsUYW6DePFUQXqkYsVnslfTlXO5Al3uvNYKeJYjPKumqVZvp981tC9/3f3ZHnRXViBSBdrQxQBOevzkm5fT6OXjvKlQVYwuXh0DY6raez2zkJJASLMZxt1GguXc6EijHZlRz0V03p+XA0gP6OpEPUjSh0ETF1xaYFILKjnewvkQWDSPjFzGSVRKHnIZ1x7Es+91WgUKTGpGESKZ/9wFXBQvSRuAvT4eVb/2F7tT64g3/06pAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A lightning icon representing power&quot;
        title=&quot;A lightning icon representing power&quot;
        src=&quot;/static/155b1790b33ed2a86c8a1ef1d741a776/01e7c/power.png&quot;
        srcset=&quot;/static/155b1790b33ed2a86c8a1ef1d741a776/c26ae/power.png 158w,
/static/155b1790b33ed2a86c8a1ef1d741a776/6bdcf/power.png 315w,
/static/155b1790b33ed2a86c8a1ef1d741a776/01e7c/power.png 512w&quot;
        sizes=&quot;(max-width: 512px) 100vw, 512px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A lightning icon representing power
&lt;br/&gt;
Source: Icons made by &lt;a href=&quot;https://www.freepik.com/&quot; target=&quot;_blank&quot;&gt;Freepik&lt;/a&gt; (link opens a new tab) from &lt;a href=&quot;https://www.flaticon.com/&quot; target=&quot;_blank&quot;&gt;Flaticons&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Energy and Execution&lt;/h2&gt;
&lt;p&gt;Modern microprocessors are complex feat with multiple physical cores and multiple different functional unit - Arithmetic and Logic Unit (ALU) to process integers, Floating Point Unit, Single Instruction Multiple Data (SIMD) units such as the ones that operate via AVX Instructions in x86 architecture.&lt;/p&gt;
&lt;p&gt;With different circuits having different complexity, they have different power draws. A careful observer with a device that can accurately measure power consumption can deduce information about runtime of victim.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 77.84810126582278%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAIAAACZeshMAAAACXBIWXMAAAsTAAALEwEAmpwYAAADmUlEQVQozy3S/U8bdQDH8f5byg9bImPLTDbM5ozRH1zUH0w0ShSYms3ULDgYAfaAlOe1lUJh2KJmQh1jBVKhz0/0Su/a612v99B77PUee71+tcn+gNcn+SRvB64bd89hZxnL1jEMGs2dftDcGVR8V6HZd8qu/vL8JXz5CrZ0mfFc1TcGmHSQb2oc2zBNEwDgqJrNITT0beUfTBcM6URgdxU4oBS22Ixfgp6TCS986CqF59iUT4M2VQ7pAqAqCs/zPYy281+QfV/RF6BmyjABrxhBbW0NPN3o/LpITs3VxqdLzllizGfPeuxHRSsNANBNnReEHpa73HZtfode4RVS2M/wWeiP+pKnPBZiPYs559+NVX9lZhOfCXHupdK9eCOsyYZhGm9wb0k2Oh1gcCL00cPitPdO9dPb+UsTxPBn0MAY+/Uw+vE3lZtT3OitzFt/ST4AgKYrAs+9waIkKaoK7G6zTNSK8OHB9MHeT9no8knkUbmwlom50nFXKefNRKfwaqTBSZphNIRmDxPt8s+1Tx4wnzMdHABgWYaW9CrHU1ho8nznfjFwDwo4Ky/GyVdT2tFDg0iZqqju35H3hiwecRAW8l3xvdHSTVg6k3mFYukNZe4ZGF+Wf5lEfhiDhh8URp5STq89Od92pjtxIFCW/2J3vc8iEw66UU9m43koZ3Y0s60rukSpZayVJ9RinjiNI+E0GjlvJOt6qabmW3azLRKdwLXu9hWLTjsyEbKQYOE8F3lZwUvN412EgJWTvSpe0NPHRPqIJEvGyV6NQtpwQsxEBJmsst4BduVCm0o5PHergQlyf7nh/h59/Ru9NFQ+/V1cHamEXGxgsua/j7/28K4vkX/9rd3H4tqPHHNWwVf7S0/etpm0I5Y8DxcqUYTYOYzH0Pr2QTSGEsHDRDiPHBWr+0koi5Kbr05ilfopTGyFkwxWUP3viu6LFpVy5Flyw2qt0NgCWlxAoelcbCYXd51nPHT1OVB3TelAZhcI+HE+8SgbXaFwhkVA8Jq9fbn3WeB6rQg8b1lWtwsoSoaxBt+yGdGo0U2KVVnJJDkVxjmKbwEADA7tbPbbvr42GXewLGt3uxTN4DgqsrsSE5Qzbjm2WA5NQi8magdPqi9nxOiynnZbZz69JZhaS0yts1G3rXEOQRAYhmYYtorCxezIWfR2888PO8FbzPqN4tJ1zD2IPhvE3dfNwPutrRt1JIOgNUbUzQ74v7D/AASs/zWE+8RHAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Block diagram on Intel Sandy Bridge CPU showing different load store units, ALU units for integers and floating point units.&quot;
        title=&quot;Block diagram on Intel Sandy Bridge CPU showing different load store units, ALU units for integers and floating point units.&quot;
        src=&quot;/static/ee91f859219c36d339bb258a3f3e5294/f058b/block_diagram.png&quot;
        srcset=&quot;/static/ee91f859219c36d339bb258a3f3e5294/c26ae/block_diagram.png 158w,
/static/ee91f859219c36d339bb258a3f3e5294/6bdcf/block_diagram.png 315w,
/static/ee91f859219c36d339bb258a3f3e5294/f058b/block_diagram.png 630w,
/static/ee91f859219c36d339bb258a3f3e5294/ae694/block_diagram.png 850w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: Block diagram on Intel Sandy Bridge CPU showing different load store units, ALU units for integers and floating point units.
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://www.researchgate.net/figure/Sandy-Bridge-block-diagram_fig1_220308557&quot; target=&quot;_blank&quot;&gt;https://www.researchgate.net/figure/Sandy-Bridge-block-diagram_fig1_220308557&lt;/a&gt;
&lt;/center&gt;
&lt;h2&gt;Device for leak&lt;/h2&gt;
&lt;p&gt;The device for significant leaks using power analysis are generally the ones that are dependent on SIMD circuits. Consider an algorithm that calls a SIMD routine based on value of data. For example:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;secret&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;secret &lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;token function&quot;&gt;simd_compute&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
        secret &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; secret &lt;span class=&quot;token operator&quot;&gt;&gt;&gt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here call to &lt;strong&gt;simd_compute()&lt;/strong&gt; is queued to the SIMD unit that can do 4x the computation of a Floating Point unit in same number of cycles. What this also means is that it will consume proportional energy to do so. Thus observing the power draw can give an attacker an insight of the victims runtime and sometimes  even leaking secret data.&lt;/p&gt;
&lt;h2&gt;How significant is power draw difference?&lt;/h2&gt;
&lt;p&gt;Using the value measured by Dr. Ian Cutress of AnandTech as reference we can see that a CPU benchmark program that stresses the Single Instruction Single Data (SISD) unit consume not more than 200W&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 65.18987341772153%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABcRAAAXEQHKJvM/AAACKklEQVQ4y4VT226bQBDl/38gVVWlrVqlStWnqupDL7KUVFWT1DKOL8IYY2yDLxgCBFgWw+6pZi2cq9SRhhnNzpyd5cxonHNZVRWqqmqsUhLHcdDpdGCaJgzDQL/fh+d5kEKgrusnSnUafcIwVGBSyoOS5HmOKIrA8lz5SZKAMaaKy7LEbrdT2vgkBCgpQJaAhBAHfU4ox/cDmOZYdW5ZFnRdV93TmeowCAJ1CyAfFgPgVfMcsgKclwi3PnrXXXR0XYH+bbdxcXG5ByQgzjmkFNjVAvEtw23KkGYF/CBBsI2edJllKWzbgmWN4LlzmKaBqTPZP9m2bSzmc+yqGmt3i2QdIN1GSIMYsbfBn7MuOkMP7WsHV7qDy76L320b+mCB9sDFRW+BX+0p9N4MOSuhjcdjxEkMnjO4lo0wDBBFN7iJQoRRhO8nX/Dt6AV+HJ/g59E7nJ9+RevNJ5y/PkXr1Qe03n9G6/gjzl6+RbTeQvN9H6vVCmkUI05C1LKCEBWErFCWHK65xMJewBj2YI2HMIZdOBMTjm1jYg0wGQ9hWwac6QScF9AaZvOMQYqGyT0jUkhIeZ8iksfsPyRSscwKhtl0iYIVkJCK1WZ0Hg+vqJuY2PvVXYzytWYr3LmnAO/P2//852JaM/VFwVSANmGz2SiftiQMQ1VAsTiOVRe0fs2GzGYzdZ5lGZbL5V2HBKz+kBCHNaIY+a7rYjQaqX0mYKqhPAKiGW5y6YJ/RAPdkN9zbz4AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Power draw of latest Intel 11th Generation Rocket Lake series running Agisoft, CPU power. The average power draw is close to 150W with peak nearing 200W.&quot;
        title=&quot;Power draw of latest Intel 11th Generation Rocket Lake series running Agisoft, CPU power. The average power draw is close to 150W with peak nearing 200W.&quot;
        src=&quot;/static/d00b292d3fd81e7480018df3cd3e9b57/f058b/normal.png&quot;
        srcset=&quot;/static/d00b292d3fd81e7480018df3cd3e9b57/c26ae/normal.png 158w,
/static/d00b292d3fd81e7480018df3cd3e9b57/6bdcf/normal.png 315w,
/static/d00b292d3fd81e7480018df3cd3e9b57/f058b/normal.png 630w,
/static/d00b292d3fd81e7480018df3cd3e9b57/40601/normal.png 945w,
/static/d00b292d3fd81e7480018df3cd3e9b57/78612/normal.png 1260w,
/static/d00b292d3fd81e7480018df3cd3e9b57/91b67/normal.png 1527w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: Power draw of latest Intel 11th Generation Rocket Lake series running Agisoft, CPU power. The average power draw is close to 150W with peak nearing 200W.
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://www.anandtech.com/show/16495/intel-rocket-lake-14nm-review-11900k-11700k-11600k/5&quot; target=&quot;_blank&quot;&gt;https://www.anandtech.com/show/16495/intel-rocket-lake-14nm-review-11900k-11700k-11600k/5&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;Compare these numbers to power draw of AVX-512 unit, we see the average close to 250W and a peak close to 300W when the SIMD unit is being used.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 65.18987341772153%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABcRAAAXEQHKJvM/AAACXElEQVQ4y32Ty27jOBBF/f+flW02nYmRxHYQp23ZkixKfIuUaOk0yJ4YsxoCBYmFwincYt1NjHFNKZFSKt/7/c7hcOD5+Zn9fs9ut+P9/Z3tdsvr62u5v729sT8cCCEwjuMjpmlikyHDMBTYuq4lwjiitcYYg3PuET93pRS/fv1TmmT4x8cHT09PVOczm2VZVtGLTF8zbFkWVv7/rOvC19eBl5cXXrdb9rtdAZ4zUEpJ13VFapoT3o1oZQljJC0r95SIYyhNcsMp3ZnnGW8Ng9QoqRhDLJLvaWaT5/X9/V2KY4i0v690VYusO/pGEJzHXBusNEx+ZGh7tJDIpmeyHnXtMN3A5ANLnuHxeKSqKpZ1Jc0z/a3iWh3pbmdkXaM6gewu1KcK1QrkTSAuV05f7/T1ESVrVNOU2uQ9m8/PT06nU5ndHEa872kvB6Sq0abFmBtGdzRNhZI3hr5l6K907Qk9VITJYkzO/SY6/R/gujIHT4yOoT3jvGQMluAVzvZYK3CmxyhRGsi+QesbaZ5wrse5gTEYNhmWJZeBe1OASlxwVhCiw2eI6fBR482Alh3W9eihoe9r5iliVVNyYXJs8uvm3YrTzGgkU/Ro3WIzJBi8FgVofY81AtW3uFGihoZBVEwxINtvtLoVBQUYY0SIG5fTgXkKRYr1CmUVwUucV9gsadRI0RBnh3WySE9zQA4No5OleQFml1hruN9T2bFhGMoCZ2cI0ZX/vPzZIXk0t7YttluXhaZp/j7oPFM3zV/r5ZOT/Lu8P7mfZtfr9eHrOq9HSo/6aZofls1e/gPRx97EWqU6bAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Power draw of latest Intel 11th Generation Rocket Lake series running 3DPMavx in AVX-512 mode. The average power draw is close to 250W with peak nearing 400W.&quot;
        title=&quot;Power draw of latest Intel 11th Generation Rocket Lake series running 3DPMavx in AVX-512 mode. The average power draw is close to 250W with peak nearing 400W.&quot;
        src=&quot;/static/60d4622c64534c340d0953f7d726ac19/f058b/avx.png&quot;
        srcset=&quot;/static/60d4622c64534c340d0953f7d726ac19/c26ae/avx.png 158w,
/static/60d4622c64534c340d0953f7d726ac19/6bdcf/avx.png 315w,
/static/60d4622c64534c340d0953f7d726ac19/f058b/avx.png 630w,
/static/60d4622c64534c340d0953f7d726ac19/40601/avx.png 945w,
/static/60d4622c64534c340d0953f7d726ac19/78612/avx.png 1260w,
/static/60d4622c64534c340d0953f7d726ac19/91b67/avx.png 1527w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: Power draw of latest Intel 11th Generation Rocket Lake series running 3DPMavx in AVX-512 mode. The average power draw is close to 250W with peak nearing 400W.
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://www.anandtech.com/show/16495/intel-rocket-lake-14nm-review-11900k-11700k-11600k/5&quot; target=&quot;_blank&quot;&gt;https://www.anandtech.com/show/16495/intel-rocket-lake-14nm-review-11900k-11700k-11600k/5&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;As we see there is indeed a significant difference in the power draw between a normal workload and workload that depends on SIMD processing.&lt;/p&gt;
&lt;h3&gt;Complications&lt;/h3&gt;
&lt;p&gt;The following are the complications to power analysis:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Attacker must be able to accurately observe and record power draw of the CPU.&lt;/li&gt;
&lt;li&gt;In some systems, power draw of entire system might not capture CPU state due to presence of other computation hardware.&lt;/li&gt;
&lt;li&gt;Careful analysis needs to be performed on power draw data infer correct results. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can see, as a result of the non-uniformity in power consumption by different units of CPU, the power consumption becomes a side-channel to extract information from the unsuspecting system.&lt;/p&gt;
&lt;h2&gt;Coming up next&lt;/h2&gt;
&lt;p&gt;We’ll take a brief detour from Power Analysis and look at other exploits and emerging memory architecture but we’ll come back to power analysis to see a real world exploit based on the concepts discussed here.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please leave a comment and I’ll address it in the next edit. Have a nice day! &lt;/p&gt;</content:encoded></item><item><title><![CDATA[Spectre: Exploiting speculative execution]]></title><description><![CDATA[This article is based on the paper In this article we’ll take a brief look at Spectre attack however I highly recommend reading the paper…]]></description><link>https://outofordercore.github.io/spectre/</link><guid isPermaLink="false">https://outofordercore.github.io/spectre/</guid><pubDate>Fri, 02 Jul 2021 14:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This article is based on the paper&lt;/p&gt;
&lt;center&gt;
&lt;a href=&quot;&quot; target=&quot;_blank&quot;&gt;
Kocher, P., Horn, J., Fogh, A., Genkin, D., Gruss, D., Haas, W., Hamburg,M., Lipp, M., Mangard, S., Prescher, T., Schwarz, M., and Yarom, Y.
&lt;br /&gt;
&quot;Spectreattacks: Exploiting speculative execution&quot;. In S&amp;P(2019)
&lt;/a&gt;
&lt;br/&gt;
(link opens a new tab with PDF ~ 294kB)
&lt;br/&gt;
&lt;a href=&quot;&quot; target=&quot;_blank&quot;&gt;
Source (link opens a new tab): https://meltdownattack.com
&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;In this article we’ll take a brief look at Spectre attack however I highly recommend reading the paper mentioned above that goes into more depth about the cause and methods of exploit.&lt;/p&gt;
&lt;p&gt;Spectre attacks are of two variants. The first one is similar to Meltdown that exploits out of order speculative execution to leak secrets. This post looks at the second variant of attack that uses indirect branches to launch a device that leaks data.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 471px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 58.86075949367089%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACIUlEQVQoz32S70tTURzG7x8V9CKyiIiWmWKTlWKQQb8gwhcJgXsR9CIKit4kZWkzjRDFd7IgxbwibjFn4UW23ZqSpru7bu6n93rvPZ/a0jlL/R6e88DhnIfn+Z6vxCElhEBssyOc8lkqn+ZV+B0vQm95GejjTfg9vd8+0PXVhxyfQTpQSIi9oqVdwMJyhPOf2zj5ycNR3zmOdJ+hZqSRY7KbZ3PdSDuP/8WOWJktC+E4rK6sMjMfpFW+i3vqJvUjV3H1Xcbtv86FyWt0zfqQHP7GKWNnCacivBmNoo2Nkc3nsSwL09piYS1KJKnyfX0RdT1eRiShspZOICGqs26jqnRFYbGnB1PTdu8cUtLz2dfcCzzEG3pCZ+gx97884kHwKQk9waZhUtCTbOk6jmlWXNu29T8sC8e2kW4HOzk+epGagQZODDZyatRD49QNwsocuUwOp8pSdX8PdHgn4OX0eDMufyuuj62cHb9Ck3yLX+urGEUDTdNIpVIUi8XKo2wsRl5RKCoKm4pCYX6edDhMOhZDmlkKMfZDRv4ZYHI5wMTSNBPxaQpGoSJgGAbZTAZVVYlFo+jt7eRbWoh7LhH3eFhpbibb1MSK17v/HB4U0TRNdE1Da2vDaGhAra0l4nKxVF+PUVdHsqMDqTQitrCxy7yLPYNdJVxqvD48zMbAAJnBwTI2hobQ+vtJ+v2HO9xP0DBMcgIMoNTVwjbnSgn+fMpvTktc1mPWgJAAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A diagram showing the general idea behind the spectre attack.&quot;
        title=&quot;A diagram showing the general idea behind the spectre attack.&quot;
        src=&quot;/static/e70ea6a89cb1a8f9f0c00300938371dc/1f09d/banner.png&quot;
        srcset=&quot;/static/e70ea6a89cb1a8f9f0c00300938371dc/c26ae/banner.png 158w,
/static/e70ea6a89cb1a8f9f0c00300938371dc/6bdcf/banner.png 315w,
/static/e70ea6a89cb1a8f9f0c00300938371dc/1f09d/banner.png 471w&quot;
        sizes=&quot;(max-width: 471px) 100vw, 471px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A diagram showing the general idea behind the spectre attack.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Cause for Spectre&lt;/h2&gt;
&lt;p&gt;Spectre attacks are cause as a result of speculative execution in case of branch resolution. I recommend reading my post on branch prediction in post titled &lt;a href=&quot;/branch-prediction&quot; target=&quot;_blank&quot;&gt;Branch Prediction&lt;/a&gt; (link opens a new tab) however if you already know how modern processors use branch target buffer to predict branches and their target, you can continue reading this post.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 48.10126582278481%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAezG1gC//8QAGRAAAgMBAAAAAAAAAAAAAAAAABEBAiEQ/9oACAEBAAEFArQLBbz/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAWEQEBAQAAAAAAAAAAAAAAAAABEBH/2gAIAQIBAT8BTZ//xAAXEAADAQAAAAAAAAAAAAAAAAAAASAh/9oACAEBAAY/Ah7P/8QAGRABAAMBAQAAAAAAAAAAAAAAAQARMRBB/9oACAEBAAE/IWXYtqF1DJTwSgzn/9oADAMBAAIAAwAAABAsz//EABYRAQEBAAAAAAAAAAAAAAAAAAEREP/aAAgBAwEBPxAI3P/EABcRAAMBAAAAAAAAAAAAAAAAAAEQEUH/2gAIAQIBAT8QBFxf/8QAGhABAAIDAQAAAAAAAAAAAAAAAQARITFxQf/aAAgBAQABPxDr+mEFKsi2RWEbiN8wnkNAHCE//9k=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The diagram shows a branch target buffer, a table with entries of PC of branch instruction, the pc if the branch is taken and a n bit predictor that predicts the direction of the branch. At every cycle, the current pc is looked up in the Branch Target Buffer to know if it is a branch or not and if it is, based on the prediction bits, the program counter is speculatively updated to the resultant program counter for branch taken from the branch target buffer&quot;
        title=&quot;The diagram shows a branch target buffer, a table with entries of PC of branch instruction, the pc if the branch is taken and a n bit predictor that predicts the direction of the branch. At every cycle, the current pc is looked up in the Branch Target Buffer to know if it is a branch or not and if it is, based on the prediction bits, the program counter is speculatively updated to the resultant program counter for branch taken from the branch target buffer&quot;
        src=&quot;/static/db4ccf9377f6b1342e97ddb6fc87417c/828fb/btb.jpg&quot;
        srcset=&quot;/static/db4ccf9377f6b1342e97ddb6fc87417c/ff44c/btb.jpg 158w,
/static/db4ccf9377f6b1342e97ddb6fc87417c/a6688/btb.jpg 315w,
/static/db4ccf9377f6b1342e97ddb6fc87417c/828fb/btb.jpg 630w,
/static/db4ccf9377f6b1342e97ddb6fc87417c/80e3c/btb.jpg 720w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The diagram shows a branch target buffer, a table with entries of PC of branch instruction, the pc if the branch is taken and a n bit predictor that predicts the direction of the branch. At every cycle, the current pc is looked up in the Branch Target Buffer to know if it is a branch or not and if it is, based on the prediction bits, the program counter is speculatively updated to the resultant program counter for branch taken from the branch target buffer
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://slidetodoc.com/lecture-9-branch-prediction-basic-idea-saturating-counter&quot; target=&quot;_blank&quot;&gt;https://slidetodoc.com/lecture-9-branch-prediction-basic-idea-saturating-counter/&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;The branch target buffer uses the program counter (pc) to give the following information - is the instruction corresponding to the pc a branch instruction? What is the target pc for the branch (Where will the branch jump to)? Prediction for the jump (Will this branch be taken or not)?&lt;/p&gt;
&lt;p&gt;The problem stems from two threads linked to same physical core sharing the Branch Target Buffer. Although harmless in thought, this can be misused by one thread to dictate the actions of another thread in case of speculative execution.&lt;/p&gt;
&lt;h2&gt;Influencing branches&lt;/h2&gt;
&lt;p&gt;To influence branches of victim, the attacker first must find a bug in the victim program that can leak secret via a side channel. Secondly, the attacker’s program must be written in a way it trains the Branch Predictor and manipulate the values of the Branch Target Buffer in such a way that pc for branch in attacker program points to pc for another jump in victim program and the resultant pc of the jump in attacker points to the pc in victim to set of statements that leaks data via side channel.&lt;/p&gt;
&lt;p&gt;The diagram below shows a schematic of training the Branch Predictor and manipulating the Branch Target Buffer for malicious intent:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 540px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 64.55696202531645%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAABjUlEQVQ4y12TiY7CMAxE8/9/h0DcIO77KEebFlq8epYGZYlkEeLJ88RJg5nZfr+30Whki8XCNpuNzedzm81mVtc1aft8Ph6MpmlcJy267XZrGqEoCl9AsFwubb1eu4g4Ho9GXtDH42HX69U1BMDpdOrz2+1mz+fTQpZlvvl8Pju43+/bcDi0Xq9nk8nELpeLA1+vl89Xq5Wf6HQ6eZ6ToSd2u50FXAAhoarj8djh5IgUiKNut+vQ9MgqErDZbrcdkue5Jzudjle83+9+FAHLsnRdq9XyOSbQDgYDB6N14Pv9/jqIMXqvCDbRMwHRCkyedvELCDPsDyzo9tQvDW5Za1VVueP0gn4Hxb9AXMoNIDaxlgJ1fIqzj980/gEB/DpMi6RAhtxq6ISBBDd0OBxcBIQnhEtEgghIAfT0k17SR96qDDlQ146YJE+Dy+EC0kuhEG+Nt8g+AHpiGPFnQwUqAcIlLaA66wjkEAcA9UUA1lzwLLta0Pn1rabfrcbv/1hWlhfRIkZitCKWHnXT2B84M+H8wX+TcgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The attacker program has a conditional branch at PC 4004 which always resolves and true and jumps to PC 8000. This creates an entry in the Branch Target Buffer that says the instruction at 4004 is a conditional branch instruction that jumps the PC to 8000 and is very likely to be taken. In victim program 4004 is a branch instruction and when the processor speculates on the jump, it jumps to 8000 based on the results of the branch target buffer without even decoding the instruction.&quot;
        title=&quot;The attacker program has a conditional branch at PC 4004 which always resolves and true and jumps to PC 8000. This creates an entry in the Branch Target Buffer that says the instruction at 4004 is a conditional branch instruction that jumps the PC to 8000 and is very likely to be taken. In victim program 4004 is a branch instruction and when the processor speculates on the jump, it jumps to 8000 based on the results of the branch target buffer without even decoding the instruction.&quot;
        src=&quot;/static/7ab89fd3b32283add510c031d64cf6fe/07484/train.png&quot;
        srcset=&quot;/static/7ab89fd3b32283add510c031d64cf6fe/c26ae/train.png 158w,
/static/7ab89fd3b32283add510c031d64cf6fe/6bdcf/train.png 315w,
/static/7ab89fd3b32283add510c031d64cf6fe/07484/train.png 540w&quot;
        sizes=&quot;(max-width: 540px) 100vw, 540px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The attacker program has a conditional branch at PC 4004 which always resolves and true and jumps to PC 8000. This creates an entry in the Branch Target Buffer that says the instruction at 4004 is a conditional branch instruction that jumps the PC to 8000 and is very likely to be taken. In victim program 4004 is a branch instruction and when the processor speculates on the jump, it jumps to 8000 based on the results of the branch target buffer without even decoding the instruction.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;Spectre is especially effective if the processor is already in speculative mode as a result of high latency cache miss, when it reaches the branch instruction. Especially in Intel processors, the checks are disabled and the processor continues to execute down the speculative path.&lt;/p&gt;
&lt;p&gt;The main thing to note is that this jump can be made to any arbitrary address and hence can be carried out effectively.&lt;/p&gt;
&lt;h2&gt;Device in the victim&lt;/h2&gt;
&lt;p&gt;Spectre also needs the victim program to have a device function baked into it to leak secrets via a side channel. We have already discussed about the cache side channel that uses timing to leak secrets and power based side channels that uses power draw to detect victim’s behavior.&lt;/p&gt;
&lt;p&gt;An example of device is as follows:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; secret&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;secret&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;secret &lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;token function&quot;&gt;shared_library_routine&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
        secret &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; secret &lt;span class=&quot;token operator&quot;&gt;&gt;&gt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Considered secret is cached and can be loaded in few cycle. In the time processor comes out of speculation, the device would have ran a number of loops calling a &lt;strong&gt;shared&lt;em&gt;library&lt;/em&gt;routine()&lt;/strong&gt; whose traces can be found is cache and the secret can be leaked via timing analysis.&lt;/p&gt;
&lt;p&gt;The above example is not feasible for Spectre attack as loading the shared&lt;em&gt;library&lt;/em&gt;routine() itself might take a number of cycles however the paper discusses other methods where attacker controls the register states of victim thus carrying out this attack more efficiently.&lt;/p&gt;
&lt;h2&gt;Mitigation&lt;/h2&gt;
&lt;p&gt;Mitigation for Spectre came in form of microcode update where speculative execution enforces tighter checks or a performance degrading alternate where the Branch Target Buffer is invalidated at every context switch making it hard for an attacker to train the same. The fixes via software are either ineffective or have an unacceptable performance degradation. Implementations that remove the effect of side channels are harder given the vulnerability is a part of many generations of commercial products, it is hard to mitigate. &lt;/p&gt;
&lt;p&gt;We see once again, anything shared between the threads in a core can be exploited - be it Branch Target Buffer that speculatively jumps to a device or the Last Level Cache that acts as a timing based side channel to leak information.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please leave a comment and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Branch Prediction]]></title><description><![CDATA[In this post, we’ll take a brief look at branch prediction. To learn more about branch prediction and the hardware implementation of branch…]]></description><link>https://outofordercore.github.io/branch-prediction/</link><guid isPermaLink="false">https://outofordercore.github.io/branch-prediction/</guid><pubDate>Fri, 02 Jul 2021 13:00:00 GMT</pubDate><content:encoded>&lt;p&gt;In this post, we’ll take a brief look at branch prediction. To learn more about branch prediction and the hardware implementation of branch predictors, you can watch the lectures on branch prediction by &lt;a href=&quot;https://people.inf.ethz.ch/omutlu/&quot; target=&quot;_blank&quot;&gt;Onur Mutlu&lt;/a&gt; (link opens a new tab), professor at ETH Zurich, previously at Carnegie Mellon - &lt;a href=&quot;https://youtu.be/h6l9yYSyZHM&quot; target=&quot;_blank&quot;&gt;Branch Prediction I&lt;/a&gt; (link opens a new tab) and &lt;a href=&quot;https://youtu.be/z77VpggShvg&quot; target=&quot;_blank&quot;&gt;Branch Prediction II&lt;/a&gt; (link opens a new tab) from &lt;a href=&quot;https://youtube.com/playlist?list=PL5Q2soXY2Zi_FRrloMa2fUYWPGiZUBQo2&quot; target=&quot;_blank&quot;&gt;Digital Design and Computer Architecture playlist&lt;/a&gt; (link opens a new tab) of Spring Semester, 2020 at ETH Zürich.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 325px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 122.78481012658229%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAZCAYAAAAxFw7TAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC9ElEQVQ4y5VVW2sTQRTOX6xUrU9F65si1LaxNWhbUfTBBmorIoiCoG9in3wQSyMoRrDkoVLQNnaT3Wzuu5vuZXZ2d/aT2ZvJJmntwO7MnDPnmzNzvnMmgzHN9/2kN01zYH5Sy5ykjI0lSfovsLGA3DA2Nk0LpVIJpkUGdP0e+4wl8wwfsNQi3hiLxr6D7e0dLgGXsL41aY/5fMhDHz48L17oYetTGzN3ZRS+twNtslkEZksSrHIZjIQnyAiKiD+dCkRVBnUpGENy1PwrCROzGqaWHEzOq3j5rg7m2eFWHj8RAxFFGPv78AwjBKwoEvabv1FRpehQQFnoYOGxhPNZEzOrBFfvmbiyQjA5b2BlU0ajqYWgxzqM3V2Ye3uwDg/BHCc8skMcdNsKNKWNrY8CLmVbuLlGsfzMRm6T4P4LG4tPCFaf27j+yMZ0roXPRQm9XhcNqYauLHOXwzvkP04LyyLwXBsfCjVM5zqYWiS4vUGwtEEwlydYXCe49pDg4i2C6VwDhaIUHJ9Qilq9Ht1/FOVWqzUQGEnWkF2TcHnZRHadYj5vYS5PcSGr4866iEZTGVjfbrfDiMdRlmU5oU0cYYdaePqmgolZBZMLFOdmu3i9JQOsPyjhFzuU0EYUxUgZkYX9o8321xpuPBDw5Ud3iKOhUz6azeZgplSr1aEMYX0bUNuKZIM5Ho8bjcZowFGFIeYl92pcgTgVMA2azt10Ozsg884OOOTRmOT3U/fH+wFALogB/RGVxKcG7MMdeEZMDTZ0FfWY2DFtBEHoowSD67rJ3G39Avn5Hlbp7diyxT1M6iH/cWLyXVRVDVhfLBZxcHCQGNjlAmh9DyFnq4Gepyu3q9VqODo6Gq6HjuMEnhmGAU3TQClN8pNWviH2icv5prquB2NCSGCbAKbvblQQmK1HZf709yeTvuD0d5LxmV69JAWjIHle+BC5nhfIvOhhchw3kMUOnArIX7uOokLr6cG4d2zAMC0oag+6YULRjgMdH3PAv16Yd9YLxwc4AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;An illustration showing the need for branch prediction to speculate the direction of conditional branches for speculative execution&quot;
        title=&quot;An illustration showing the need for branch prediction to speculate the direction of conditional branches for speculative execution&quot;
        src=&quot;/static/c2baafb75c65a4df7fc869da73bc06d9/ff46a/banner.png&quot;
        srcset=&quot;/static/c2baafb75c65a4df7fc869da73bc06d9/c26ae/banner.png 158w,
/static/c2baafb75c65a4df7fc869da73bc06d9/6bdcf/banner.png 315w,
/static/c2baafb75c65a4df7fc869da73bc06d9/ff46a/banner.png 325w&quot;
        sizes=&quot;(max-width: 325px) 100vw, 325px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: An illustration showing the need for branch prediction to speculate the direction of conditional branches for speculative execution
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Need for branch prediction&lt;/h2&gt;
&lt;p&gt;When a processor encounters a branch instruction - it has to decode the instruction to find the target of the branch. In case of a conditional branch, the direction of branch also depends on the values in the Flag Registers - you can read more about these registers in Wikipedia article titles &lt;a href=&quot;https://en.wikipedia.org/wiki/FLAGS_register&quot; target=&quot;_blank&quot;&gt;FLAGS register&lt;/a&gt; (link opens a new tab). Based on the results of previous operations, these flags are set and decide the direction of current branch.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 300px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 63.291139240506325%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACVUlEQVQ4y02TS09TURSFv3N7e1vagsViaeHyKI8W6AsqSgQ1KUFEbcWQMNKQODPBqFGJD8ROTBzwA0z8CTo1ODIy0YTEFzFRMc70f1yzL7tJb3Jyzzk5a+219gOgCswCFeAsUAYmgX5gABgD5jHMATNAFpjDcAo4DmSAQV1FgCvAAnACuKAgeZgG+oARfbNcWUk8qK6nNuK9Th2oY5B/rwZPAqeFsBMwCpbvCDANpIBRiWyHjKhwb70Z/3nn7YRXXU+tiNKOVFCwYaBbOQTns0dVUfMvNuNquScYNhIsvbFbONjcK3mLd3uEsDcUtbKKd4EQcBKVHFMSR5VlW+7cgO0rHL73Lv9jY7fgzd9Mr0m+gm1WRUnS6k7S5h8cjSTyuwSshAkM7fahwuSjj8VfT7+WvXqj7zJw1IlYeSAHjKubmSZhUKypbCEcUvtdGDrssBFLXT7hl7JX23KX5exErIK6yKlt37JsInrZpgnOanG6MT5QgkTvvy/83vpc9i5t+oRpzeGIttyUtp1vNaZ9FFOlY1p9UZ90IpbkNf7wQ/FPY3/Sqz1xa2I5FLNGFd9UONtsm2ZxaCENiCpjEUoMhMSBeXYwtb/9b9pbeT5wTlxFOu0exblaTBkIai1rCViUJvan43C/YCyEoLq6Pbiz9nL4e2Ymdh04YwW4qEOx1PKehCbzqlZJ1OS188VyJhIPiIv+xrfy38d7Je/ai6Hzkt/2Y8FmvhPq1G+boj+b+NHkYkIDSF6kinnLNnKXu/Eq9/r2zsSn6dWEjGjGdkxJ3xd1piv/Ae1HYgRrsxlFAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Diagram of a 5 stage pipeline in RISC systems showing how different stages of pipeline are busy at any given clock cycle. (IF = Instruction Fetch, ID = Instruction Decode, EX = Execute, MEM = Memory access, WB = Register write back). In the fourth clock cycle (the green column), the earliest instruction is in MEM stage, and the latest instruction has not yet entered the pipeline.&quot;
        title=&quot;Diagram of a 5 stage pipeline in RISC systems showing how different stages of pipeline are busy at any given clock cycle. (IF = Instruction Fetch, ID = Instruction Decode, EX = Execute, MEM = Memory access, WB = Register write back). In the fourth clock cycle (the green column), the earliest instruction is in MEM stage, and the latest instruction has not yet entered the pipeline.&quot;
        src=&quot;/static/696a7840fbcca52be4681b8396a4d80b/5a46d/pipeline.png&quot;
        srcset=&quot;/static/696a7840fbcca52be4681b8396a4d80b/c26ae/pipeline.png 158w,
/static/696a7840fbcca52be4681b8396a4d80b/5a46d/pipeline.png 300w&quot;
        sizes=&quot;(max-width: 300px) 100vw, 300px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: Diagram of a 5 stage pipeline in RISC systems showing how different stages of pipeline are busy at any given clock cycle. (IF = Instruction Fetch, ID = Instruction Decode, EX = Execute, MEM = Memory access, WB = Register write back). In the fourth clock cycle (the green column), the earliest instruction is in MEM stage, and the latest instruction has not yet entered the pipeline.
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://www.quora.com/What-is-CPU-pipelining&quot; target=&quot;_blank&quot;&gt;https://www.quora.com/What-is-CPU-pipelining&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
 
&lt;p&gt;In a modern out of order processor, decoding an instruction and predicting branch direction in case of conditional branches make take some time - a lot longer if processor is waiting for data that decides the direction of branch as a result of L1 / L2 cache miss.&lt;/p&gt;
&lt;p&gt;In such a case, the processor predicts the outcome of the branch and speculatively starts executing down the predicted path until the branch can be resolved.&lt;/p&gt;
&lt;h2&gt;Evolution of Branch Predictors&lt;/h2&gt;
&lt;p&gt;The earliest predictors were a one bit counter. The counter value indicated the direction of previous branch - 0 for not taken and 1 for taken. The prediction for current branch would depend on previous branch and the result of current branch will update the counter for prediction regarding next branch. AS it turns out even one bit counters were fairly accurate at prediction but the high cost of flushing the pipeline in case of mis-prediction means these predictors needs to be as accurate as possible to improve performance.&lt;/p&gt;
&lt;p&gt;The next evolution was a two bit saturated counter, where the state 00 indicated there is a strong chance branch is not taken, state 01 meant there is a good possibility branch will be not taken, state 10 meant there is a good possibility branch will be taken and state 11 meant there is a great chance branch will be taken. The diagram below shows the transition between the state based on the result of current branch:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 110.12658227848102%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAWCAIAAABPIytRAAAACXBIWXMAAAsTAAALEwEAmpwYAAADOUlEQVQ4y4VUa5OiRhT1//+LzaekUjUbHZ84ymh2h3FRkFGUx6AoyIC8EZqmeaWQidndbDanuqDr0ofT9/a53ZBlGVyRZVkQ+GuWjWMIIUySJI5j1/Ns23Zdt44AAOpJFEVhGDZM0yzLMo5jXddN0ySensIwdF3Xtm1ZlqfTCY7j9HJpWpZt2zBJfN93HCdJkrIsG+fzWRTF4/FIEMTDYNDvdAbd3nq1sp0K8ArbsXVdFwShfX+Pdbv3Hz+Ss1lRFA1d11mWtSxLEIRhr/fnGB8NsFaz6bpuEASqqh6OR8Mwsix1HGc8Gk0ehjiGTR8fEUKNq4BLEM/E8zNNU19mM1EQFEXRNE2WZZqiKJpmGEYQBMMwJEn65cOHp8+fWZattm2aJkIIQojStMjz8j9QFEVZlqZpKooCABBF8T3n27fib+R5fpt/Td5ut0EQ5Hm+XC4vYfhOvq3+iazv+xRFXS6XsiwJgtjLh2+U/2fPZ4MgCAhhWZYkSUq73ffkH/6lDnqeO5s9I4SyLGMYxnGcnykXRZFlGUKoKPJ6gSiKAIAoiiRJ+qdgCCHP8yCEnucCAMIoCvxgtVo9jB7Go5H0+hoEQZIkHMepqkotFiRJvh+VqqrH43EymWD9frvZ7LTuGYYxDMP3/drDmqYpikKSZLvVajf/+P3X36jFoiIbhvHy8mJZ1m6367Xbg06n3WwNMQwAEMfxLYU8zy3Lwno9rNMd9vpfZrM8zxvr9Up8fR3j+Hw+5znu6dMngec5jpNlmReE6XQ6Go2m02nt/8PhwCyXS5quD6yhaVqapjeTIITqMy/LEgBwOqmqohiGgRD6d0WrnE8n9VWSbNtOkqRuo/iKJElqt+V5Xpfzaxe+kxXlyHFbnucty6raSD5op5O837+9vSmKkl8Nf7lc6h7+Rtkyzf1+t5dldrPd7XaCIMwXlChJ7GbDC8Jmw0YAVOTwR2TzfBZ4fr1ezecLjuM2LEvR9MuqAr1kaJqmaPpNN6IoAlFU5ZBlt9HwPC+GMUrTGMZZllVpxzGIY5hUdxVMUJ0qhDBN0++V7+7uut1uf1Ch36/fAwzD6uct3mw2seEQf3wc43g9cBz/CzygrVm2sK1+AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Diagram showing transitions in a 2 bit counter - For state 00, the state remains same if the prediction for branch not taken is correct, else there is a transition to state 01. For state 01, on branch not taken, there is a transition to 00, else if branch is taken we  jump to 10. If on state 10, branch is not taken, we dial back to 01 else we jump to 11. In state 11, if branch is taken we stay on 11 else on branch not taken we change to state 10.&quot;
        title=&quot;Diagram showing transitions in a 2 bit counter - For state 00, the state remains same if the prediction for branch not taken is correct, else there is a transition to state 01. For state 01, on branch not taken, there is a transition to 00, else if branch is taken we  jump to 10. If on state 10, branch is not taken, we dial back to 01 else we jump to 11. In state 11, if branch is taken we stay on 11 else on branch not taken we change to state 10.&quot;
        src=&quot;/static/65514e072e610ed41050a4eeb506e658/f058b/2-bit-saturating-counter.png&quot;
        srcset=&quot;/static/65514e072e610ed41050a4eeb506e658/c26ae/2-bit-saturating-counter.png 158w,
/static/65514e072e610ed41050a4eeb506e658/6bdcf/2-bit-saturating-counter.png 315w,
/static/65514e072e610ed41050a4eeb506e658/f058b/2-bit-saturating-counter.png 630w,
/static/65514e072e610ed41050a4eeb506e658/9d76a/2-bit-saturating-counter.png 829w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: Diagram showing transitions in a 2 bit counter - For state 00, the state remains same if the prediction for branch not taken is correct, else there is a transition to state 01. For state 01, on branch not taken, there is a transition to 00, else if branch is taken we  jump to 10. If on state 10, branch is not taken, we dial back to 01 else we jump to 11. In state 11, if branch is taken we stay on 11 else on branch not taken we change to state 10.
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://www.researchgate.net/figure/2-bit-saturating-counter_fig1_333641705&quot; target=&quot;_blank&quot;&gt;https://www.researchgate.net/figure/2-bit-saturating-counter_fig1_333641705&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;The transitions are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;State 00 predicts the branch will not be taken. If the branch is not taken, it stays  on 00. If branch is taken despite the prediction, the state transitions to 01 getting closed to the “taken” prediction.&lt;/li&gt;
&lt;li&gt;State 01 predicts branch will not be taken (although with not as large a probability as state 00). If the branch is indeed not taken the state transitions to 00 indicating a bigger probability next branch might also not be taken. If the branch is taken, the state transitions to 10.&lt;/li&gt;
&lt;li&gt;State 10 predicts branch will be taken with moderate probability. If the branch is indeed taken the state transitions to 10 indicating a high probability next branch will be taken. If the branch is not taken despite the prediction, the state transitions to 01.&lt;/li&gt;
&lt;li&gt;State 11 strongly predicts for the branch to be taken. If the branch is indeed taken the state remains the same. If not the state transitions to 01 indicating weakening in probability for branch being taken.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unlike a single bit predictor, two bit predictor depends on a larger branch history to predict next branch. Slightly better accuracy was achieved with more states and more transition. Modern processors have graduated from just predicting direction of branch to predicting the jump right from the program counter without even decoding instruction.&lt;/p&gt;
&lt;h2&gt;Branch History Table&lt;/h2&gt;
&lt;p&gt;One single counter for all the branches doesn’t give a clear picture for all branches. To address this, the single branch predictor now became a branch history table.&lt;/p&gt;
&lt;p&gt;The table is looked up using the pc of the branch instruction to predict whether it would be taken or not. The diagram below shows a simple schematic of a branch history table.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 353px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 101.8987341772152%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAECAwX/xAAWAQEBAQAAAAAAAAAAAAAAAAACAAH/2gAMAwEAAhADEAAAAe1OOw3RB5S4awV//8QAGxAAAgMAAwAAAAAAAAAAAAAAAAECESESIjL/2gAIAQEAAQUCs7US9Rvjo4ptYj//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAXEQEBAQEAAAAAAAAAAAAAAAABECEx/9oACAECAQE/AR2HZ//EABcQAAMBAAAAAAAAAAAAAAAAAAAwMUH/2gAIAQEABj8CpiP/xAAbEAEAAgIDAAAAAAAAAAAAAAABABEQMSFRcf/aAAgBAQABPyFQtA9milY3TiUEOwS8NwUBj//aAAwDAQACAAMAAAAQiw/A/8QAFxEBAQEBAAAAAAAAAAAAAAAAARAhMf/aAAgBAwEBPxBMjyf/xAAWEQEBAQAAAAAAAAAAAAAAAAABEBH/2gAIAQIBAT8Q2ZAan//EAB0QAQACAgIDAAAAAAAAAAAAAAEAESFBEFExYbH/2gAIAQEAAT8QKguhn7BbMrm9Qui/O4UviGvbauJGA+m4gaz0w7BQb4//2Q==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The figure shows a branch history table that uses k bits from lower half of branch address to find prediction&quot;
        title=&quot;The figure shows a branch history table that uses k bits from lower half of branch address to find prediction&quot;
        src=&quot;/static/ead8c158524536d7f4c9eef02899a14f/51faa/bht.jpg&quot;
        srcset=&quot;/static/ead8c158524536d7f4c9eef02899a14f/ff44c/bht.jpg 158w,
/static/ead8c158524536d7f4c9eef02899a14f/a6688/bht.jpg 315w,
/static/ead8c158524536d7f4c9eef02899a14f/51faa/bht.jpg 353w&quot;
        sizes=&quot;(max-width: 353px) 100vw, 353px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The figure shows a branch history table that uses k bits from lower half of branch address to find prediction
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://slidetodoc.com/lecture-9-branch-prediction-basic-idea-saturating-counter/&quot; target=&quot;_blank&quot;&gt;https://slidetodoc.com/lecture-9-branch-prediction-basic-idea-saturating-counter/&lt;/a&gt;
&lt;/center&gt;
&lt;/br&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: There are several ways to design and realize a Branch History Table. Some microarchitecture implement a branch history register and that along with the prediction from the table gives the final prediction. To know more about them I highly recommend you to watch Onur Mutlu’s videos liked above on Brach Predictors.&lt;/p&gt;
&lt;h2&gt;Branch Target Buffer&lt;/h2&gt;
&lt;p&gt;Modern processors implement a lookup table known as branch target buffer in hardware that stores the program counter for the jump instruction, the program counter in case the branch is taken and a prediction counter to predict the direction of branch. If the branch is predicted to be taken, the current program counter is replaced by the program counter for the branch taken condition retrieved from the lookup table, else the program counter is incremented as normal generally pc = pc + 4 (considering 4 byte instruction size)&lt;/p&gt;
&lt;p&gt;The image below shows the design of Branch Target Buffer in hardware:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 48.10126582278481%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAezG1gC//8QAGRAAAgMBAAAAAAAAAAAAAAAAABEBAiEQ/9oACAEBAAEFArQLBbz/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAWEQEBAQAAAAAAAAAAAAAAAAABEBH/2gAIAQIBAT8BTZ//xAAXEAADAQAAAAAAAAAAAAAAAAAAASAh/9oACAEBAAY/Ah7P/8QAGRABAAMBAQAAAAAAAAAAAAAAAQARMRBB/9oACAEBAAE/IWXYtqF1DJTwSgzn/9oADAMBAAIAAwAAABAsz//EABYRAQEBAAAAAAAAAAAAAAAAAAEREP/aAAgBAwEBPxAI3P/EABcRAAMBAAAAAAAAAAAAAAAAAAEQEUH/2gAIAQIBAT8QBFxf/8QAGhABAAIDAQAAAAAAAAAAAAAAAQARITFxQf/aAAgBAQABPxDr+mEFKsi2RWEbiN8wnkNAHCE//9k=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The diagram shows a branch target buffer, a table with entries of PC of branch instruction, the pc if the branch is taken and a n bit predictor that predicts the direction of the branch. At every cycle, the current pc is looked up in the Branch Target Buffer to know if it is a branch or not and if it is, based on the prediction bits, the program counter is speculatively updated to the resultant program counter for branch taken from the branch target buffer&quot;
        title=&quot;The diagram shows a branch target buffer, a table with entries of PC of branch instruction, the pc if the branch is taken and a n bit predictor that predicts the direction of the branch. At every cycle, the current pc is looked up in the Branch Target Buffer to know if it is a branch or not and if it is, based on the prediction bits, the program counter is speculatively updated to the resultant program counter for branch taken from the branch target buffer&quot;
        src=&quot;/static/db4ccf9377f6b1342e97ddb6fc87417c/828fb/btb.jpg&quot;
        srcset=&quot;/static/db4ccf9377f6b1342e97ddb6fc87417c/ff44c/btb.jpg 158w,
/static/db4ccf9377f6b1342e97ddb6fc87417c/a6688/btb.jpg 315w,
/static/db4ccf9377f6b1342e97ddb6fc87417c/828fb/btb.jpg 630w,
/static/db4ccf9377f6b1342e97ddb6fc87417c/80e3c/btb.jpg 720w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The diagram shows a branch target buffer, a table with entries of PC of branch instruction, the pc if the branch is taken and a n bit predictor that predicts the direction of the branch. At every cycle, the current pc is looked up in the Branch Target Buffer to know if it is a branch or not and if it is, based on the prediction bits, the program counter is speculatively updated to the resultant program counter for branch taken from the branch target buffer
&lt;/a&gt;
Source (link opens a new tab): &lt;a href=&quot;https://slidetodoc.com/lecture-9-branch-prediction-basic-idea-saturating-counter/&quot; target=&quot;_blank&quot;&gt;https://slidetodoc.com/lecture-9-branch-prediction-basic-idea-saturating-counter/&lt;/a&gt;
&lt;/center&gt;
&lt;h2&gt;How sensible is branch prediction?&lt;/h2&gt;
&lt;p&gt;Consider a RISC based pipeline with 5 stages and 10% of instructions are branch instructions. Consider a branch can be predicted with an accuracy of 99% (branch predictors in modern processors are in fact this accurate).&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;For every 1000 instructions, there are 100 branch instruction out of which 99 can be predicted correctly.
Total cycles to run 1000 instruction
= 4 + 999 (comes from the pipelined nature)
+ 2 (2 cycles wasted until the branch is resolved)
+ 5 (cycles added as a result of flush)
= 1010 cycles

Consider a pipeline that adds 2 nop (no operation) in pipeline before every branch instruction
= 4 + 999 (comes from the pipeline nature)
+ 2 * 100 (2 nop for 100 branch instruction)\
= 1203  cycles&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can observe there is a clear performance gain with branch prediction compared to adding nops down the pipeline.&lt;/p&gt;
&lt;h2&gt;Coming up next&lt;/h2&gt;
&lt;p&gt;This is a brief introduction to branch prediction and hardware behind it. This is in no way a comprehensive look but it covers enough to give a foundation for the exploit we’ll cover later named Spectre.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This might sound repetitive by now but to get solid understanding of branch predication - from reasoning behind it, to realization in hardware - I highly recommend watching Onur Mutlu’s lectures linked at the beginning of this post. His lectures are an invaluable resource for people looking to understand computer architecture and microarchitecture implementation of these concepts in modern processors and I highly recommend watching the entire playlist to get a good understanding of braoder picture of computer architecture.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please leave a comment and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Meltdown: Reading Kernel Memory from User Space]]></title><description><![CDATA[This article is based on the paper: In this article we’ll take a brief look at Meltdown attack however I highly recommend reading the paper…]]></description><link>https://outofordercore.github.io/meltdown/</link><guid isPermaLink="false">https://outofordercore.github.io/meltdown/</guid><pubDate>Fri, 02 Jul 2021 12:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This article is based on the paper:&lt;/p&gt;
&lt;center&gt;
&lt;a href=&quot;https://meltdownattack.com/meltdown.pdf&quot; target=&quot;_blank&quot;&gt;
M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, A. Fogh, J. Horn, S. Mangard, P. Kocher, D. Genkin, Y. Yarom, and M. Hamburg,
&lt;br/&gt;
“Meltdown: Reading Kernel Memory from User Space,”  Tech. Rep.,2018.
&lt;/a&gt;
&lt;br/&gt;
(link opens a new tab with pdf of paper ~ 258kB)
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://meltdownattack.com/&quot; target=&quot;_blank&quot;&gt;https://meltdownattack.com/&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;In this article we’ll take a brief look at Meltdown attack however I highly recommend reading the paper mentioned above that goes into more depth about the cause and methods of exploit.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 421px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 56.9620253164557%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACMklEQVQoz4WSS2sTYRSG54d1461KBTGkYAlTTDGxLrqqipSWLlwo7l0IrqS6cKELLUUpQm2trVRqQolNNLWpNZfJNDOTby5J5vZIJm2oYvGFl/PBdzi85/BIQRAQhAHtTodqtYqiKCh1hUajga7rCCEwTRPDMNAaDZRaDcdx6CoMAsIw/MMSR/JD3FaH/8m07cgnSfpZ/0WmtMVmMcNGYZPvlR1+VHajZLZtR+4mahoGolplY3mZ7Npa9NbKZUwhsCwr2qLbJz3aeMLpN1cYfD7Cqbk4saU0qcVbKKqC7/m0HAcPqGWzGOk028PDlGQZa3wcZWICUS7T8X3cw5NJc/kXnFuRuTAvc/b1CJc+pbi2chthCg4PFRWrUMBPJqnGYohEAsbGMNNpOqraX1dVVaRn+ZcMLslcXLjK+fkElz9eZ3zlDkazGTUFvhdVkc/TSaXYj8fRR0cJUimMGzdoKUp/YL1eR3r85SkD7+KceTvCwKsYgx9GSb6fjG7SSxj2Bm5t4SUSlIeG0OJxkGX0ZBLn2MBarYa08HWRm6t3mVq61/PafR6sPqRSrqBpGmq9jiYEO+vr7M/MkJucZHdqisbsLMXpaZRSCUMIDlSVvb29HjZ+2+dbrkD2c4bmgdGjyPf79rze2vuKQiaXY7tYRDNNutn9IOj3dJmWIiAJMS0T9UCl457MomPbGLqOrml4rvtvDo8IP66/6T/67yaxW21cz8dptSPbTgvLdjBtB9f1+A3auw4ewJLv3AAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;An illustration of Meltdown on how data at target can be captured by a location in a device&quot;
        title=&quot;An illustration of Meltdown on how data at target can be captured by a location in a device&quot;
        src=&quot;/static/a1ccc5b61854e2484826b00adfbee4b3/092ed/banner.png&quot;
        srcset=&quot;/static/a1ccc5b61854e2484826b00adfbee4b3/c26ae/banner.png 158w,
/static/a1ccc5b61854e2484826b00adfbee4b3/6bdcf/banner.png 315w,
/static/a1ccc5b61854e2484826b00adfbee4b3/092ed/banner.png 421w&quot;
        sizes=&quot;(max-width: 421px) 100vw, 421px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: An illustration of Meltdown on how data at target can be captured by a location in a device
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Memory layout&lt;/h2&gt;
&lt;p&gt;Note: This as the memory layout for programs before Operating Systems implemented mitigations for Meltdown. Now every access into kernel space is trapped and checked for validity.&lt;/p&gt;
&lt;p&gt;Before Meltdown became a known threat, the virtual memory layout for any program looked as follows:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 500px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 94.9367088607595%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAIAAAAf7rriAAAACXBIWXMAAAsTAAALEwEAmpwYAAADqklEQVQ4y1WS2U8bVxTGp8trG9qH/il9aQtSAjIJ2A0l6kPVtOEhCVCgQQmhASrAZYtETIzVNEkdFgONHYoqEBAHsEBNypKyjMEY8D42tmfzvs3cWW7locTx0dXR0ZG++/vuuQeBEIqiACF0eKyPntc/XqzTmhoeGuvUf13XTNdopqs1MzW/ztb8vtSgNf34wHh16mV/MEB6vVgoFEYSibgZRTGPz+G19E1XKifLlZPyW4+Kr/V+VqcqrO0vrO77/AdVUfvTso6n8vY/S8b/bsvyYJaHsCwbDocBy9vc5p5nii79+RZtSfNvZ+9oS9rHLrRoZbcfFjc9OHtzsKjtiaxTf25koSkWTlE0mUgkEMm2CCHcPtz/ZW2ue3uxe2uhb3e5c2Xqpzld09xo6/xYz+aLXtTUu73YsWkcQl9GKZqkqHg8nhULQlZ86PM3b6BNO9Zbr9HG1a0bK2tXZ4xVU7O186Ybr/5tXNtu3rLUb6CPbW4oSgIIc2RXIDBhd+i9vnG7Y3jPMnJwoDuyjTsco4dHw5b9Ycu+3oPp3B4jhkGOE8WsCoGnQRIEyzBQugzm4q1a6jPpNAAAviGfBEEQDJORfPCiyAtSfruQJiym06k88YltgqTTLCdCyEtHOIW+6Zw0UxkmnywtCe6zJjZr+d1qYK4R965TG43kWn1k/drxq5usuVbYq+Z2a3n0Sny/Hwj/PweJx2Mup4MKJSlsNTr5fkyPRPXv0BOIQ4u8ViELSmRrEAnqEHIMof94L6RDkivnJC4viRNxl9OBk5GAc502fBI3fEBOFHiHCgKjZwKjBdTER7juQ+zJGe9QQcTwcXT83fCSnMuKhTzbhH03M3gJaiqAuiJ5T8Hev4h1ypYbvkiqFOkBRWbgS0FzCarOp561gdPJSwMTsh7wo92IsjKjrIi2XwzckRMt8mBLube5jGjN1kSrIqGsTLeVRobzxVCQyBYzU1UOvyuFVy6AyzL+ssz5VeFq6aexb4qZb0uE70thVRn8uijTcxucms19VfDI5u9S0V0DdPd9v3IA61TZW/vsbXc9HSp3xz2iS033qKmf7xIjei7PtvShfoyyLgLnMtx/waGzjOU5/4+BMKg3dmbSlnlgnmVtJmhbgs51hgEpwAKO43LkwDHu26NJW9JnoV07QTeKY2YSM5NuFHejQQ+KBw9ixGHSa8XdbpcH84RoOreeOI4nUjHAM4BnOAFwAgt49qSQMmC5DOCZaCx87PMG/P5wJPofu3uLKDzDiqgAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Shows the layout of program in virtual memory where the lower address are occupied by the program and the highest addresses are reserved for kernel data.&quot;
        title=&quot;Shows the layout of program in virtual memory where the lower address are occupied by the program and the highest addresses are reserved for kernel data.&quot;
        src=&quot;/static/427f91b73b8b229ab84ace482e1e2aea/0b533/memory_layout.png&quot;
        srcset=&quot;/static/427f91b73b8b229ab84ace482e1e2aea/c26ae/memory_layout.png 158w,
/static/427f91b73b8b229ab84ace482e1e2aea/6bdcf/memory_layout.png 315w,
/static/427f91b73b8b229ab84ace482e1e2aea/0b533/memory_layout.png 500w&quot;
        sizes=&quot;(max-width: 500px) 100vw, 500px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: Shows the layout of program in virtual memory where the lower address are occupied by the program and the highest addresses are reserved for kernel data.
Source (link opens a new tab): &lt;a href=&quot;https://gabrieletolomei.wordpress.com/miscellanea/operating-systems/in-memory-layout/&quot; target=&quot;_blank&quot;&gt;https://gabrieletolomei.wordpress.com/miscellanea/operating-systems/in-memory-layout/&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
 
&lt;p&gt;As we an observer from the diagram, the program is loaded into the lower addresses of the memory space and the kernel data resides in the higher addresses. This is has great performance as the address space remains same from the view of both program and kernel and no additional data swapping is required.&lt;/p&gt;
&lt;p&gt;A userspace program cannot access the kernel data directly due to the bound checks on the address space. The Operating System sets a base address register and bound register to limit the access of user program within the address space.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 44.93670886075949%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAEDBf/EABYBAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAAB3RzEULn/xAAYEAACAwAAAAAAAAAAAAAAAAAAMQECQf/aAAgBAQABBQI0lVZ//8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQMBAT8BR//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAECAQE/AVf/xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAaEAEBAAMBAQAAAAAAAAAAAAABABEhMUFx/9oACAEBAAE/IUU2FjRwXt0u0e/b/9oADAMBAAIAAwAAABAz3//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QH//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QH//EABwQAQACAQUAAAAAAAAAAAAAAAEAETEQQVFxof/aAAgBAQABPxBuNOLZRIiFXeJu7nndLlD/2Q==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Image showing the bound check where any address is checked to be between a base address and a limit beyond the base address.&quot;
        title=&quot;Image showing the bound check where any address is checked to be between a base address and a limit beyond the base address.&quot;
        src=&quot;/static/48cfad41843afb88d3db0f938f47f22f/828fb/bse_reg.jpg&quot;
        srcset=&quot;/static/48cfad41843afb88d3db0f938f47f22f/ff44c/bse_reg.jpg 158w,
/static/48cfad41843afb88d3db0f938f47f22f/a6688/bse_reg.jpg 315w,
/static/48cfad41843afb88d3db0f938f47f22f/828fb/bse_reg.jpg 630w,
/static/48cfad41843afb88d3db0f938f47f22f/49221/bse_reg.jpg 746w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: Image showing the bound check where any address is checked to be between a base address and a limit beyond the base address.
Source (link opens a new tab): &lt;a href=&quot;https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/8_MainMemory.html&quot; target=&quot;_blank&quot;&gt;https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/8_MainMemory.html&lt;/a&gt;
&lt;/center&gt;
&lt;h2&gt;Speculation in bound check&lt;/h2&gt;
&lt;p&gt;The check for address is slow and hence the processor speculates whether the access is valid or not and continues execution. hen the bound check resolves, the CPU comes out of speculative state and the results are committed if speculation war right else the results are discarded and CPU is interrupted at the point of speculation due to invalid access.&lt;/p&gt;
&lt;h2&gt;Piecing together Meltdown&lt;/h2&gt;
&lt;p&gt;In Meltdown, a userspace program can leak kernel data with a combination of speculation and timing analysis. Consider the following snippet:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;char&lt;/span&gt; device&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;4096&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;kernel_ptr&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
device&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;kernel_ptr &lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;4096&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the above code, &lt;strong&gt;kernel_ptr&lt;/strong&gt; is a pointer to some kernel data we want to leak that is cached. We have a &lt;strong&gt;device array&lt;/strong&gt; that is 4096 * 16 bytes long and we make sure this array is not cached when we try our meltdown attack.&lt;/p&gt;
&lt;p&gt;The attack starts with the access &lt;strong&gt;device[(*kernel_ptr &amp;#x26; 15) * 4096]&lt;/strong&gt; where we access data in device depending on the 4 least significant bits of the kernel data.&lt;/p&gt;
&lt;p&gt;Technically this access should fail but CPU speculatively executes these instructions until the bound check returns. Once the check returns, the CPU discard the results and interrupts but now a part of device array is present in the cache as a result of this speculative execution. The attacker can now use timing analysis to see which part of the array is cached to leak the last 4 bits of the kernel data.&lt;/p&gt;
&lt;p&gt;The paper goes into details on how they recover from interrupt by grouping the access into a x86 based Atomic operations which don’t crash the program when interrupted. On probing the device array they find address for which access takes very less time compared to other.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 52.53164556962025%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABwklEQVQoz6WTzW7aQBSFeccEQeMAC5xuusgGKRJd9DWyaKWqm74AUqUkGyRIHEUI2xHKIrDsj90G47Hxv/1VY+KG0rSbjnRm7txrnzkzc6YGkGUZYRBAnlNk2e+QuSpfxbuQtaKQVNRkl6YpQZbxv02SloR5nvN1OMQ5P2d5cfELztkZq7s7VtMp7miEp2n4moZ3dYW4vMQdjxHjMavRiNhxNgp938dfr/nR6xHv7xMqCtHBAZGilPNvp6eIXo+kXic6PCzz24gVBb/RwJtON4SmaWJZFst+n7TdJlZVkm63HLNWiy/v3iL6fbKt2jZSVSXodPANY0MohCAMQx5OTig6HdKjIzJVLce83cJ+/wHRf03aapE8QyghCdem+XQp8pY/Hx8j9vZwmk2cRoNls0lUb/LxzUvmr7rwQimPI96C3LJcSB5RWCmUnVRomSZLw+C7YWDrOrahY00m3FwPmXwaYGsa4vYWoet4j5CqLE1jNhiwmM2IkuRJYfEPOzy4Aj9NkcbKd2oJIOIY4fskkrAyJEXxjGE3v9uWxWI+Z3F/j+e65bfyEVDkfyxeqwxZEf8t3m1xkhCGEXGcEEYRwWP8E+uGBYAIdcKFAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Access time vs Address diagram for the probe that shows that data at address 7 * 4096 is cached while the rest is not indicating 4 least significant bits of kernel data are 0111&quot;
        title=&quot;Access time vs Address diagram for the probe that shows that data at address 7 * 4096 is cached while the rest is not indicating 4 least significant bits of kernel data are 0111&quot;
        src=&quot;/static/57ad3cbc662d0d9352f98a9f9b66b172/f058b/timing.png&quot;
        srcset=&quot;/static/57ad3cbc662d0d9352f98a9f9b66b172/c26ae/timing.png 158w,
/static/57ad3cbc662d0d9352f98a9f9b66b172/6bdcf/timing.png 315w,
/static/57ad3cbc662d0d9352f98a9f9b66b172/f058b/timing.png 630w,
/static/57ad3cbc662d0d9352f98a9f9b66b172/dba9a/timing.png 652w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: Access time vs Address diagram for the probe that shows that data at address 7 * 4096 is cached while the rest is not indicating 4 least significant bits of kernel data are 0111
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;br/&gt;
 
&lt;p&gt;Based on the timing analysis depicted above, we can say the last 4 bits of the kernel data is 0111 in binary or 7 in decimal &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The access is scaled by factor of 4096 as to detect the correct data even if the hardware prefetcher brings neighboring pages into cache. With an array of only 16bytes, chances are the prefetcher brings the entire array into the data cache.&lt;/p&gt;
&lt;h2&gt;Mitigation&lt;/h2&gt;
&lt;p&gt;Mitigation have been made in both hardware and software to overt meltdown type attacks. The operating system no longer maps kernel data into the same virtual memory space as the userspace program. Instead, it replaces the kernel data region with a stub that traps the access requests and sends it to kernel.&lt;/p&gt;
&lt;p&gt;Meltdown was the first attack of its kind that showed how data can be effectively leaked using the micro-architectural state which was previously thought to be invisible. In the coming posts we will discuss more about different attacks that stemmed after Meltdown, some persisting in our processors to this very day.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please leave a comment and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Speculative Execution]]></title><description><![CDATA[Most of the recent CPU vulnerability discovered depend on the property of modern processors known as Speculative Execution. In this post, we…]]></description><link>https://outofordercore.github.io/speculative-execution/</link><guid isPermaLink="false">https://outofordercore.github.io/speculative-execution/</guid><pubDate>Sun, 27 Jun 2021 13:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Most of the recent CPU vulnerability discovered depend on the property of modern processors known as Speculative Execution. In this post, we’ll take a deeper look at where and why modern processors speculate.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 39.87341772151899%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAACBElEQVQozzWS70tTURzG7x/R2wr6H3pVvamgeiPhLAexiihShOhFxSBJCNGMIBDJIhEaxF6oQ8vQEsW6uOkUl229mXvR3PS6u3vP/TW3pO4+ca75wIdzOHAevs95jlKtViluFdnZ3sZybZ6kX/BwtZdoup/oSh+PVp/Rqz5FWwiz8yVEabaV0ucQxnwLlXQPXq3B3t4ejUYdy7JQDMMgn89TLpVxPJdb6gPakh20p7oIp7oIpe/RuXCTv7Mn8CaOob0/SiV+HP/DERpqmD8+NJs+UrVaDUVums1mcOD7Pp+yc0xsTDOe+chYZorxjWkS61PMrSVY+J5g8UcCNZdgcSPOcnaGql5F13VkUoniOA6bm5tsFYvUf9cJfb3LefUal9QbXPgW4aJ6nbMzYc7NRzgz1c7pyaucGr/CyclWOpd74GC4QK7rHhjK2EII6o06sZ9jvM7FGM7GeJV9x3AuxuDqCC/X3jC4PhIwlBllMPOWeC6BYztID2kmPZT9/f1gZNMwsF2b/rUhulee050a4HFygGiqj4HkEHq5gr5VoVrWETsmYttAaGZgdmhomiaKzF0oFCj+KqLpGpHkfS4v3QmKaVvqoGXpNh1qNPgB2q7Grr6LVpFoCFsE734oz/NQZCGH+E0f27MxbfEfE+EITEsEE8gW5SW5SgzTxBQWlmUHuF6Nf3IMGbhQPpSOAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A illustration that shows speculative execution and how the results are committed or discarded based on result of speculation - whether it was correct or not respectively.&quot;
        title=&quot;A illustration that shows speculative execution and how the results are committed or discarded based on result of speculation - whether it was correct or not respectively.&quot;
        src=&quot;/static/6fc9c9792dc4fc914dff57f770eaf4fe/f058b/banner.png&quot;
        srcset=&quot;/static/6fc9c9792dc4fc914dff57f770eaf4fe/c26ae/banner.png 158w,
/static/6fc9c9792dc4fc914dff57f770eaf4fe/6bdcf/banner.png 315w,
/static/6fc9c9792dc4fc914dff57f770eaf4fe/f058b/banner.png 630w,
/static/6fc9c9792dc4fc914dff57f770eaf4fe/a0209/banner.png 725w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A illustration that shows speculative execution and how the results are committed or discarded based on result of speculation - whether it was correct or not respectively.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Pipelined Execution&lt;/h2&gt;
&lt;p&gt;Most modern processors are pipelined and are often superscalar in nature running instructions out of order, with multiple stages of execution of instruction running concurrently.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 58.22784810126582%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACO0lEQVQoz22T3WoTQRiG50I89k68AaFVROip9u/ICt6ACIKnhXpsUCrpQe2JSEUw1qYppGlMutnEzWZ/ku2m2c1/zWbzyExsQ2oHZl5mYF6e7535hG3X6Ha7mKZJEARUq1Xq9TqaViSf09k7XufVxzsc6K+RI44jpZPJRM2bQ9RqBsPhEF3XCcNQqeM45E6zHP3M8y51j+Utwef8039X4luNrg3DsEWn84dKxaDdDjEMA9d1KVdKnBVMPqTus7ol2Dtew/e6XLT8OcKbpEIuQTBB10263TaWZeF5HvW6Q90OSHxbZHlTkEytkD/RMaq/ry/fWvJ4PKLXA9tu0OsNsG1nathwcWoXbB8ssvpWsHu0QvGXgWWbKqJ+v/9fllJFFEXEsTwcK1LH8fD9c5rNc1yrxc7xAs/fC3bSSxz+yFHSzygWi+RyuTnKKxXTzRS30wHLquN5Dfymh202SWYW2EgIkodLHHzPopWKaJpGPp9XJuPxmDiOZ4Qz5AlRJOeIy8sYx72g5ff5dPpQEe5rq+hnNq5rk81mFaX8DVJHo9F16eK2gKMIjKqP32izm3vAs4Q0XEMr1LAsk1QqxcnJifoRmUwGGdvcK8/nIMuAIOwyGkIy85gX24KvpXVqhq+ikFTSrFQqKVrf91VjDAaDGeGMVK3AWO0TqUdsbAv29SeYlXPa7YByuaz+qnyYdDqtzKTKxhDzZlNCKVct9uX0JZv7dzmqvsGpNQnClmpPaSgJ5ePILAuFAp1Oh7+/6mcBE0lnqwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Pipeline of a superscalar processor with 2 instruction fetch every clock cycle and a 5 stage pipeline.&quot;
        title=&quot;Pipeline of a superscalar processor with 2 instruction fetch every clock cycle and a 5 stage pipeline.&quot;
        src=&quot;/static/0a80897d7a4b2db5ed70abb7e91489d5/f058b/1024px-Superscalarpipeline.png&quot;
        srcset=&quot;/static/0a80897d7a4b2db5ed70abb7e91489d5/c26ae/1024px-Superscalarpipeline.png 158w,
/static/0a80897d7a4b2db5ed70abb7e91489d5/6bdcf/1024px-Superscalarpipeline.png 315w,
/static/0a80897d7a4b2db5ed70abb7e91489d5/f058b/1024px-Superscalarpipeline.png 630w,
/static/0a80897d7a4b2db5ed70abb7e91489d5/40601/1024px-Superscalarpipeline.png 945w,
/static/0a80897d7a4b2db5ed70abb7e91489d5/2bef9/1024px-Superscalarpipeline.png 1024w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: Pipeline of a superscalar processor with 2 instruction fetch every clock cycle and a 5 stage pipeline.
&lt;br/&gt;
Source (link opens a new tab): &lt;a href=&quot;https://en.wikipedia.org/wiki/Superscalar_processor&quot; target=&quot;_blank&quot;&gt;https://en.wikipedia.org/wiki/Superscalar_processor&lt;/a&gt;
&lt;/center&gt;
&lt;br /&gt;
&lt;p&gt;In case of a long latency cache miss, permission check for an access or conditional branches, the processor generally has to stall waiting for these outstanding data and results to be fetched to continue execution. Generally a nop - signifying no operation, is sent through the pipeline and the process is known as stalling the pipeline.&lt;/p&gt;
&lt;p&gt;Stalling pipeline is easy and safe but the processor could have been doing useful work in that time instead of sitting idle waiting for data or results. This expensive idling is what fueled the era or speculative execution&lt;/p&gt;
&lt;h2&gt;Speculating Conditional Branches&lt;/h2&gt;
&lt;p&gt;Consider the following snippet of C code:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;c&quot;&gt;&lt;pre class=&quot;language-c&quot;&gt;&lt;code class=&quot;language-c&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;ptr&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;ptr&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token function&quot;&gt;do_something&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Consider the data pointed to by the address in pointer ptr is not cached, It’ll take several hundreds of clock cycles to fetch the data from the main memory. Idling for hundreds of clock cycle especially in a superscalar processor massively degrades the performance.&lt;/p&gt;
&lt;p&gt;In this case, processor goes into a state of speculation and starts executing instruction based on prediction of whether the branch will be taken or not. This process is known as branch prediction - we won’t go into details of branch prediction in this post but if you want to learn more about branch prediction you can read the Wikipedia article titled &lt;a href=&quot;https://en.wikipedia.org/wiki/Branch_predictor&quot; target=&quot;_blank&quot;&gt;Branch Prediction&lt;/a&gt; (link opens a new tab) which talks briefly about the branch prediction algorithms but if you want to understand how modern processor implement branch prediction in hardware, you can read this blog by Cloudflare titled &lt;a href=&quot;https://blog.cloudflare.com/branch-predictor/&quot; target=&quot;_blank&quot;&gt;Branch predictor: How many “if”s are too many? Including x86 and M1 benchmarks!&lt;/a&gt; (link opens a new tab) where Marek Majkowski takes a look at how Branch Target Buffers work.&lt;/p&gt;
&lt;p&gt;Coming back to the example snippet, the processor may speculate that the value at address pointed by ptr is indeed non zero and start executing the &lt;strong&gt;do_something()&lt;/strong&gt; routine speculatively. It is only later, when the data arrives, will the processor come out of speculative execution state. In case of a mis-speculation, the pipeline is flushed, the processor state is reset to the point of speculation and the execution continues in the correct direction. On a high level, speculation is completely safe as the user cannot read the results computed during speculation and only after a speculation is deemed correct or incorrect, the user can see the changes reflect in the registers. &lt;/p&gt;
&lt;h2&gt;Speculating Permission Check&lt;/h2&gt;
&lt;p&gt;As it turns out, checking whether a program can access data at particular address takes quite some time. In this case too the processor speculates if the access if valid or not and continues with execution or program or stall respectively. Consider the same above example - if data at the address pointed by ptr is cached, the processor may speculate that this data indeed accessible to the userspace program and speculatively execute the following statement based on value at address pointed by ptr. It is only later, when the permission check is complete will the processor come out of speculative execution state. Same as before, in case of a mis-speculation, the pipeline is flushed, the processor state is reset to the point of speculation and the execution continues in the correct direction.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 505px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 52.53164556962025%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB3ElEQVQoz4WSyW4TQRCG5+YgJF4ALHLME+TZQNyQkFDIhRviAJK5sEiAQoK4cgBCvETBS8Y4sYU1g3d73LN6tg91GxtjC9FSqWuqar6u+rs1gDRNWV3yOwgCptMpjuMof71mUbce1xYBuU8mE3q93nLvdrs0m00Mw1Dw8XiM7/vEcUySJBtgaUughPT7fQWSP1uWpfx2u81wOGQ0Gqm8hMqYrus0Gg3q9bqySqXCYDD4A5SFYRguT5SdSOhi7CiKVE4IoeparRbValWBpMkpZOd/AT3PgzQhTWOJJU3kaL/9NFE513XUAbVabQmUcNml1FpLkzlQWAIS/rvG1hwoG5ETlEolJcdCVy1lDqyblxT1TwjzFMvMY3dOsIxjhPkFYR5jGV9xOnnKJ++VDAtppBSrN63V9HO84ZRXrY/cyu3C4U16r7e5fJbFfJHlIncD43kW53Cb4Og6nYNdojBYXO/GTWuFYoH2+QVPah+4nduBtxlGL6+iP8rw4+kW3x9vYeSuEB5cI32Xof9mh9ks2HguS6DruRAlFH/qHH1+iH26x/hsH1HeZ/rtAXb5PuLsHpPSXSaFO3TzeyRx/E+NtfWALE1WLF4zPwJhO3iej+v5OK6H7bgI22UWhvwC5hUwXceURmAAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A block diagram that shows speculative execution in case that check for data access takes longer than fetching data. The processor comes out of the speculative state once the check has resolved.&quot;
        title=&quot;A block diagram that shows speculative execution in case that check for data access takes longer than fetching data. The processor comes out of the speculative state once the check has resolved.&quot;
        src=&quot;/static/72dff352104c079dbedb6fd405b92708/c0cb9/mem_access.png&quot;
        srcset=&quot;/static/72dff352104c079dbedb6fd405b92708/c26ae/mem_access.png 158w,
/static/72dff352104c079dbedb6fd405b92708/6bdcf/mem_access.png 315w,
/static/72dff352104c079dbedb6fd405b92708/c0cb9/mem_access.png 505w&quot;
        sizes=&quot;(max-width: 505px) 100vw, 505px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A block diagram that shows speculative execution in case that check for data access takes longer than fetching data. The processor comes out of the speculative state once the check has resolved.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Pitfalls&lt;/h2&gt;
&lt;p&gt;The main pitfall of speculation is the fact that during a miss prediction, most processor reset their state but the traces of the speculation is left in caches and as seen in previous post of Timing Analysis, we can read the data from the cache using a device and timing analysis.&lt;/p&gt;
&lt;h2&gt;Coming up next&lt;/h2&gt;
&lt;p&gt;In the next post we’ll look at Meltdown, a CPU vulnerability that used speculative execution and timing analysis to read kernel memory.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please leave a comment and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Prime and Probe]]></title><description><![CDATA[This is the third post in our series of Timing Analysis and I high recommend reading the first two posts - Timing Analysis (link opens a new…]]></description><link>https://outofordercore.github.io/prime-and-probe/</link><guid isPermaLink="false">https://outofordercore.github.io/prime-and-probe/</guid><pubDate>Wed, 23 Jun 2021 13:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This is the third post in our series of Timing Analysis and I high recommend reading the first two posts - &lt;a href=&quot;/timing-analysis&quot; target=&quot;_blank&quot;&gt;Timing Analysis&lt;/a&gt; (link opens a new tab), and &lt;a href=&quot;/flush-and-reload&quot; target=&quot;_blank&quot;&gt;Flush and Reload&lt;/a&gt; (link opens a new tab). That said if you are aware about cache hierarchy, shared libraries, shared pages, and cache placement policies, you can continue reading this article.&lt;/p&gt;
&lt;p&gt;In this post we look at &lt;strong&gt;Prime and Probe&lt;/strong&gt;.
&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 583px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 53.79746835443038%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB9klEQVQoz32STWsTURSG5w/qprgRXIili0gxARNXbpJKk4DapUjslHbjtiAGF3ajzYfQUIqLoGiEYDLOzSSZyXx/5JGZSaKJxQOXy4H7Pue85x4JwPM8JpMJlmliWxYzwyDwfTZjPp//cy/PMpem0ymmZRGFIX4U4YYhpusyEILe1+/4no/pe/hBcC1ss5ikFIt4lpUkg9NTlIMDfsoyQpZ5cL7P6zOZyeMSvzoXqTCK1kCGYRCG4Z8OZ5kMtmEQP9EOD5nmcojSHmaxxM12jhf1KtzZRms2UtFCHIeiKFxdXdHr9ZKxJR0auRyOaabAkxNGhQJqpYJRqXKrWaBWf8Z8+z6i1VwDCiHQdX0F7na7BEGANMtmcRfAcQzM51HLFfRyha3mQ2pvn8K9DKKdAomiRDgcDpPU9/3EtqqqaJqGZGazyQxjoDg6QsvnETFwv8xWM8+regrUPrVWwHhm/X5/7TPG4/FfwEWHo+NjtEKBUbWaWm49Qn73PAGqrXSG0cJyLI5tLzscDAZJIUnf2cHW9QSo1GqI3V3UYglj7wk3GllevikT3r7L8PzDaobLrmJQbD22GyzWSpo2GgSLHxLdLkq7jbi8ZNTp8PHHBV++fUZ9f8Z0OLh2mTcXX9pczP/F8o3retiOk9yO42LZDrbtEEURvwFjEx22X7OZgwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;An illustration of prime and probe&quot;
        title=&quot;An illustration of prime and probe&quot;
        src=&quot;/static/9fc4b42662541bfaafb807d4c6aa5f0b/9fc4b/banner.png&quot;
        srcset=&quot;/static/9fc4b42662541bfaafb807d4c6aa5f0b/c26ae/banner.png 158w,
/static/9fc4b42662541bfaafb807d4c6aa5f0b/6bdcf/banner.png 315w,
/static/9fc4b42662541bfaafb807d4c6aa5f0b/9fc4b/banner.png 583w&quot;
        sizes=&quot;(max-width: 583px) 100vw, 583px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: An illustration of prime and probe
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Cache Replacement Strategies&lt;/h2&gt;
&lt;p&gt;The placement of data in cache is discussed briefly in Flush and Reload post. Here we will take a look at how data is replaced in cache. There are many different strategies to evict data from cache when a new data is needed to be stored in a filled cache set. Some of them are (some more practical than others):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;First In First Out (FIFO)&lt;/strong&gt; - The logic behind the First In First Out is that the data that came first is probably the one that won’t be used again for long time and hence need not be cached.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Last In First Out (LIFO)&lt;/strong&gt; - The logic behind Last In First Out policy is that the data used last will not be used again for a while and in case of spacial locality the first data will be fetched first and that will lead to a cache hit.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Least Recently Used (LRU)&lt;/strong&gt; - The data that hasn’t been accessed for the longest will be evicted. This policy uses past access as a metric to predict future.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To know more about cache replacement, you can read the Wikipedia article titled &lt;a href=&quot;https://en.wikipedia.org/wiki/Cache_replacement_policies&quot; target=&quot;_blank&quot;&gt;Cache Replacement Policy&lt;/a&gt; (link opens a new tab).&lt;/p&gt;
&lt;p&gt;The main takeaway from this section, to understand prime and probe, is that whenever cache set is filled, some data is evicted from the cache set to make room for the new data.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 489px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 160.75949367088606%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAgCAYAAAASYli2AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFYklEQVRIx5WW+09b9x2G/cftl41k7aaUrWkzllIGGQSGAUMIKh3g2FyiBBKaZlHbtE26SP0LslyaTSUaqFKHwQ0Y4jv28bnfbMCX80zn2BAD6bR8JMu27O+j9/3cvscH4DiO+0ZpdxchEkHc3KSwuYnw4gViNIqwukohFiO7soJtmhycOTi3X95nW4wjWTK+ZqBumqgDA4izs4jhMMbYGJlgEG1oiOTcHFp7O2omUwfWatScmvc5pwr8+tEHLEbuHgUaloXZ3484PY0SCmGPjnpAKxAgPTeH/eGHqNnsK2CtDhR0kZanbdyIfH4SaPj95MNhlHAY8/JlMqEQekOh1dGBkc/T8MxBFHSJU0/+yOLqaxQa/f2HQN1V2ACmZmcpdnaS297mZSKBpqpYtkXJLpLMpTj99Dw3I1+czOEBUD0GzLiWOzpQMhn2ymXK+/tUqpV6DuU8p56cZ3Hty5NAvb+fXCiENj2N7lp2wYEA2YZlbWfn0PLBuYIqcvrpB3wa/fooUDMM9L4+csEg5swM1tgYO6EQ1uAgeRfoVrm5KI0qi5rEW8/aufPimwawUS1V1xEHBkgFgyhzcxjj42SuXkUZHfUUSh0dyEeAdSGKofL243burN/H56k7aND9faRYDCWZRE0kUNwGTyQQ43GkrS2v6Yu2faKxK5UKkfxPZLVcXWGxUkFUFDRNQy+VKFUqlJva4ng4Tb85x/7nc6pVNh4+RNzaolyrIScSZDc3ScdiJNbXSaVSyLKMLgie8lKxeEJhtVYlbxQwSiY+LZul0NKC8uABiuOQu3SJ9Ogo8rVrSENDbMfjCLpO8vZt8l1dSK8pSkEXOfOPTj5b+zs+M5fDbm1Fe/AAqVbDGB6mMDSENTWF3dNDNp9nD8guLFDq7EQThBOjl1Py/PLJH7gV/aoOtN55B/X+feRaDXV4GCEQwLxyBePiRdI7OxQdh9TCAlZXl2f9eLjLoeVxW70PrXy+Drx3D7lS8TaLMDSEEQxi9PSQyeU8YHJ+ntKFCwjJpDd6hq5TLBWpliskhRQtT9q4tf5VHWg3gEq1ijY4WAdOTWH29pLO5z1g4vp1ihcuIKbTSIqCaZpNwLQH/MQdPdtV2NqKcu8emuN4c5tvKLT6+sg0gK5C+2cs51WBXz1uY3H9Lj5LEA4V6u60+P0URkYwQyGKfj+CLLMLpBcXPYX6a4si1LdN9C4+u1BAPHMG49tvMdxl2dXFjt+PMj6O3d1NTpawqlXPsnbu3LHRe1XlXzw6y8yPt/Bl02ki333H9tqad6fkIhEKGxsUolGktQiSJKOqOvL2Nrkffnjt6JX2Sjx6+U+iuQ18drGI4t4luk65XPaqZypKfTdatreNU1Ia3TLRdZ3dUunIyJ0YveYvlttv4+PoH39M/MY8pcBlZpdu8tt/XWT1bwvI59spbMUOLTdDq049Bd628ZLrOLhm5I8+Yu/SJTKzM/DnvxB+Ps/p5R42bs9T/N27SLFNmlfe8Xi1YB0H14wyOYk9MkJ8Oky120/4++u8vdxL9M4NrLPvI74JcLcBNIeHiYdDVLv7mV6a563lXtZd4LvveQ8BbwSUJiYwAgHiV4IecPb5DU/h+mc3PaDUlMP/CyhPTKAPDpKYmqTa42d2qQ786fNPsM++/2ZAN4fa5CT6wADJib9C7yBXl27ym5U+Nr/4lN1zbSgvt08Am3vyyK3nVlkcG0Pt6yM2Mkz1TxeZeXaNU8+7idy6jtX6+yPAA1Dz6wjQvQKyy8uIKyukl75HfPqMH1/+h2fxf5ONrJJ7+BBLVflfcdjYzrHnlZ+LcqWKYVremJZ297CLJSy7iGnZ7JfL/BfZCcb0P2TVswAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A depiction of cache replacement where when a new data arrives at a populated cache set, data from a particular cache line is evicted based on the cache replacement algorithm and the new data is filled in.&quot;
        title=&quot;A depiction of cache replacement where when a new data arrives at a populated cache set, data from a particular cache line is evicted based on the cache replacement algorithm and the new data is filled in.&quot;
        src=&quot;/static/8875175fe0efcaa56dae3d4b3ce6cddc/03e1f/replacement.png&quot;
        srcset=&quot;/static/8875175fe0efcaa56dae3d4b3ce6cddc/c26ae/replacement.png 158w,
/static/8875175fe0efcaa56dae3d4b3ce6cddc/6bdcf/replacement.png 315w,
/static/8875175fe0efcaa56dae3d4b3ce6cddc/03e1f/replacement.png 489w&quot;
        sizes=&quot;(max-width: 489px) 100vw, 489px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A depiction of cache replacement where when a new data arrives at a populated cache set, data from a particular cache line is evicted based on the cache replacement algorithm and the new data is filled in.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Prime and Probe&lt;/h2&gt;
&lt;p&gt;In prime and probe, the attacker threads fills the cache set where the shared library routine will be loaded. As cache placement is deterministic based on the address of the data being loaded, attacker can fill a cache set very easily with junk data.Once filled, the attacker its and tries to read this data again. If he can access all the data quickly, they are still in cache and the shared routine must not have run since cache was last primed. If one data access takes longer that other, the data has been evicted from the cache and the shared library routine might have run since cache was last primed.&lt;/p&gt;
&lt;p&gt;Thus the attacker can prime the cache set with his data and probe it at regular interval timing the accesses. The advantage of prime and probe over flush and reload is that we don’t depend on the micro-architecture to have implemented an instruction like clflush and we use the design and behavior of cache to spy on victim. With prime and probe, the probe in fact primes the cache for the next analysis as reading data will cause the data to be cached again but priming cache initially takes longer.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 559px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 241.13924050632912%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,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&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A step by step look at how prime and probe works on a blocking cache - the data from victim thread evicts the data from cache primed by the attacker. When the attacker probes the data, the he finds cache misses and following an LRU replacement scheme, the victim data becomes the least recently used data and is evicted at the end after all the probing thus priming the cache set again for next round.&quot;
        title=&quot;A step by step look at how prime and probe works on a blocking cache - the data from victim thread evicts the data from cache primed by the attacker. When the attacker probes the data, the he finds cache misses and following an LRU replacement scheme, the victim data becomes the least recently used data and is evicted at the end after all the probing thus priming the cache set again for next round.&quot;
        src=&quot;/static/07e25d281fd32f607987157b1ab6222e/a65ce/pnp.png&quot;
        srcset=&quot;/static/07e25d281fd32f607987157b1ab6222e/c26ae/pnp.png 158w,
/static/07e25d281fd32f607987157b1ab6222e/6bdcf/pnp.png 315w,
/static/07e25d281fd32f607987157b1ab6222e/a65ce/pnp.png 559w&quot;
        sizes=&quot;(max-width: 559px) 100vw, 559px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A step by step look at how prime and probe works on a blocking cache - the data from victim thread evicts the data from cache primed by the attacker. When the attacker probes the data, the he finds cache misses and following an LRU replacement scheme, the victim data becomes the least recently used data and is evicted at the end after all the probing thus priming the cache set again for next round.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;br /&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The diagram depicts a blocking cache where only one outstanding request to cache can exist. In modern microprocessors, the caches are asynchronous and the LRU counter is updated dynamically. The end result is however the same - if victim doesn’t calls the shared routine again in middle of probing, it becomes the lease recently used data as it was brought in before the probing began and will be the one to get evicted.&lt;/p&gt;
&lt;p&gt;How secrets can be leaked using shared memory access is discussed in the previous article of this series titled Flush and Reload but the basic gist behind the leak is if the call to shared library routine is based on a secret in the victim thread, the attacker can infer information about the secret and can, in some cases, discover what the secret is entirely.&lt;/p&gt;
&lt;h2&gt;Complications&lt;/h2&gt;
&lt;p&gt;Prime and Probe have the following complications associated with it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The attacker and victim should run on the same physical core on separate threads at the same time.&lt;/li&gt;
&lt;li&gt;The attacker and victim should share the last level cache. Without shared cache, this type of attack will not work.&lt;/li&gt;
&lt;li&gt;Probing the data takes some time and the victim thread must not make a call to the shared library routine in middle of probing else based on cache replacement strategies, the cache set might not be primed in the end,&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Scenarios&lt;/h3&gt;
&lt;p&gt;The following images depict the optimal scenario for prime and probe:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 59.49367088607595%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABYElEQVQoz6VTy27CMBDMR3JD3MiNEzeExJ9xQuLxBQUOlRCvxHlR24kTO8lUa0hUoFUlWGnkzcoe7+zETl3XoMjzHMYYmze1V8JpkjRNLenbhNSV1toSFkXREr4Kh3MO3/chpWwlvxN3komcuqVOf4Jqj/WyLG0DBBqVUsrmTjOvVEpIzmG0Rq6U3UAbCQ1J802XM8YQBgHCMIRMU2RZZi9tCbM8B7tcEAkB9Y90UrLebPB5POJjvbbjepYcx9gtl9jN50i2W9R/mEOhjUFwPmM/neJ8OKDQujXTIZkKgFgsILpdmH4f0Xh890/eoapsvYxjhK6LPAiu+6rqSsg8Dz7n4LMZVKeDuteDGI1Q3Q4+xa3LKkmQDAZQjP3uslitEHa7yFwX0WTSvpxHlLTSiHwfh+EQyX6Pwpj2YbSmFEohOp0Qex4ujEEKYYed3hxs0LhPaxLF4FxACIkvLpBlCt9bOJ05caKiiQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The attacker thread primes the cache and finds no cache miss in next probe thus deducing that victim didn&amp;#39;t call the shared library routine.&quot;
        title=&quot;The attacker thread primes the cache and finds no cache miss in next probe thus deducing that victim didn&amp;#39;t call the shared library routine.&quot;
        src=&quot;/static/1f82f3042b9a10fc24065de76928a383/f058b/2.png&quot;
        srcset=&quot;/static/1f82f3042b9a10fc24065de76928a383/c26ae/2.png 158w,
/static/1f82f3042b9a10fc24065de76928a383/6bdcf/2.png 315w,
/static/1f82f3042b9a10fc24065de76928a383/f058b/2.png 630w,
/static/1f82f3042b9a10fc24065de76928a383/f8067/2.png 726w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The attacker thread primes the cache and finds no cache miss in next probe thus deducing that victim didn&apos;t call the shared library routine.
&lt;/center&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 60.12658227848101%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACL0lEQVQoz32T209TQRDG+9fxYEzAF1FSwNILJK2J0RjfefONBMJ/wgO8GIhUoCFSLhYoYAu0wGk5Pdc99/7MntoDKnGSLzu7O/l2Zr7ZVL/fR5rneYRhGPvDsygIuWxectO+4eryio7SYWjDmL8tNbywLAvf94fRmMLirHHO3mE1Ru20xsGPA65vWwnhU6SpKIrizEzTfEQIn6vLvPxWZKbykemdD0xvvWdy+x2F8idsT/xB+hgpx3Fot9v0er2kZEk4v7fAyNdJxsoFRjdzjJXzPN+c4fXmW0zH/B32RIZDx7ZtJHkQBhD0ma8sMPIlzYuNPKMbWUbXszxbf8Or9SKapcePygQkgiCIIatNeigJLdPEc11c4XDcPmWruUvleo/K9Xe2r3YpNyvxmWEaGJqOqesYmoZpGHHLXNd9IJSbrqahqCqGEPzPPN/nsF7n+OIiXk3H+bdkVwjaR0f83NmhU6sRyhL6EWEUEsbrwI8AR1VprK1xvrrK2coKer2eiJRyHQfh+5iNBk6xSJTPY87OIrrdQVAUPagYRYMRq1Zxpqbwczn8iQn0xcX4IWQP77tdWre3dE9O8HI5wnQaO5PBV9VkJh9N86Df+/t46TRBJkM4Po6xtJTo/aByq0WvVEIUCqjFIkJRCPp9At9PVJS+zESrVlHn5jBKJaxsFmV5Gcv3cYQYiCIhe9ZTFNS7OzRFiVWTv0eqL4RIIEdLwjYM1E4HrXuP0dPQDRlv8wttBW1QD3Kv9QAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The attacker thread primes the cache. The victim thread loads the shared library routine evicting some data from cache set. The attackers finds a cache miss in next probe thus deducing that victim called the shared library routine.&quot;
        title=&quot;The attacker thread primes the cache. The victim thread loads the shared library routine evicting some data from cache set. The attackers finds a cache miss in next probe thus deducing that victim called the shared library routine.&quot;
        src=&quot;/static/0a63ec2ef646a3f6eb92404e50a63d50/f058b/1.png&quot;
        srcset=&quot;/static/0a63ec2ef646a3f6eb92404e50a63d50/c26ae/1.png 158w,
/static/0a63ec2ef646a3f6eb92404e50a63d50/6bdcf/1.png 315w,
/static/0a63ec2ef646a3f6eb92404e50a63d50/f058b/1.png 630w,
/static/0a63ec2ef646a3f6eb92404e50a63d50/f8067/1.png 726w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The attacker thread primes the cache. The victim thread loads the shared library routine evicting some data from cache set. The attackers finds a cache miss in next probe thus deducing that victim called the shared library routine.
&lt;/center&gt;
&lt;br /&gt;
&lt;br /&gt;
&lt;p&gt;The following scenarios show where the attacker can misinterpret data if they fail to plan the timing between prime and successive probes:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 50.632911392405056%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB4UlEQVQoz32Sz2sTQRzF90/rwVMPkR5aKFJy6aG0CEUKvXlQ0VPppeYQKApeexEv/rbQ1ijEBqyIpCE1MUk3281u3M3u7Ozu7Edm00ilki+8mWH48r7z3hsDIEkSoijSRzKyfBfDgPNWD+uXyaBng+Jv5T0Z/y1DL2maEgTBuFllvPz5gVLtKeXjZzkeV5/w4vQ1rWGH541XjPkysuw6DE1kWRZCiPEIBRtfHnDj8BY3K8sUPi7n5zvH96j0qmxWHzGtDKVULtf3fWQsiUPJRuU+M28WmH1XZPZ9kZm3C9yu3OWw9ZnNTw/JpCJJk9wqDSllzqGV5pI16cj3SaQkFhGndpNa/4Sa+Y2aeUK1/5UfgwbOyKXhnBHLmKHjjOG6REJcJxwGAV3HwZ1In1Laq7Nej+/NJvV2+2peGCiVXwyPjrgol3H39ohGPoqMVKVXoPLBujcOQwa7u5hbW/S3twnq9ctAFcZFv8+55xHu7EChgFhZIbLtqS+UnodcXSVbXCSenyc4OLgMVGFkaUoMOKUS3twcztoav7tdoiTJk9feaGjjNeIkwbNt7PV1vGKR4dISg/19pB4kBAbZ+IeGloXfaBC020RhSBzH/2CS6CRVYZqITodRq0XgugShQEQRfwDY1d+W/p+YxAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The attacker thread primes the cache. The victim thread loads the shared library routine evicting some data from cache set. The routine is run again in victim before the probing as a result of poor timing. The attackers finds a cache miss in next probe thus deducing that victim called the shared library routine once when in fact it ran twice.&quot;
        title=&quot;The attacker thread primes the cache. The victim thread loads the shared library routine evicting some data from cache set. The routine is run again in victim before the probing as a result of poor timing. The attackers finds a cache miss in next probe thus deducing that victim called the shared library routine once when in fact it ran twice.&quot;
        src=&quot;/static/ded049832de1d227db332998996c0eb0/f058b/3.png&quot;
        srcset=&quot;/static/ded049832de1d227db332998996c0eb0/c26ae/3.png 158w,
/static/ded049832de1d227db332998996c0eb0/6bdcf/3.png 315w,
/static/ded049832de1d227db332998996c0eb0/f058b/3.png 630w,
/static/ded049832de1d227db332998996c0eb0/39a20/3.png 859w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The attacker thread primes the cache. The victim thread loads the shared library routine evicting some data from cache set. The routine is run again in victim before the probing as a result of poor timing. The attackers finds a cache miss in next probe thus deducing that victim called the shared library routine once when in fact it ran twice.
&lt;/center&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 51.26582278481012%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACD0lEQVQoz12STUsbURSG88e66KJdlCouSlC6KBUXgj9C8GOtBYUW2kID0kWhFbIodCMWrSX2w6JiwMTEdpLGTMbMZObOnY8785R7E8H0wHvP4Z5zXt57zi0ApGlKFEU6JM9zgxvrtWyufv/Ftq4IHJ/bdrvuxgr6UEohhDAXWZ4Zfy1dXh2/5cXPEs9/lHh5tMXGt9ccdU7Y/1OhF16PCbhBIQxDbNtGSjlGWPcuub/zmImDOR7uzzL5ZY67n6fZqn1g5fAZVbc+qh9XWdDqNKlWmGUZSZqYRM1pcO/jDA92nvBw9ykTu7Pc+fSIN2fvWD5Y58SumrpUKTKlzNh0v3myDgaeRywlUggiGeEGHt9bvzi0jtirf2WvdsD+ZQXLbVPrNXCFh/ADHNvm2nFMvxY3JFSKvhBYjkM/DMeekIqEZu2SRtPCadtjuX4QcNZsclKv4wwGo6XkOXpqXqWCXSrRL5dJRqRKpSjAbVzQ3n6PSGLyPCPLFHpyzvY23bU1euvreOWy4Sn0ul06vo/Y2IDJSeT8PNIeKVFq6KpVBktL/P9J9F1WLJIXi4jl5SFhliToH+hubhJOTeEvLBB2uyaZxrFRGBwf01lcROY5cRQZSKWwV1bwpqcZzMzQW11FJslwhtqCdhv39BTv/Bzf88zmNWQcIz0PYVlmo0mSDJGmhJ0O/sUFotHEb7WQUcQ/WLbZvnpSltcAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The attacker thread primes the cache. The attacker probes before data for the shared routine could be loaded into cache thus detecting no cache miss deducing that shared library has not been run when in fact it is being loaded concurrently. The victim thread loads the shared library routine evicting some data from cache set. The routine is run again in victim before the probing as a result of poor timing. The attackers finds a cache miss in next probe thus deducing that victim called the shared library routine once when in fact it ran twice.&quot;
        title=&quot;The attacker thread primes the cache. The attacker probes before data for the shared routine could be loaded into cache thus detecting no cache miss deducing that shared library has not been run when in fact it is being loaded concurrently. The victim thread loads the shared library routine evicting some data from cache set. The routine is run again in victim before the probing as a result of poor timing. The attackers finds a cache miss in next probe thus deducing that victim called the shared library routine once when in fact it ran twice.&quot;
        src=&quot;/static/95f6574a05a8e320749ed44968d6eb85/f058b/4.png&quot;
        srcset=&quot;/static/95f6574a05a8e320749ed44968d6eb85/c26ae/4.png 158w,
/static/95f6574a05a8e320749ed44968d6eb85/6bdcf/4.png 315w,
/static/95f6574a05a8e320749ed44968d6eb85/f058b/4.png 630w,
/static/95f6574a05a8e320749ed44968d6eb85/39a20/4.png 859w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The attacker thread primes the cache. The attacker probes before data for the shared routine could be loaded into cache thus detecting no cache miss deducing that shared library has not been run when in fact it is being loaded concurrently. The victim thread loads the shared library routine evicting some data from cache set. The routine is run again in victim before the probing as a result of poor timing. The attackers finds a cache miss in next probe thus deducing that victim called the shared library routine once when in fact it ran twice.
&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h2&gt;Coming up next&lt;/h2&gt;
&lt;p&gt;In the next post we’ll look at other side channels which exist in modern processors and attacks that use these channels effectively to leak secrets in real world application.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please reach out to me and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Flush and Reload]]></title><description><![CDATA[This is the second post in series of timing analysis. If you haven’t read the first post - Timing Analysis (link opens a new tab), I highly…]]></description><link>https://outofordercore.github.io/flush-and-reload/</link><guid isPermaLink="false">https://outofordercore.github.io/flush-and-reload/</guid><pubDate>Wed, 23 Jun 2021 12:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This is the second post in series of timing analysis. If you haven’t read the first post - Timing Analysis (link opens a new tab), I highly recommend reading it to understand why these attacks are possible. If you have an idea of inclusive cache hierarchy and how OS loads shared library into virtual memory, you can continue with reading this article.&lt;/p&gt;
&lt;p&gt;In this post, we will look at &lt;strong&gt;Flush and Reload&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 59.49367088607595%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACEElEQVQoz4WSz08TQRTH+8d58CL+CpoY4AAVicbEg4ly0Jh48eCBGI9G/xAjxqilrUUI1R6ICGKhu13sdmd2Z3dnt/sxM4WiFONLvtl5+16+877vO6WiKDCRJAlZlnFaFHkx/q8oTu0tHR2iKLKkJgaDAfv9Du1gny13h0+tVXYP2uz22jh9d0R2GmnJTKW1/oswTmMWKotc+HCdKx9vcrVyy37Pvy9zp/aIVKcjwpMoCSFwXZcwDNGZHsrPUuar9zm3MsellQUursxzubpg89v1h6SHff+VbMjzLEeEkvLyXc6+mWZieZaJt3MWZ15f48a7e8hQWlVxEltVBnEcWw9KR3swE0oh0EmCUopN9xsbnRYtb5O1dpO1vSYbbouWs2nraZpa6YbI5GYgc8mIMDV71JrBSQ0DcH526O67/FnM4wwl1b8lqyDgR72O12ySRRHmmiRNcLsuBQVO12Vr+zs6Hz6t+s5nVrfXx8wphUIQA7JeR87MEM3O0q9WbaMMAnzfHz2lXq9n92disfGEpS8vhtMW+TFh13FwhUBUKsSTk+ipKaJabdioNZ7n2d0YeAce+SC3tQfrT3n29eVwQopxybLRwJ+eJiyXCapVskNCs3THcSzM2RJm8LixxPP1V5BCFCuUGr7jY1OUwt/bI+h0kL5vXTcwDppG46ohNDC5jCS/+j5ShggZEgiJUjG/AVjredLmLK+BAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;An illustration depicting flush and reload attack using timing diagram&quot;
        title=&quot;An illustration depicting flush and reload attack using timing diagram&quot;
        src=&quot;/static/0de702cd1489b3fb2b53fb41d1c456a1/f058b/banner.png&quot;
        srcset=&quot;/static/0de702cd1489b3fb2b53fb41d1c456a1/c26ae/banner.png 158w,
/static/0de702cd1489b3fb2b53fb41d1c456a1/6bdcf/banner.png 315w,
/static/0de702cd1489b3fb2b53fb41d1c456a1/f058b/banner.png 630w,
/static/0de702cd1489b3fb2b53fb41d1c456a1/f8067/banner.png 726w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: An illustration depicting flush and reload attack using timing diagram&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)
&lt;/center&gt;
&lt;h3&gt;Cache Placement&lt;/h3&gt;
&lt;p&gt;Cache can be designed in few different ways. Cache has to store address and the data at that address. We have to map an address to a particular cache line and depending on design, there is a tradeoff between data retention in case of conflict and time to access. The following are the popular mapping (taught at an undergraduate level) for mapping addresses to cache line:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Direct Mapping (1:1 associative) - Each address can be uniquely mapped to a particular cache line. For example, assume a system with 4 cache line that stores one byte each, (address % 4) gives the cache line to load data into.&lt;/li&gt;
&lt;li&gt;Set Associative (1:m associative) - Each address can be mapped to m cache lines - This is known as a cache set. Modifying above example consider a cache set with 2 lines, the data at address will get loaded into (address % 2) cache set.&lt;/li&gt;
&lt;li&gt;Fully associative - Here any address can be stored in any cache lines. The circuit used to resolved the correct cache line for a given address is more complicated than the other two.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To read more about cache placement policies, you can read the Wikipedia article titled &lt;a href=&quot;https://en.wikipedia.org/wiki/Cache_placement_policies&quot; target=&quot;_blank&quot;&gt;Cache Placement Policy&lt;/a&gt; (link opens a new tab).&lt;/p&gt;
&lt;p&gt;The main takeaway here is, with most popular design, the cache set for a data can be determined from the address. In case a new data is to be brought in to a set that is occupied, data needs to be evicted to make room for the new data. To know more about cache replacement, you can read the Wikipedia article titled &lt;a href=&quot;https://en.wikipedia.org/wiki/Cache_replacement_policies&quot; target=&quot;_blank&quot;&gt;Cache Replacement Policy&lt;/a&gt; (link opens a new tab).&lt;/p&gt;
&lt;p&gt;The diagram below depicts cache eviction in case of conflict for direct associative cache.&lt;/p&gt;
&lt;center&gt;
![Data at address 400 is resolved to cahce line 0](./1.png) 
Alt: Address 400 is resolved to cache line 0
![Data at address 400 is loaded in cache line 0](./2.png) 
Alt: Data at address 400 is loaded into cache line 0
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 438px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 87.34177215189874%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsTAAALEwEAmpwYAAACIUlEQVQ4y42U34rTQBTG80Li9YLeipcu6Dv4CD6HsBfCSldYWl3R7uKFIv6rFKrQLjWx7XpnW5r+S9ts0naTyUw+OSedkK7b3Q4M57Q588v3zZmJEccxaNLQkXMk+XHzPR5/e4Lvf3/g3HFh923Yto3xeIzJZMJRT9d1YaSAFUxKiSiKEIoQUMDeaQ63P95HvlVE4F5ASMHA0WjE9cPhEP1+n9c5jgMjq3C5XHIhPSAlf8wzPK3s4+7XRzg6e4fIDxFGggFUQ4OUEZSAtDYFKqUwnU7XLUvguVXAzuddvGydIPIFK7wKSK4oX7OsiyiXseT8Res1dj49QKF5DOGF1wJZIdmkOZ/POZJSVhyrBNgk4C4KzSLC8wDiGsussN1uo1QqoVwuo1KpcPQ8L7V+0HjFlvPbAgeDAQM7nQ7LJpX0UCFRmPu9AjaKEASUNwDpYb1eTwv0kCvLOUsD3yLasIc00y5nIbrj2T3UwMPGm7TLpEgD9TFbOza6EVlo2pTGEe58ecjA0AsQyYgBdEu0Qsr/OzaXlWrLz34d4taHe9g381hM5ghEyAu1QuoBAfWx2whUK8U/2zXsnR7AGrQwc6Zr95gm2aQ4m804Xgm8fL+3GUEQ8D5uVJh+LFRyY7rdLmq1GkzTRLVa5d+WZfHZJdt6nXHTmzV4sVig1+txh8kmfaoo0n++76f1xjZ2stZFJCFVDCkVpFK810EosLxILP8DDPL935pz2WwAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Data at address 480 is resolved to cahce line 0&quot;
        title=&quot;Data at address 480 is resolved to cahce line 0&quot;
        src=&quot;/static/8074f99b8614bd40c935bb26bf6ae182/50e4b/3.png&quot;
        srcset=&quot;/static/8074f99b8614bd40c935bb26bf6ae182/c26ae/3.png 158w,
/static/8074f99b8614bd40c935bb26bf6ae182/6bdcf/3.png 315w,
/static/8074f99b8614bd40c935bb26bf6ae182/50e4b/3.png 438w&quot;
        sizes=&quot;(max-width: 438px) 100vw, 438px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;
Alt: Address 480 is resolved to cache line 0&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 264px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 162.0253164556962%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAgCAYAAAASYli2AAAACXBIWXMAAAsTAAALEwEAmpwYAAADfElEQVRIx6WW227aShSG/ZC9aNyoaoryVt2X7U2bJ6CUkhalhSgKUrLVBEPMwdjG4COGxBj+rX9gLEOgyW5HGtmewzf/mrVmjRUAeHh4QBAE8H0faZqyCcvlEn9SlDAM8c+7d/j08SM+vH8Py7JEx2KxEND/W5V5mqLZakFrt/Hvr1+YTqf4m6LMkwTeYADfNBF7HtL5HEmSYDgcwnVdjMdj3N/fC8WTyUTUKIown8+FIn7HcSyEcLsUQ9Nwo6pwXr9GW1XRq9Xg+D60ZhOj0Qjtdht3d3digZubGziOI747nY5YjP3sM01TbJdiahpGR0dAoYCZqsKq1WD7PqIgECZQSa/XEyA6TbZ1u10MBgPhUBaqMwxjBbSPjrAoFBC+egXz5084QYDA88RAmsLJBFIxC01kGxfiO8tsNoOu61DMVgvDt2+xLBQQqSqMHz8wjiKEa4UcKIE0UQIJYzv7WbjPNF8Z6jqcHLB3dgYvjhGuzdsFpCP6/f5u4Jj7swaGqoputSqAwW+A9PJeoGcYm8Dv3wXQX+/hPiAdsBMYmOYGsPPt2wrounuBPF37gZaVOSU8OMiA3hNAhsxOIE8IwyYPdCcTeOvJnMAgfjaQx85aB7YAnp6ugH9qsmsYMN+8yYD66emTJv/WKfuAz/Eyg3s3MGeyXqk8GYcysAklaDOwt4Ffv65OSu7oyeSQB7KNjnkM7Pc3nKKXywIYhWE2kEqYGLbPMtPVToWWjMOXL6F/+SK8nAcy120DuQ22bT8Gcg/tHLBTKmEUhtkeciAnEiaBTGmMzW0gE68Ajo6PgeNjTA4O0P38GcMgyLINEyfV8Trw1p7nZCrcNpmLKE63i87hIaLDQ9gvXqBTLIqMba2zMVXRZALpBC7AzC1TP7O3zOICOKXHajUY9ToGjQbiIEA8naLVaonQ4EQC6O3b21uhSnqdJ4ZKuaB0kvI3VyZvQipjlT8ICq/CRZqKiuVSdMqLZ7vISfuKuOjzvx1csV6v4/r6Gufn52g0GiiXy7i4uICmaeISurq6QrVaFW2Xl5cZKPtzyAP5bDabYvDJyYmAsxaLRQHjAuwrlUqoVCriSRF5qJKXu+v9uSbLOY8UyndOTsWmp6JN/jzxmSTzbIsekmRD5SOF8hlNphiOXNjOGOEkhh9EcMYe4ukMI9eH54fwghC242Lsrb650H9xy0L1I0vsKQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Data at address 480 is loaded in cache line 0 overwriting data at address 400&quot;
        title=&quot;Data at address 480 is loaded in cache line 0 overwriting data at address 400&quot;
        src=&quot;/static/4170c618e912fcaa52a3ca4893238dcf/e61aa/4.png&quot;
        srcset=&quot;/static/4170c618e912fcaa52a3ca4893238dcf/c26ae/4.png 158w,
/static/4170c618e912fcaa52a3ca4893238dcf/e61aa/4.png 264w&quot;
        sizes=&quot;(max-width: 264px) 100vw, 264px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;
Alt: Data at address 480 is loaded into cache line 0 overwriting previous data
&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 438px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 87.34177215189874%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsTAAALEwEAmpwYAAACA0lEQVQ4y42Uy27iQBBF/WlRtkjJ1+RjssgiUh5IkERZZI8EChvQSCBF2Y2QB2P8ZHi27bZvdCvTjiEzHlpqlaGrj+91VbdVFAU4OUz880OC8/IC9+IC4esr5osFXMeB4zjwfR9hGEo0c7FYwPra/wnQWiPLMmRJghSAe3WF5PQUUbsNf7dDnqYC9DxP8ufzOWazmewLggBWVeF2u5VELlDJj/d3/Ly8RHp+jvD5GXGaQqepAJjDQWWEEsi9JTDPc0RRtGc54YbbW6hGA8HTUy2Qrvi8Z9kkyUu0BnXHzSZ2jQb8x0dESVILFIW0ybleryVSqXyCPEcOIDLAhweEStVaFoWTyQSdTgfdbhf9fh+9Xg/L5VKSCQzu78Xy0UAuEmTbtsimSi4ahf7dXQmss7wHHI/HZUI5DoHtNuIkkbY5BHKWVa4yTMWr39AAvVZLqkwgFRmgabO9tikLUYEaYNBsQp2dwW+1ECmFPMsEwFNiFPL5W9scKjVA7/oa25MTeDc3mK/XyJSSjUah67oCNG33T6BRHAwGcvx+v73Bi2PMKueYkzYZ4ziW+FegQCsXxDFDsaW0rrFMlSw2WwjAL9vGcDjEaDTCYDCQNmN3sOVo2+yz/vdmY32z2WA6nUqFaZNXFSP/W61WZb51jJ3qPZlmGjovoHUOzcIVBVSSYrv7tPwBryEDxNM/NEUAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Data at address 400 is resolved to cahce line 0&quot;
        title=&quot;Data at address 400 is resolved to cahce line 0&quot;
        src=&quot;/static/29c5251517317cdfc30c65f448b48cf1/50e4b/5.png&quot;
        srcset=&quot;/static/29c5251517317cdfc30c65f448b48cf1/c26ae/5.png 158w,
/static/29c5251517317cdfc30c65f448b48cf1/6bdcf/5.png 315w,
/static/29c5251517317cdfc30c65f448b48cf1/50e4b/5.png 438w&quot;
        sizes=&quot;(max-width: 438px) 100vw, 438px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;
Alt: Address 400 is resolved to cache line 0
&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 264px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 158.22784810126583%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAgCAYAAAASYli2AAAACXBIWXMAAAsTAAALEwEAmpwYAAAD1ElEQVRIx6WWS28bVRiG568hAYsmgQUFBEhN3CKkFlViASvoihW/oewipWySLMiCJG7dRpR23CSOPXac+BKP7Tg3X+bq8YwT+0XvcWYy8SVAONbRjI/mPPN+l/N9IwGA53kwTROWZaHX63EJ/X7/VlM6PT3F01+fIvYyhme/PUOr1cK4wYeH/48FOm0Hya0d5HZzULZTcDsufNX+9GHn5+fif7fbxaQhZdQsHv/xI3549TOevPoFpRMVrUYTSlpBuVxGNptFtVqFpmnI5XI4OjrCwcGBuNq2jVKphOPjY5ycnKBer0N6sx/H+2tfYFp+gA+iXyKhptA4bcC0TPFGqqlUKjg7OwvcQaWqqgpQo9HAxcUFHMcRa5Kc28TMegSfyo/w8YsHSFUyaNVbMAxDbOaDBPLt3Mzhuq5QX6vVhErfpwIYz29hOjqHT+SHmHlxHzuqAr2pi4j7QG4OAzudjngJXeEDqTKfz0PaLCYwE41cAiNIHKRgagbMEHBYIdcIGwYWCgVICVW5Aj6PYLuYhKWbgQ/HAdvt9mRgqpoRJt+VH2L6eQRbhR0BNExjoskEHh4ejgema9kBME7gHDYLCQHUDX2iQkImAjNHe5hevwRG5/Auvw1TM6Hr+kSFhDDCfNEosLaHqbXZEaCma7cDpg+zAXDqGvCfFY41Wanu4s7qPdyNPxJA5uWwyf/Jh0olg6nV2WtAS7s5KH6UOUfTJgAOTOZRHE6bSUCazft/AbSCxOYxo2njTgorzg1AmjyLN7l3sHULlm0FQKohLAykalYb3l87ywK4NgDeic7ir31Z+NC69A2BVBIGco2RZ7UPAwOFg8Qm8B5e77+F2TIChSxVLJ7NZnOkfLFGhoHFYnEQ5Y/W7+Oz+LfCh69zb6E3tCAo3MyNw0DWvmGFrORSspzGh+tfYUb+Gu+tfY6Xe39CO2sFCtkFGRBWaz83udk3mT3GH1yTMuUsvvn9ezyO/oTvVp8gXdlFq95ESS2Jqs1o0vmE0UcsvFRMNVRMKNfYc4QPr/riVefyup7wGyc3sK9QFYNDtZxMF/YWQukOTvZ2SfTTy1+v38P/HVK4SXMw+8Nnlqb4gaACpgyV8Xn6d6TRh78KGDFZlhGPxzE/P49YLIbFxUUsLS1BURQkk0lsbGxgYWEBKysrWF5eFvAwQwp/VnDQZ36D99UyvxggBoJ+5TobPNfp2zBDuun75VY+HFYovr76fTidDuy2A8tuw/U8uK4n7j2vK64d1xXTtGzxXLd7LtRKk76yHKcDTTfR1IwArJuWgPBqmLaAaYYprrphCejfJpAuAZMY/d4AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Data at address 400 is loaded in cache line 0 overwriting data at address 480&quot;
        title=&quot;Data at address 400 is loaded in cache line 0 overwriting data at address 480&quot;
        src=&quot;/static/41d9971979ecc4fade1d1a46f8a5731f/e61aa/2.png&quot;
        srcset=&quot;/static/41d9971979ecc4fade1d1a46f8a5731f/c26ae/2.png 158w,
/static/41d9971979ecc4fade1d1a46f8a5731f/e61aa/2.png 264w&quot;
        sizes=&quot;(max-width: 264px) 100vw, 264px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;
Alt: Data at address 400 is loaded into cache line 0 overwriting previous data&lt;/p&gt;
&lt;p&gt;Cache thrashing in case of directly mapped cache here consecutive loads are resolved to same cache line thus over writing one another and degrading performance&lt;br/&gt;
Made with &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link opens a new tab)&lt;/p&gt;
&lt;/center&gt;
&lt;h2&gt;CLFLUSH&lt;/h2&gt;
&lt;p&gt;clflush is an x86 instruction that is used to flush a cache line corresponding to specific address through the entire cache hierarchy. If you are interested to learn more about clflush instruction, you can visit &lt;a href=&quot;https://www.felixcloutier.com/x86/clflush&quot; target=&quot;_blank&quot;&gt;https://www.felixcloutier.com/x86/clflush&lt;/a&gt; (link opens a new tab).&lt;/p&gt;
&lt;p&gt;The important point with clflush is that it can be used at any privilege level and hence ever a program running in userspace with basic execution privilege can still run the clflush instruction. This allows for attacker to exploit clflush without escalating privilege level.&lt;/p&gt;
&lt;h2&gt;Flush and Reload&lt;/h2&gt;
&lt;p&gt;In flush and reload, the attacker thread flushes a particular cache line or a cache set where the shared library will be loaded. As we know the address beforehand, we only have to observe a small part of cache which makes this an efficient technique.&lt;/p&gt;
&lt;p&gt;Once flushed, the attacker waits for a small amount of time before loading the shared library themself. If the call resolves quicker than expected, we realize the routine is cached in the last level cache shared between the hardware threads. As the attacker had flushed this cache line previously, they can now determine that the victim thread has called the shared library routine.&lt;/p&gt;
&lt;p&gt;Based on this timing analysis, the attacker thread can track events on the victim thread.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 621px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 70.88607594936708%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsTAAALEwEAmpwYAAABiElEQVQoz5WT204bMRCG8/6Pg3pTqQiUDSC4oiQVtBG0LMlu3D15xl5v7PGh2vU2JFVSibmyx/70zz9jT8KJ0FrXdW2MCadjcjRLREII5xzn/MMwIhJRCAEAvPcx6f/G/2CttZQyrpVSXdf15N6FHT+JG2vtSBJVTWOdi9u2bZVSYzlSffvxk4v2QJmIACCEYLquvLuD21tVVfHYGCOECCE0KF/WJav491/Z7xoHyUN4KyVOp3Y2azebnUsEcM4/v7GhVl8UxTLNrXXvyog4wklibm4OYESybpmy3tQwuZd1obb6GDydmqsrOcCxMf2Rd1nBS+jN16hes/LA8zt8eamTROR5Dw9tk1J2Xee9X7Eq3dQrVu+6e0w5Sdp9WEglVTg1KmttbKluWzGb0fW1YmycnDUP6eLr60Js5TBt/+8L21eG8/PtxQWu1264m9X52fPnT+mXp2wZfDBkrLVEFMXHRwKcA2JZFPn9fTWfl1kGAqWQrGTz1eMie3xjK4GCcw4ATdPED/MH57socA7ZCWAAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;An image that illustrates how the timing changes with cached and un-cached data exaggerated for emphasis.&quot;
        title=&quot;An image that illustrates how the timing changes with cached and un-cached data exaggerated for emphasis.&quot;
        src=&quot;/static/e156606aabac6a89299bbf2a9fcae5c9/3075e/timing.png&quot;
        srcset=&quot;/static/e156606aabac6a89299bbf2a9fcae5c9/c26ae/timing.png 158w,
/static/e156606aabac6a89299bbf2a9fcae5c9/6bdcf/timing.png 315w,
/static/e156606aabac6a89299bbf2a9fcae5c9/3075e/timing.png 621w&quot;
        sizes=&quot;(max-width: 621px) 100vw, 621px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: An image that illustrates how the timing changes with cached and un-cached data exaggerated for emphasis.&lt;br/&gt;
The picture is made using &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link will open a new tab)
&lt;/center&gt;
&lt;h2&gt;Leaking secrets&lt;/h2&gt;
&lt;p&gt;To leak secrets, the victim thread must have a gadget that calls a shared library based on a secret. Consider the following code snippet:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; secret&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;secret&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;secret &lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;token function&quot;&gt;shared_library_routine&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
        secret &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; secret &lt;span class=&quot;token operator&quot;&gt;&gt;&gt;&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Based on timing analysis, the attacker thread can detect if &lt;strong&gt;shared_library_routine()&lt;/strong&gt; is called by the victim and we know that this call happens only if the least significant bit of shifting secret is 1 and the attacker can decipher the entire secret just based on timing analysis.&lt;/p&gt;
&lt;h2&gt;Complications&lt;/h2&gt;
&lt;p&gt;Flush and reload have the following complications associated with it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The attacker and victim should run on the same physical core on separate threads at the same time.&lt;/li&gt;
&lt;li&gt;The attacker and victim should share the last level cache. Without shared cache, this type of attack will not work.&lt;/li&gt;
&lt;li&gt;The micro-architecture must implement a form of clflush instruction to facilitate flush and reload.&lt;/li&gt;
&lt;li&gt;The timing between the flush and reload is important. If the timing is not right, the attacker might misinterpret the secret.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Scenarios with Flush and Reload&lt;/h3&gt;
&lt;p&gt;The following images depicts the optimal flush and reload scenario:&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 57.59493670886076%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACAElEQVQoz5WSy2tTQRTG85e5cFd3hSKo4KO0K6ULibgRLBKXFaQ7t90VXRTUlVYxramlmjTGEMFWLTFpbu7N4965j7mP+clMSGggKh74mMPMOd/MN9/JASRJQhAEOkUpZdae3aPTPmXQG9DtWKhUTZ3/KXJjQs/zJg1JllA/bvDxS5nDr5/5VK/guL3J+d9Ic7Zt4/s+QggUo8Ltn7tceneLxVKexfd5ruyscKdUwA+DKdJZyA2HQyNXk44Jnx+/4tzbi8ztXjc4v3OZG6U8QRTwr5hIdhyHMApRsaL4Y4+VD/fJHxS4vf+Am3v3KBw8xhMecRwTRZFBGIYG4zxN0xGhTpxuF+G6DIcDojCCDIgVSmYGWZwiI2kuDcLAEGhlZ2EIx9q/NZs0Tk4Y+L6Rb/4Kxf/G6IVS0tzaoru5iSiXZ358pjKzv98q86j8hJ7bp/WrRcfq0G63aTab5pW5U8vC63QQS0tk8/M4a2ukujPLpghTZXZ5evSCue2rWK5No96gWq1Sq9WoVCojwr7rImwbd3kZtbCAt74+U8pY/rPvL7nw5hr9YEAiE4QvJuaYsTEu+z6t1VX6+TzWxgZCSnwhzGzqW40BYWDMeX1U5G7xIVa/SxInEzJdpydgYkootYMRkZTIM9BFGnq09JrGqXFfj4rrCTwh8DzB0HWJIslvZvOA/Ik05XUAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The attacker runs the flush, the victim runs the shared routine, the attacker then loads the same routine to find that it is cached based on timing and interprets a part of secret.&quot;
        title=&quot;The attacker runs the flush, the victim runs the shared routine, the attacker then loads the same routine to find that it is cached based on timing and interprets a part of secret.&quot;
        src=&quot;/static/da1d6a35e6d51ad43340a0d3faf3f68f/f058b/fr2.png&quot;
        srcset=&quot;/static/da1d6a35e6d51ad43340a0d3faf3f68f/c26ae/fr2.png 158w,
/static/da1d6a35e6d51ad43340a0d3faf3f68f/6bdcf/fr2.png 315w,
/static/da1d6a35e6d51ad43340a0d3faf3f68f/f058b/fr2.png 630w,
/static/da1d6a35e6d51ad43340a0d3faf3f68f/f8067/fr2.png 726w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt; &lt;/p&gt;
&lt;center&gt;
Alt: The attacker runs the flush, the victim runs the shared routine, the attacker then loads the same routine to find that it is cached based on timing and interprets a part of secret.
&lt;/center&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 59.49367088607595%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABvElEQVQoz6WRzWsTURTF509zpRu7sRCVJoKmfqEIbvxzXAiCC3HrqjYxtU2HgCjqiC3FSUkm03EyM+/NR2aSzE/eGyatqJv2wuG9d9/lcM49RlmWqJrNZsznc32ve+cpo74kSaJJL0yoVBVFoQnzPF8RnheGEALXdYnjeGX5IvWHZSmlVquUnoXq1agd1adak0KWZbpn1PtSCqMwpMhz/alQD9eknudhH9s4Ewf7eKjPJE1I01QLUjMrwrwosMdjfo5GuJ73T/siiPj68QvDQ5vvny0mQ+f/ltMwZGpZDE2T2Pf/CkfVwckRb60ttg932DrosX30gYHzibw4DdOIhSADpGkSNZuk7TaRaVYDi4UeWpRL/X5uveLSu+usde9wtXubK50Wjc5DPPFL/y/LJcbJZIIrBGJ3l6zRoNjYINnfr2QvK6IllcIXP15zeafFev8B1/bus7bX5lb/KX48rQSctSwHA4JWi3hzk6jfZwE6ILXLfF7o6Zff3rDeuUfz/RNudh9zo/eIu71njLwxxawK8zSUNCUYjYgcBxkEOnUFlZ5KUUHGkkCETKMAP5zi+h5+FCCkJBKSJM34DZiOhwu3tpD1AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The attacker runs the flush, the victim doesn&amp;#39;t the shared routine, the attacker then loads the same routine to find that it is not cached based on timing and interprets a part of secret.&quot;
        title=&quot;The attacker runs the flush, the victim doesn&amp;#39;t the shared routine, the attacker then loads the same routine to find that it is not cached based on timing and interprets a part of secret.&quot;
        src=&quot;/static/a988ee8a803f7136dc2e36619c4b15be/f058b/fr1.png&quot;
        srcset=&quot;/static/a988ee8a803f7136dc2e36619c4b15be/c26ae/fr1.png 158w,
/static/a988ee8a803f7136dc2e36619c4b15be/6bdcf/fr1.png 315w,
/static/a988ee8a803f7136dc2e36619c4b15be/f058b/fr1.png 630w,
/static/a988ee8a803f7136dc2e36619c4b15be/f8067/fr1.png 726w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt; &lt;/p&gt;
&lt;center&gt;
Alt: The attacker runs the flush, the victim doesn&apos;t the shared routine, the attacker then loads the same routine to find that it is not cached based on timing and interprets a part of secret.
&lt;/center&gt;
&lt;br /&gt;
&lt;br /&gt;
&lt;p&gt;The following are scenarios where attacker didn’t time the flush and reload correctly:&lt;br&gt;
&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 59.49367088607595%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACSUlEQVQoz22Tz08TQRzF+495Ml4knECiAv6CRNDEmHgzxph4MjHRGC8mBA8eNPGmxgMhaCBgKQVLoUUKgqVd2gVpd3d2Z3+0ux+zU1po8CXfzGRnvi/vfd9sIooiYnieR6PRoA1HOFT3qxweHFLRKnjS7ZwRQdx3utTnKCLRIXAcRRpDBi6bxS2WsmlWchm1Vms6buChmweExwSn0SZNxKqCIFCE0mupmMx/oOf7Da7O3+Py3F365m5zf/EJX7anGZgZV6S2ZWOYBrVaDSnliULLstB1Hdu28Ru+Opj49Z4L80NcSo7Tlxyj98cId5Ye8Wlniv7ZMbZK26xlsmwWNsnn8wghOkq7LBuWCU14s/qOc1P99H67ycWZ65yfvsKt2Qd8zH+m5+s1fms7lIslPN9TY/J9H9d1VQaJtvdYoWHUCYMG5ZrGciXLqp4jo6+Trq6ypm9QMXRWtCzCForIdmxlNxYTE8aj6xD6QUBxf59drUztqKaS/B+0P2UKhQLl3RKl3T21jysMw27L0jCobWywl0ohjv4qvmbYpBmFag2jUFkyLANXuiwVf5It55C2g2lZSp0itC2LOFuRSmEODSFHRjBTqVZqzeaZt9bGw+VnvFifOPN0EgfVKrplYS0s4A4MEAwO4iwutm4c2+hqOp7F48xzXuUmW9cIz6Ys0mnqw8PYo6OYyWQcNoHvK5td1WxAA56mX/I68xZ8cFyJlK0f4yQUKalrGmalgqjXVepxqQcvZafiNONG4QiOjDpC2FjCxrQEUrr8A5gjc8lCvt0iAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The attacker runs the flush, the victim runs the shared routine twice by the time the attacker loads the same routine to find that it is cached based on timing. In doing so attacker misses a part of the leak.&quot;
        title=&quot;The attacker runs the flush, the victim runs the shared routine twice by the time the attacker loads the same routine to find that it is cached based on timing. In doing so attacker misses a part of the leak.&quot;
        src=&quot;/static/fdf70775a464ba97031174c7eb58fdb1/f058b/fr3.png&quot;
        srcset=&quot;/static/fdf70775a464ba97031174c7eb58fdb1/c26ae/fr3.png 158w,
/static/fdf70775a464ba97031174c7eb58fdb1/6bdcf/fr3.png 315w,
/static/fdf70775a464ba97031174c7eb58fdb1/f058b/fr3.png 630w,
/static/fdf70775a464ba97031174c7eb58fdb1/f8067/fr3.png 726w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt; &lt;/p&gt;
&lt;center&gt;
Alt: The attacker runs the flush, the victim runs the shared routine twice by the time the attacker loads the same routine to find that it is cached based on timing. In doing so attacker misses a part of the leak.
&lt;/center&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 560px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 77.21518987341771%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC3klEQVQ4y22TbW/bZBSG87v4xpeNbkXQ0cKGuqbrOlgihtgYSIwvW0Hr7xhMiKkICSGEkNalbhOnLevUQbu0WeolIc6cZH6PHce1cyE7TfqyHeno2Od5zq1z7uc+iV6vR+SR6bqO7/vx9yAX7Ae8qrdoqza2asWuKSpWy8BsGmgv1fjOoCbBETMM4zVAx3O4/3iBn57+yv0nv/DjxgL31n+Ocz/8/YB76w9oWeohYBiG7O/vxwnTNIeAYS+M4ytLZWzlE0ZySUbFGc7mLvVj7JcYzc5QaD4f1iQigGKxSL1efyOgaml8vHKND8SrTIhpJsTUgacZj+JKikKj2K8Jw+MjW5ZFEARHU2htnfczs5zOTnEmO33MR7JJzgjT7Bx02KNH4uSjRO44Dm2nTdfrohkat5bn+Wrte27mv+NG7g7Xc7e5Lt7mxuodvszPUVIk/I6P53n9DgeAUYcRWMRpNLrX9foU+D1kqUZN+g+l+hL5RY2m3KAqVVFkhdLzEqqqxnePAbZtm7IkUdjeplouU6vVhhSUqxW2trfYk/bYLe6ys7sTc/+s8IxKpRLzF1k88uDHdl3cqLjRQJJlgoP8kE9D45+tf9l4ssHm08041uryUCWv6VDb3ESdm8O5e5fW/DyuZQ3POr4X8zcrfk0qf4ur4jekV79lSviCxXK2vwRhQKLValGtVGjZNqYg0BkfJ7xwAePiRRxNOwLYYXL581iP7+YuM5qb4T1xlrcz5/lt769DQNu2aSoKuuuiZ7M4ySTBlStYqRSeYRwDvJy9yVj+Uz7Mp5nIpzm/9hlnhWn+kBb7gL3gxMhLS9jnzhEcdNjV9eGZ23X56GGKU5lJ3slMcTozychSkrf+HGOh8Ht8xw/8E4+iKMiPHtEQBOqCgNpsYphmvEGGabC695ictEbuxTor0irLJZHF4jJFuYSpG7F2hx0OpHPSjgr/MAm+G0C0pT503C6m3abjdfkf9qIhVZZEt34AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The attacker runs the flush, the victim runs the shared routine but the attacker&amp;#39;s load of the same routine is too quick and overlaps with the load of the victim. In doing so attacker misses interprets a part of the leak as the time taken is closer to that of a cache miss.&quot;
        title=&quot;The attacker runs the flush, the victim runs the shared routine but the attacker&amp;#39;s load of the same routine is too quick and overlaps with the load of the victim. In doing so attacker misses interprets a part of the leak as the time taken is closer to that of a cache miss.&quot;
        src=&quot;/static/e8c3205f9925ff909165388c4b9d05f5/b06ae/fr4.png&quot;
        srcset=&quot;/static/e8c3205f9925ff909165388c4b9d05f5/c26ae/fr4.png 158w,
/static/e8c3205f9925ff909165388c4b9d05f5/6bdcf/fr4.png 315w,
/static/e8c3205f9925ff909165388c4b9d05f5/b06ae/fr4.png 560w&quot;
        sizes=&quot;(max-width: 560px) 100vw, 560px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The attacker runs the flush, the victim runs the shared routine but the attacker&apos;s load of the same routine is too quick and overlaps with the load of the victim. In doing so attacker misses interprets a part of the leak as the time taken is closer to that of a cache miss.
&lt;br/&gt;
All images are made using &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link will open a new tab)
&lt;/center&gt; 
&lt;h2&gt;Coming up next&lt;/h2&gt;
&lt;p&gt;In the next post we’ll look at Prime and Probe - a an alternative to Flush are Reload technique that works on systems that don’t implement a variant of clflush instruction.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please reach out to me and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Timing Analysis]]></title><description><![CDATA[Welcome to out of order core, a blog that looks into computer micro-architecture and the micro-architectural vulnerabilities. Over the…]]></description><link>https://outofordercore.github.io/timing-analysis/</link><guid isPermaLink="false">https://outofordercore.github.io/timing-analysis/</guid><pubDate>Tue, 22 Jun 2021 12:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Welcome to out of order core, a blog that looks into computer micro-architecture and the micro-architectural vulnerabilities. Over the course of next few posts, we will be taking a dip in the world of Timing Analysis.&lt;/p&gt;
&lt;h2&gt;Memory Hierarchy&lt;/h2&gt;
&lt;p&gt;Before we look at what timing analysis is, let us take a brief look at memory hierarchy of modern computer system.
A pyramid that depicts memory hierarchy with CPU registers on top followed by L1, L2, and L3 caches, followed by DRAM based memory followed by flash based drives such as Solid State Drive, followed by Hard Disk Drive. The registers and caches reside on CPU and are faster at resolving requests but are very small, the DRAM is larger and plenty fast compared to the Solid State Drive and Hard Disk Drive that takes milliseconds to resolve data.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 65.18987341772153%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsTAAALEwEAmpwYAAACZklEQVQoz22S60/TYBSH+x9jgtMlOMWAG4ZruGwgKCwtbGw4mJuCEQMCImQkxF1gMNfSdKXdu7Zv37brha19zSBOMD7fTk6e8/t9OIQoCAAA8yGGYWCM9/f2c8c5z/MMw+iums0mwzC5XK5cLhOmabmuix/ieR7GOJqcj6fJ7tgFIcSy7PX1NWHbzn9NmjuLpifJzBQnVBz7xjCM5h8cp6NYlkXYtn0ndMEYm7YTnJx8MTbycnx0ODJrmtZ9IISFQqFYLBJ3Z/6J/VEWXlF7/XOZ57MfBqlvp3TjfnlN1wEAoF4nREHkeZ6vdeA4TpIk9ooZnXo7vRCbeUPNvYtNzS9PhBf5GqdpGoRQVVVd1zVNAwAQtyav6zpCCEKIsfdx88Tnmw6FokOvqeGRWDAUffJ0Zvvrz7tYRVGKt50vymVCkWUVqrqmG7ru3DjnF9Xw3NoiubVEbS4tb5Kxz8ur2wtLnyLzqV/0lWmaSFUbnc6gAQAhSZLUkBBCruvhdutwIZLw9yQDvvRgID0YyIb6NwaeJfp6E/5HJ9RiJxnC46Ojw4PvpVKJgBAihFQIm5bNXpYLSbKSXSukYvn3K6VUvJiKnybIs/V4JbuWT5I1pmo6jiLLCCFZlom6KIqCUAdAFsTV4OhEj3/GFwg/DqwEx1ZC46nxCDkwPN3bF/YFJnr8yaExW9MVFdLVaiGfJ0zTbLVaLsZNhlMyu9rWgZzZkTM74voXOpa+pFJgYxtmd+XMjrZ1oGR3DYYzLBMqiiRJhOu67Vs8t0PbdWVFqbHsxfk5XakwNMPQdK3Gy7LSarc7j+z+faffTBmWa4ZR2CIAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;A pyramid that depicts memory hierarchy with CPU registers on top followed by L1, L2, and L3 caches, followed by DRAM based memory followed by flash based drives such as Solid State Drive, followed by Hard Disk Drive. The registers and caches reside on CPU and are faster at resolving requests but are very small, the DRAM is larger and plenty fast compared to the Solid State Drive and Hard Disk Drive that takes milliseconds to resolve data.&quot;
        title=&quot;A pyramid that depicts memory hierarchy with CPU registers on top followed by L1, L2, and L3 caches, followed by DRAM based memory followed by flash based drives such as Solid State Drive, followed by Hard Disk Drive. The registers and caches reside on CPU and are faster at resolving requests but are very small, the DRAM is larger and plenty fast compared to the Solid State Drive and Hard Disk Drive that takes milliseconds to resolve data.&quot;
        src=&quot;/static/ca8e6c4cae3206178a779cbd1b514787/f058b/hierarchy.png&quot;
        srcset=&quot;/static/ca8e6c4cae3206178a779cbd1b514787/c26ae/hierarchy.png 158w,
/static/ca8e6c4cae3206178a779cbd1b514787/6bdcf/hierarchy.png 315w,
/static/ca8e6c4cae3206178a779cbd1b514787/f058b/hierarchy.png 630w,
/static/ca8e6c4cae3206178a779cbd1b514787/01267/hierarchy.png 713w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A pyramid that depicts memory hierarchy with CPU registers on top followed by L1, L2, and L3 caches, followed by DRAM based memory followed by flash based drives such as Solid State Drive, followed by Hard Disk Drive. The registers and caches reside on CPU and are faster at resolving requests but are very small, the DRAM is larger and plenty fast compared to the Solid State Drive and Hard Disk Drive that takes milliseconds to resolve data.&lt;br/&gt;
Source (link will open a new tab): &lt;a href=&quot;https://sites.google.com/site/cachememory2011/memory-hierarchy&quot; target=&quot;_blank&quot;&gt;https://sites.google.com/site/cachememory2011/memory-hierarchy&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;
As we can see the CPU register sits on top and can generally be accessed every clock cycle of the CPU, followed by the L1, L2, L3 caches each having relatively small latency in 10s of cycles. The main memory access to the DRAM takes even longer and access to data in Solid State Drive (SSD) and Hard Disk Drive (HDD) can take milliseconds to resolve.
&lt;h2&gt;Why is this hierarchy needed?&lt;/h2&gt;
&lt;p&gt;Assume CPU is repeatedly working on same data over and over again. Maybe this data is too large to store in the registers and CPU has to repeatedly access DRAM. As each DRAM access can take 100s of cycles, and CPU has to wait for the data to be brought it before it can work on it. Suppose this data, which is being repeatedly accessed, was stored in a small chunk of memory on the chip, the CPU wouldn’t have to wait as long for data and can perform more efficiently as it spends more time working on data rather than waiting for it. This line of thinking gave us cache memory on our general purpose processors.
A plot of Page number on Y-Axis vs Time on X-Axis showing how addresses are repeatedly accessed over time and the concentrated parts show how the accesses have spacial and temporal locality.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 47.46835443037975%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsTAAALEwEAmpwYAAABqElEQVQoz03RT+uiQBjA8d5plx+9iC4dK/YQRLcuEXQKuhRLFB5KCrTJCvOgiCnZBKONZuP/sVmyZdnPYXgO84UHnsqr9CwFQeD7fhAEz+czTVNWer/f37cofQdKKWOs4jhOEAR5ntNSHMd5nidJQgjxfd91XYwxISRJkjRNsywjhHw/F0VRCcPQMAxBECRJOhwOx+NREITBYDCdTjmOW61WHMcpioIQkmWZ53lFUSCEkiR9YsYYz/OtVqvb7fZ6vU6nAwCAEJqly+VyPp89zzudTqPRyLIs13UVRZFl+bM2Y2y5XDYajV+ldru9Xq9N09R13TRN27YNw0AIiaLY7/cty3IcR5IkAMDfeLfbjcfj2Ww2LW02GwBAvV6vVqs/Pz+1Wm273Wqatlgsms3mcDhUVXUymXxiSmmWZew/GOM0TQEAv0vz+TyKIsYYpVQURV3XGWMQwk9cFIXv+xjj76mCINA0zff9f0cKw3C/379eLwih53kIIYyxYRh5nn/i2+1m2/b9fkcIQQjDMKSURlFECInj2PM8VVWvpcfjYZrm9XrVdT3Lsj9fa9MyaX2TKAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;Alt: A plot of Page number on Y-Axis vs Time on X-Axis showing how addresses are repeatedly accessed over time and the concentrated parts show how the accesses have spacial and temporal locality.&quot;
        title=&quot;Alt: A plot of Page number on Y-Axis vs Time on X-Axis showing how addresses are repeatedly accessed over time and the concentrated parts show how the accesses have spacial and temporal locality.&quot;
        src=&quot;/static/d82e555422e884475af0c35f7c71c1d4/f058b/locality.png&quot;
        srcset=&quot;/static/d82e555422e884475af0c35f7c71c1d4/c26ae/locality.png 158w,
/static/d82e555422e884475af0c35f7c71c1d4/6bdcf/locality.png 315w,
/static/d82e555422e884475af0c35f7c71c1d4/f058b/locality.png 630w,
/static/d82e555422e884475af0c35f7c71c1d4/0955e/locality.png 901w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: A plot of Page number on Y-Axis vs Time on X-Axis showing how addresses are repeatedly accessed over time and the concentrated parts show how the accesses have spacial and temporal locality.&lt;br/&gt;
Source (link will open a new lab): &lt;a href=&quot;https://ieeexplore.ieee.org/document/5388264&quot; target=&quot;_blank&quot;&gt;D. J. Hatfield and J. Gerald, &quot;Program restructuring for virtual memory,&quot; in IBM Systems Journal, vol. 10, no. 3, pp. 168-192, 1971, doi: 10.1147/sj.103.0168.&lt;/a&gt;
&lt;/center&gt;
&lt;h2&gt;Shared Libraries&lt;/h2&gt;
&lt;p&gt;Before seeing what is timing analysis, we need to understand the concept of shared library. Consider two programs dependent on a common library. If we load this library twice into memory, it’ll add to redundancy and lower the effective capacity. Modern OS use the concept of shared library and shared pages to reduce this type of redundancy. When the program runs, a stub tells the OS about an access to the shared library. If this library is not in memory, it is loaded into a shared page and its address is made known to the program. When another program requests access to this same library, OS supplies the address of this shared page back. This works really well when two programs share read only data.
The images hows the memory layout of two compiled programs and how the shared library section maps to the same shared page for both the programs.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 67.08860759493672%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAwABBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHtabIcUf/EABoQAAICAwAAAAAAAAAAAAAAAAABAjIRITH/2gAIAQEAAQUCS31YI2lU/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFhAAAwAAAAAAAAAAAAAAAAAAECAx/9oACAEBAAY/AhE//8QAGxAAAgIDAQAAAAAAAAAAAAAAAAERMSFxkaH/2gAIAQEAAT8hgr6S2SjZ0Q3CWD//2gAMAwEAAgADAAAAEIz/AP/EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/EIj/xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAgEBPxCn/8QAHBAAAgICAwAAAAAAAAAAAAAAAAERITFxYaGx/9oACAEBAAE/ELia5v0Jd1pOJEsYDEjElGvSlZ//2Q==&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;The images hows the memory layout of two compiled programs and how the shared library section maps to the same shared page for both the programs.&quot;
        title=&quot;The images hows the memory layout of two compiled programs and how the shared library section maps to the same shared page for both the programs.&quot;
        src=&quot;/static/c4610a4a9725f5ca20a981b267390298/828fb/shared_lib.jpg&quot;
        srcset=&quot;/static/c4610a4a9725f5ca20a981b267390298/ff44c/shared_lib.jpg 158w,
/static/c4610a4a9725f5ca20a981b267390298/a6688/shared_lib.jpg 315w,
/static/c4610a4a9725f5ca20a981b267390298/828fb/shared_lib.jpg 630w,
/static/c4610a4a9725f5ca20a981b267390298/b0df9/shared_lib.jpg 646w&quot;
        sizes=&quot;(max-width: 630px) 100vw, 630px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: The images hows the memory layout of two compiled programs and how the shared library section maps to the same shared page for both the programs.&lt;br/&gt;
Source (link will open a new lab): &lt;a href=&quot;https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/9_VirtualMemory.html&quot; target=&quot;_blank&quot;&gt;https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/9_VirtualMemory.html&lt;/a&gt;
&lt;/center&gt;
&lt;h2&gt;Resource Sharing and Timing Analysis&lt;/h2&gt;
&lt;p&gt;Most processors today implement Hyperthreading or Simultaneous Multi Threading (SMT) where two hardware threads share resources between them such as the floating point unit and often the last-level caches or the L3 cache - the main idea behind this being these units are not busy / populated always by a single thread and two threads can keep this resource busy for longer as opposed to only a single one.&lt;/p&gt;
&lt;p&gt;As we saw, smaller memory can resolve request faster compared to the larger one all owing to laws of physics. Consider in a system with Simultaneous Multi Threading where each core has to physical threads, the threads share the last level cache for all their data. Consider program in one thread runs a routine from a shared library and the program from other thread calls the same routine shortly after, the code for the routine is present in the last level cache and hence will run slightly faster for the second thread compared to the scenario where the second thread calls the routine and its not caches.&lt;/p&gt;
&lt;p&gt;Looking at the time taken for execution, program on one thread can analyze the behavior of program on another thread. If the access to routine is based on the value of a secret, the attacker thread can do a timing analysis and leak the data from the victim thread.&lt;/p&gt;
&lt;p&gt;An image that illustrates how the timing changes with cached and un-cached data exaggerated for emphasis.&lt;/p&gt;
&lt;p&gt;&lt;span
      class=&quot;gatsby-resp-image-wrapper&quot;
      style=&quot;position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 621px; &quot;
    &gt;
      &lt;span
    class=&quot;gatsby-resp-image-background-image&quot;
    style=&quot;padding-bottom: 70.88607594936708%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsTAAALEwEAmpwYAAABiElEQVQoz5WT204bMRCG8/6Pg3pTqQiUDSC4oiQVtBG0LMlu3D15xl5v7PGh2vU2JFVSibmyx/70zz9jT8KJ0FrXdW2MCadjcjRLREII5xzn/MMwIhJRCAEAvPcx6f/G/2CttZQyrpVSXdf15N6FHT+JG2vtSBJVTWOdi9u2bZVSYzlSffvxk4v2QJmIACCEYLquvLuD21tVVfHYGCOECCE0KF/WJav491/Z7xoHyUN4KyVOp3Y2azebnUsEcM4/v7GhVl8UxTLNrXXvyog4wklibm4OYESybpmy3tQwuZd1obb6GDydmqsrOcCxMf2Rd1nBS+jN16hes/LA8zt8eamTROR5Dw9tk1J2Xee9X7Eq3dQrVu+6e0w5Sdp9WEglVTg1KmttbKluWzGb0fW1YmycnDUP6eLr60Js5TBt/+8L21eG8/PtxQWu1264m9X52fPnT+mXp2wZfDBkrLVEFMXHRwKcA2JZFPn9fTWfl1kGAqWQrGTz1eMie3xjK4GCcw4ATdPED/MH57socA7ZCWAAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
  &gt;&lt;/span&gt;
  &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        alt=&quot;An image that illustrates how the timing changes with cached and un-cached data exaggerated for emphasis.&quot;
        title=&quot;An image that illustrates how the timing changes with cached and un-cached data exaggerated for emphasis.&quot;
        src=&quot;/static/e156606aabac6a89299bbf2a9fcae5c9/3075e/timing.png&quot;
        srcset=&quot;/static/e156606aabac6a89299bbf2a9fcae5c9/c26ae/timing.png 158w,
/static/e156606aabac6a89299bbf2a9fcae5c9/6bdcf/timing.png 315w,
/static/e156606aabac6a89299bbf2a9fcae5c9/3075e/timing.png 621w&quot;
        sizes=&quot;(max-width: 621px) 100vw, 621px&quot;
        style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;&quot;
        loading=&quot;lazy&quot;
      /&gt;
    &lt;/span&gt;&lt;/p&gt;
&lt;center&gt;
Alt: An image that illustrates how the timing changes with cached and un-cached data exaggerated for emphasis.&lt;br/&gt;
The picture is made using &lt;a href=&quot;https://excalidraw.com/&quot; target=&quot;_blank&quot;&gt;https://excalidraw.com/&lt;/a&gt; (link will open a new tab)
&lt;/center&gt;
&lt;h2&gt;Why can you expect next?&lt;/h2&gt;
&lt;p&gt;Over the next few posts, we will take a look practical techniques that allows an attacker to leak secrets from the victim. Stay tuned for the next post on Flush and Reload.&lt;/p&gt;
&lt;p&gt;Thank you for reading till the end. I’m an undergraduate student keenly interested in Computer Architecture and I look at micro-architectural based attacks to understand more about the working of our hardware. If you find any inaccuracies in the above post, please reach out to me and I’ll address it in the next edit. Have a nice day!&lt;/p&gt;</content:encoded></item></channel></rss>